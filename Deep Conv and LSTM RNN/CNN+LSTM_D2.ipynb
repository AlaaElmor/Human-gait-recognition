{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN+LSTM_D2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfVBi0Bd2HU0",
        "outputId": "223ab22b-e3ce-4005-f5c9-21f0efac6ffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Mounted at /content/gdrive\n",
            "(44339, 128, 6) (44339, 20) (4936, 128, 6) (4936, 20)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/'  #change dir to your project folder\n",
        "\n",
        "import numpy as np\n",
        "x_train = np.load('gdrive/My Drive/dataset2/trainX.npy')\n",
        "y_train = np.load('gdrive/My Drive/dataset2/trainy.npy')\n",
        "x_test = np.load('gdrive/My Drive/dataset2/testX.npy')\n",
        "y_test = np.load('gdrive/My Drive/dataset2/testy.npy')\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "from numpy import save, load\n",
        "from tensorflow import keras\n",
        "from pandas import read_csv\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras import Model\n",
        "from keras.layers import LSTM, Conv1D, concatenate,GlobalMaxPooling1D,TimeDistributed, MaxPooling1D\n",
        "# from keras.utils import to_categorical\n",
        "from matplotlib import pyplot\n",
        "from keras import regularizers\n",
        "import tensorflow as tfs"
      ],
      "metadata": {
        "id": "HCRJ_J-N2LoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape data into time steps of sub-sequences\n",
        "n_timesteps, n_features, n_outputs = x_train.shape[1], x_train.shape[2], y_train.shape[1]\n",
        "n_steps, n_length = 4, 32\n",
        "x_train = x_train.reshape((x_train.shape[0], n_steps, n_length, n_features))\n",
        "x_test = x_test.reshape((x_test.shape[0], n_steps, n_length, n_features))"
      ],
      "metadata": {
        "id": "Zx6rbQdC2cEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_training, X_validation, y_training, y_validation = train_test_split(x_train, y_train, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "BeAqBV-i2nrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "model2.add(TimeDistributed(Conv1D(filters=64, kernel_size=5, activation='relu'), input_shape=(None,n_length,n_features)))\n",
        "model2.add(TimeDistributed(Conv1D(filters=64, kernel_size=5, activation='relu')))\n",
        "model2.add(TimeDistributed(Conv1D(filters=64, kernel_size=5, activation='relu')))\n",
        "model2.add(TimeDistributed(Conv1D(filters=64, kernel_size=5, activation='relu')))\n",
        "model2.add(TimeDistributed(Dropout(0.5)))\n",
        "model2.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
        "model2.add(TimeDistributed(Flatten()))\n",
        "model2.add(LSTM(100))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Dense(128, activation='relu'))\n",
        "model2.add(Dense(128, activation='relu'))\n",
        "model2.add(Dense(n_outputs, activation='softmax'))\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model2.summary()\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOoetIKT23_q",
        "outputId": "ae29e6fe-c972-4ade-ce11-429a4b358d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed_7 (TimeDis  (None, None, 28, 64)     1984      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_8 (TimeDis  (None, None, 24, 64)     20544     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_9 (TimeDis  (None, None, 20, 64)     20544     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_10 (TimeDi  (None, None, 16, 64)     20544     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_11 (TimeDi  (None, None, 16, 64)     0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_12 (TimeDi  (None, None, 8, 64)      0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_13 (TimeDi  (None, None, 512)        0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               245200    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               12928     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 20)                2580      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 340,836\n",
            "Trainable params: 340,836\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit network\n",
        "history = model2.fit(X_training, y_training, epochs=200, verbose=True, validation_data=(X_validation, y_validation), batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzPAA4P83LR0",
        "outputId": "f8c01e56-2234-4c02-c594-fc9dca8113cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "278/278 [==============================] - 49s 166ms/step - loss: 1.0132 - accuracy: 0.6860 - val_loss: 0.2890 - val_accuracy: 0.9170\n",
            "Epoch 2/200\n",
            "278/278 [==============================] - 47s 168ms/step - loss: 0.2873 - accuracy: 0.9196 - val_loss: 0.1612 - val_accuracy: 0.9565\n",
            "Epoch 3/200\n",
            "278/278 [==============================] - 47s 167ms/step - loss: 0.1933 - accuracy: 0.9444 - val_loss: 0.1188 - val_accuracy: 0.9674\n",
            "Epoch 4/200\n",
            "278/278 [==============================] - 46s 165ms/step - loss: 0.1501 - accuracy: 0.9582 - val_loss: 0.0990 - val_accuracy: 0.9709\n",
            "Epoch 5/200\n",
            "278/278 [==============================] - 46s 166ms/step - loss: 0.1253 - accuracy: 0.9641 - val_loss: 0.1084 - val_accuracy: 0.9684\n",
            "Epoch 6/200\n",
            "278/278 [==============================] - 46s 166ms/step - loss: 0.1020 - accuracy: 0.9703 - val_loss: 0.0841 - val_accuracy: 0.9751\n",
            "Epoch 7/200\n",
            "278/278 [==============================] - 46s 166ms/step - loss: 0.0913 - accuracy: 0.9734 - val_loss: 0.0788 - val_accuracy: 0.9789\n",
            "Epoch 8/200\n",
            "278/278 [==============================] - 46s 167ms/step - loss: 0.0826 - accuracy: 0.9756 - val_loss: 0.0853 - val_accuracy: 0.9762\n",
            "Epoch 9/200\n",
            "278/278 [==============================] - 47s 169ms/step - loss: 0.0799 - accuracy: 0.9763 - val_loss: 0.0655 - val_accuracy: 0.9811\n",
            "Epoch 10/200\n",
            "278/278 [==============================] - 47s 168ms/step - loss: 0.0688 - accuracy: 0.9792 - val_loss: 0.0751 - val_accuracy: 0.9793\n",
            "Epoch 11/200\n",
            "278/278 [==============================] - 46s 166ms/step - loss: 0.0660 - accuracy: 0.9801 - val_loss: 0.0652 - val_accuracy: 0.9812\n",
            "Epoch 12/200\n",
            "278/278 [==============================] - 46s 166ms/step - loss: 0.0615 - accuracy: 0.9807 - val_loss: 0.0551 - val_accuracy: 0.9840\n",
            "Epoch 13/200\n",
            "278/278 [==============================] - 47s 168ms/step - loss: 0.0614 - accuracy: 0.9816 - val_loss: 0.0835 - val_accuracy: 0.9786\n",
            "Epoch 14/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0522 - accuracy: 0.9839 - val_loss: 0.0648 - val_accuracy: 0.9815\n",
            "Epoch 15/200\n",
            "278/278 [==============================] - 48s 174ms/step - loss: 0.0501 - accuracy: 0.9842 - val_loss: 0.0529 - val_accuracy: 0.9847\n",
            "Epoch 16/200\n",
            "278/278 [==============================] - 49s 175ms/step - loss: 0.0469 - accuracy: 0.9858 - val_loss: 0.0551 - val_accuracy: 0.9851\n",
            "Epoch 17/200\n",
            "278/278 [==============================] - 48s 172ms/step - loss: 0.0471 - accuracy: 0.9855 - val_loss: 0.0446 - val_accuracy: 0.9876\n",
            "Epoch 18/200\n",
            "278/278 [==============================] - 48s 171ms/step - loss: 0.0431 - accuracy: 0.9865 - val_loss: 0.0514 - val_accuracy: 0.9866\n",
            "Epoch 19/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0409 - accuracy: 0.9866 - val_loss: 0.0584 - val_accuracy: 0.9834\n",
            "Epoch 20/200\n",
            "278/278 [==============================] - 47s 168ms/step - loss: 0.0478 - accuracy: 0.9857 - val_loss: 0.0537 - val_accuracy: 0.9853\n",
            "Epoch 21/200\n",
            "278/278 [==============================] - 47s 167ms/step - loss: 0.0380 - accuracy: 0.9881 - val_loss: 0.0416 - val_accuracy: 0.9887\n",
            "Epoch 22/200\n",
            "278/278 [==============================] - 48s 171ms/step - loss: 0.0428 - accuracy: 0.9877 - val_loss: 0.0501 - val_accuracy: 0.9876\n",
            "Epoch 23/200\n",
            "278/278 [==============================] - 47s 167ms/step - loss: 0.0338 - accuracy: 0.9896 - val_loss: 0.0466 - val_accuracy: 0.9871\n",
            "Epoch 24/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0316 - accuracy: 0.9901 - val_loss: 0.0565 - val_accuracy: 0.9859\n",
            "Epoch 25/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0363 - accuracy: 0.9891 - val_loss: 0.0467 - val_accuracy: 0.9866\n",
            "Epoch 26/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0329 - accuracy: 0.9896 - val_loss: 0.0471 - val_accuracy: 0.9876\n",
            "Epoch 27/200\n",
            "278/278 [==============================] - 47s 169ms/step - loss: 0.0334 - accuracy: 0.9900 - val_loss: 0.0510 - val_accuracy: 0.9855\n",
            "Epoch 28/200\n",
            "278/278 [==============================] - 47s 168ms/step - loss: 0.0317 - accuracy: 0.9895 - val_loss: 0.0550 - val_accuracy: 0.9873\n",
            "Epoch 29/200\n",
            "278/278 [==============================] - 49s 176ms/step - loss: 0.0256 - accuracy: 0.9920 - val_loss: 0.0458 - val_accuracy: 0.9889\n",
            "Epoch 30/200\n",
            "278/278 [==============================] - 46s 166ms/step - loss: 0.0255 - accuracy: 0.9922 - val_loss: 0.0550 - val_accuracy: 0.9864\n",
            "Epoch 31/200\n",
            "278/278 [==============================] - 46s 167ms/step - loss: 0.0322 - accuracy: 0.9897 - val_loss: 0.0619 - val_accuracy: 0.9843\n",
            "Epoch 32/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0315 - accuracy: 0.9906 - val_loss: 0.0408 - val_accuracy: 0.9894\n",
            "Epoch 33/200\n",
            "278/278 [==============================] - 46s 167ms/step - loss: 0.0328 - accuracy: 0.9902 - val_loss: 0.0426 - val_accuracy: 0.9892\n",
            "Epoch 34/200\n",
            "278/278 [==============================] - 47s 168ms/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 0.0457 - val_accuracy: 0.9876\n",
            "Epoch 35/200\n",
            "278/278 [==============================] - 46s 167ms/step - loss: 0.0305 - accuracy: 0.9904 - val_loss: 0.0432 - val_accuracy: 0.9883\n",
            "Epoch 36/200\n",
            "278/278 [==============================] - 46s 166ms/step - loss: 0.0222 - accuracy: 0.9932 - val_loss: 0.0514 - val_accuracy: 0.9882\n",
            "Epoch 37/200\n",
            "278/278 [==============================] - 47s 167ms/step - loss: 0.0276 - accuracy: 0.9915 - val_loss: 0.0450 - val_accuracy: 0.9886\n",
            "Epoch 38/200\n",
            "278/278 [==============================] - 46s 167ms/step - loss: 0.0256 - accuracy: 0.9928 - val_loss: 0.0464 - val_accuracy: 0.9885\n",
            "Epoch 39/200\n",
            "278/278 [==============================] - 46s 167ms/step - loss: 0.0230 - accuracy: 0.9932 - val_loss: 0.0503 - val_accuracy: 0.9878\n",
            "Epoch 40/200\n",
            "278/278 [==============================] - 47s 168ms/step - loss: 0.0261 - accuracy: 0.9925 - val_loss: 0.0477 - val_accuracy: 0.9879\n",
            "Epoch 41/200\n",
            "278/278 [==============================] - 47s 169ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.0388 - val_accuracy: 0.9902\n",
            "Epoch 42/200\n",
            "278/278 [==============================] - 47s 169ms/step - loss: 0.0222 - accuracy: 0.9932 - val_loss: 0.0455 - val_accuracy: 0.9892\n",
            "Epoch 43/200\n",
            "278/278 [==============================] - 47s 169ms/step - loss: 0.0295 - accuracy: 0.9907 - val_loss: 0.0402 - val_accuracy: 0.9894\n",
            "Epoch 44/200\n",
            "278/278 [==============================] - 47s 169ms/step - loss: 0.0243 - accuracy: 0.9926 - val_loss: 0.0452 - val_accuracy: 0.9887\n",
            "Epoch 45/200\n",
            "278/278 [==============================] - 47s 168ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.0413 - val_accuracy: 0.9905\n",
            "Epoch 46/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.0480 - val_accuracy: 0.9885\n",
            "Epoch 47/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0215 - accuracy: 0.9930 - val_loss: 0.0482 - val_accuracy: 0.9895\n",
            "Epoch 48/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0259 - accuracy: 0.9922 - val_loss: 0.0443 - val_accuracy: 0.9892\n",
            "Epoch 49/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0257 - accuracy: 0.9925 - val_loss: 0.0582 - val_accuracy: 0.9878\n",
            "Epoch 50/200\n",
            "278/278 [==============================] - 48s 171ms/step - loss: 0.0169 - accuracy: 0.9946 - val_loss: 0.0423 - val_accuracy: 0.9900\n",
            "Epoch 51/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.0471 - val_accuracy: 0.9894\n",
            "Epoch 52/200\n",
            "278/278 [==============================] - 47s 169ms/step - loss: 0.0210 - accuracy: 0.9935 - val_loss: 0.0410 - val_accuracy: 0.9902\n",
            "Epoch 53/200\n",
            "278/278 [==============================] - 47s 171ms/step - loss: 0.0232 - accuracy: 0.9929 - val_loss: 0.0546 - val_accuracy: 0.9870\n",
            "Epoch 54/200\n",
            "278/278 [==============================] - 49s 175ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.0420 - val_accuracy: 0.9909\n",
            "Epoch 55/200\n",
            "278/278 [==============================] - 48s 171ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.0426 - val_accuracy: 0.9902\n",
            "Epoch 56/200\n",
            "278/278 [==============================] - 47s 168ms/step - loss: 0.0213 - accuracy: 0.9934 - val_loss: 0.0419 - val_accuracy: 0.9894\n",
            "Epoch 57/200\n",
            "278/278 [==============================] - 47s 169ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.0397 - val_accuracy: 0.9906\n",
            "Epoch 58/200\n",
            "278/278 [==============================] - 47s 169ms/step - loss: 0.0195 - accuracy: 0.9936 - val_loss: 0.0423 - val_accuracy: 0.9893\n",
            "Epoch 59/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0192 - accuracy: 0.9945 - val_loss: 0.0467 - val_accuracy: 0.9896\n",
            "Epoch 60/200\n",
            "278/278 [==============================] - 47s 171ms/step - loss: 0.0210 - accuracy: 0.9937 - val_loss: 0.0478 - val_accuracy: 0.9895\n",
            "Epoch 61/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.0443 - val_accuracy: 0.9905\n",
            "Epoch 62/200\n",
            "278/278 [==============================] - 47s 169ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0490 - val_accuracy: 0.9902\n",
            "Epoch 63/200\n",
            "278/278 [==============================] - 47s 169ms/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.0527 - val_accuracy: 0.9887\n",
            "Epoch 64/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.0488 - val_accuracy: 0.9895\n",
            "Epoch 65/200\n",
            "278/278 [==============================] - 47s 167ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.0429 - val_accuracy: 0.9906\n",
            "Epoch 66/200\n",
            "278/278 [==============================] - 47s 168ms/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 0.0509 - val_accuracy: 0.9883\n",
            "Epoch 67/200\n",
            "278/278 [==============================] - 47s 168ms/step - loss: 0.0187 - accuracy: 0.9944 - val_loss: 0.0542 - val_accuracy: 0.9869\n",
            "Epoch 68/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.0646 - val_accuracy: 0.9862\n",
            "Epoch 69/200\n",
            "278/278 [==============================] - 47s 169ms/step - loss: 0.0190 - accuracy: 0.9941 - val_loss: 0.0387 - val_accuracy: 0.9908\n",
            "Epoch 70/200\n",
            "278/278 [==============================] - 47s 168ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.0433 - val_accuracy: 0.9897\n",
            "Epoch 71/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.0420 - val_accuracy: 0.9908\n",
            "Epoch 72/200\n",
            "278/278 [==============================] - 47s 168ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.0519 - val_accuracy: 0.9886\n",
            "Epoch 73/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 0.0491 - val_accuracy: 0.9892\n",
            "Epoch 74/200\n",
            "278/278 [==============================] - 48s 171ms/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 0.0492 - val_accuracy: 0.9887\n",
            "Epoch 75/200\n",
            "278/278 [==============================] - 48s 171ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.0493 - val_accuracy: 0.9905\n",
            "Epoch 76/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0168 - accuracy: 0.9950 - val_loss: 0.0397 - val_accuracy: 0.9908\n",
            "Epoch 77/200\n",
            "278/278 [==============================] - 47s 169ms/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 0.0381 - val_accuracy: 0.9909\n",
            "Epoch 78/200\n",
            "278/278 [==============================] - 47s 171ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.0532 - val_accuracy: 0.9892\n",
            "Epoch 79/200\n",
            "278/278 [==============================] - 47s 169ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.0470 - val_accuracy: 0.9897\n",
            "Epoch 80/200\n",
            "278/278 [==============================] - 48s 171ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.0450 - val_accuracy: 0.9896\n",
            "Epoch 81/200\n",
            "278/278 [==============================] - 48s 171ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.0535 - val_accuracy: 0.9888\n",
            "Epoch 82/200\n",
            "278/278 [==============================] - 48s 171ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.0524 - val_accuracy: 0.9878\n",
            "Epoch 83/200\n",
            "278/278 [==============================] - 48s 171ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.0506 - val_accuracy: 0.9893\n",
            "Epoch 84/200\n",
            "278/278 [==============================] - 47s 171ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.0430 - val_accuracy: 0.9911\n",
            "Epoch 85/200\n",
            "278/278 [==============================] - 48s 172ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.0433 - val_accuracy: 0.9909\n",
            "Epoch 86/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.0489 - val_accuracy: 0.9897\n",
            "Epoch 87/200\n",
            "278/278 [==============================] - 48s 172ms/step - loss: 0.0199 - accuracy: 0.9945 - val_loss: 0.0593 - val_accuracy: 0.9882\n",
            "Epoch 88/200\n",
            "278/278 [==============================] - 48s 171ms/step - loss: 0.0195 - accuracy: 0.9946 - val_loss: 0.0484 - val_accuracy: 0.9897\n",
            "Epoch 89/200\n",
            "278/278 [==============================] - 47s 171ms/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 0.0532 - val_accuracy: 0.9887\n",
            "Epoch 90/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.0487 - val_accuracy: 0.9901\n",
            "Epoch 91/200\n",
            "278/278 [==============================] - 47s 169ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.0495 - val_accuracy: 0.9896\n",
            "Epoch 92/200\n",
            "278/278 [==============================] - 47s 171ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0471 - val_accuracy: 0.9891\n",
            "Epoch 93/200\n",
            "278/278 [==============================] - 48s 171ms/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.0524 - val_accuracy: 0.9897\n",
            "Epoch 94/200\n",
            "278/278 [==============================] - 47s 169ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.0791 - val_accuracy: 0.9860\n",
            "Epoch 95/200\n",
            "278/278 [==============================] - 47s 169ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.0493 - val_accuracy: 0.9901\n",
            "Epoch 96/200\n",
            "278/278 [==============================] - 48s 171ms/step - loss: 0.0176 - accuracy: 0.9949 - val_loss: 0.0488 - val_accuracy: 0.9901\n",
            "Epoch 97/200\n",
            "278/278 [==============================] - 48s 171ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.0441 - val_accuracy: 0.9900\n",
            "Epoch 98/200\n",
            "278/278 [==============================] - 48s 171ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.0440 - val_accuracy: 0.9905\n",
            "Epoch 99/200\n",
            "278/278 [==============================] - 47s 171ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.0519 - val_accuracy: 0.9892\n",
            "Epoch 100/200\n",
            "278/278 [==============================] - 48s 172ms/step - loss: 0.0300 - accuracy: 0.9913 - val_loss: 0.0518 - val_accuracy: 0.9901\n",
            "Epoch 101/200\n",
            "278/278 [==============================] - 48s 172ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.0429 - val_accuracy: 0.9904\n",
            "Epoch 102/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.0508 - val_accuracy: 0.9895\n",
            "Epoch 103/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.0479 - val_accuracy: 0.9902\n",
            "Epoch 104/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.0499 - val_accuracy: 0.9900\n",
            "Epoch 105/200\n",
            "278/278 [==============================] - 48s 172ms/step - loss: 0.0170 - accuracy: 0.9950 - val_loss: 0.0437 - val_accuracy: 0.9915\n",
            "Epoch 106/200\n",
            "278/278 [==============================] - 48s 172ms/step - loss: 0.0125 - accuracy: 0.9966 - val_loss: 0.0411 - val_accuracy: 0.9910\n",
            "Epoch 107/200\n",
            "278/278 [==============================] - 47s 171ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.0426 - val_accuracy: 0.9911\n",
            "Epoch 108/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.0522 - val_accuracy: 0.9903\n",
            "Epoch 109/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0171 - accuracy: 0.9952 - val_loss: 0.0468 - val_accuracy: 0.9910\n",
            "Epoch 110/200\n",
            "278/278 [==============================] - 48s 174ms/step - loss: 0.0141 - accuracy: 0.9960 - val_loss: 0.0411 - val_accuracy: 0.9914\n",
            "Epoch 111/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.0529 - val_accuracy: 0.9895\n",
            "Epoch 112/200\n",
            "278/278 [==============================] - 48s 174ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.0535 - val_accuracy: 0.9903\n",
            "Epoch 113/200\n",
            "278/278 [==============================] - 49s 175ms/step - loss: 0.0192 - accuracy: 0.9947 - val_loss: 0.0526 - val_accuracy: 0.9895\n",
            "Epoch 114/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 0.0550 - val_accuracy: 0.9889\n",
            "Epoch 115/200\n",
            "278/278 [==============================] - 48s 172ms/step - loss: 0.0189 - accuracy: 0.9950 - val_loss: 0.0553 - val_accuracy: 0.9879\n",
            "Epoch 116/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0149 - accuracy: 0.9959 - val_loss: 0.0434 - val_accuracy: 0.9906\n",
            "Epoch 117/200\n",
            "278/278 [==============================] - 48s 172ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0408 - val_accuracy: 0.9910\n",
            "Epoch 118/200\n",
            "278/278 [==============================] - 48s 172ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.0448 - val_accuracy: 0.9909\n",
            "Epoch 119/200\n",
            "278/278 [==============================] - 48s 171ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 0.0494 - val_accuracy: 0.9896\n",
            "Epoch 120/200\n",
            "278/278 [==============================] - 48s 172ms/step - loss: 0.0193 - accuracy: 0.9946 - val_loss: 0.0566 - val_accuracy: 0.9896\n",
            "Epoch 121/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0192 - accuracy: 0.9943 - val_loss: 0.0425 - val_accuracy: 0.9908\n",
            "Epoch 122/200\n",
            "278/278 [==============================] - 47s 171ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0493 - val_accuracy: 0.9914\n",
            "Epoch 123/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 0.0465 - val_accuracy: 0.9903\n",
            "Epoch 124/200\n",
            "278/278 [==============================] - 47s 171ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.0474 - val_accuracy: 0.9914\n",
            "Epoch 125/200\n",
            "278/278 [==============================] - 48s 172ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.0455 - val_accuracy: 0.9910\n",
            "Epoch 126/200\n",
            "278/278 [==============================] - 48s 172ms/step - loss: 0.0176 - accuracy: 0.9951 - val_loss: 0.0453 - val_accuracy: 0.9903\n",
            "Epoch 127/200\n",
            "278/278 [==============================] - 48s 172ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.0476 - val_accuracy: 0.9893\n",
            "Epoch 128/200\n",
            "278/278 [==============================] - 47s 171ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.0484 - val_accuracy: 0.9902\n",
            "Epoch 129/200\n",
            "278/278 [==============================] - 48s 172ms/step - loss: 0.0149 - accuracy: 0.9959 - val_loss: 0.0436 - val_accuracy: 0.9911\n",
            "Epoch 130/200\n",
            "278/278 [==============================] - 47s 171ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.0430 - val_accuracy: 0.9910\n",
            "Epoch 131/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.0453 - val_accuracy: 0.9915\n",
            "Epoch 132/200\n",
            "278/278 [==============================] - 48s 171ms/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 0.0444 - val_accuracy: 0.9904\n",
            "Epoch 133/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.0440 - val_accuracy: 0.9912\n",
            "Epoch 134/200\n",
            "278/278 [==============================] - 47s 170ms/step - loss: 0.0137 - accuracy: 0.9955 - val_loss: 0.0574 - val_accuracy: 0.9896\n",
            "Epoch 135/200\n",
            "278/278 [==============================] - 48s 171ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.0557 - val_accuracy: 0.9897\n",
            "Epoch 136/200\n",
            "278/278 [==============================] - 47s 171ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.0440 - val_accuracy: 0.9911\n",
            "Epoch 137/200\n",
            "278/278 [==============================] - 48s 171ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.0579 - val_accuracy: 0.9892\n",
            "Epoch 138/200\n",
            "278/278 [==============================] - 48s 171ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.0503 - val_accuracy: 0.9903\n",
            "Epoch 139/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 0.0544 - val_accuracy: 0.9900\n",
            "Epoch 140/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0179 - accuracy: 0.9948 - val_loss: 0.0557 - val_accuracy: 0.9892\n",
            "Epoch 141/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 0.0450 - val_accuracy: 0.9910\n",
            "Epoch 142/200\n",
            "278/278 [==============================] - 48s 174ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.0487 - val_accuracy: 0.9899\n",
            "Epoch 143/200\n",
            "278/278 [==============================] - 48s 174ms/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.0427 - val_accuracy: 0.9914\n",
            "Epoch 144/200\n",
            "278/278 [==============================] - 49s 175ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0573 - val_accuracy: 0.9888\n",
            "Epoch 145/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0157 - accuracy: 0.9956 - val_loss: 0.0516 - val_accuracy: 0.9897\n",
            "Epoch 146/200\n",
            "278/278 [==============================] - 48s 174ms/step - loss: 0.0174 - accuracy: 0.9950 - val_loss: 0.0509 - val_accuracy: 0.9903\n",
            "Epoch 147/200\n",
            "278/278 [==============================] - 48s 174ms/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.0539 - val_accuracy: 0.9894\n",
            "Epoch 148/200\n",
            "278/278 [==============================] - 48s 174ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.0424 - val_accuracy: 0.9910\n",
            "Epoch 149/200\n",
            "278/278 [==============================] - 48s 172ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0693 - val_accuracy: 0.9875\n",
            "Epoch 150/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.0535 - val_accuracy: 0.9889\n",
            "Epoch 151/200\n",
            "278/278 [==============================] - 49s 175ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.0545 - val_accuracy: 0.9900\n",
            "Epoch 152/200\n",
            "278/278 [==============================] - 48s 172ms/step - loss: 0.0184 - accuracy: 0.9948 - val_loss: 0.0507 - val_accuracy: 0.9905\n",
            "Epoch 153/200\n",
            "278/278 [==============================] - 48s 172ms/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.0448 - val_accuracy: 0.9920\n",
            "Epoch 154/200\n",
            "278/278 [==============================] - 48s 172ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.0514 - val_accuracy: 0.9903\n",
            "Epoch 155/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.0491 - val_accuracy: 0.9901\n",
            "Epoch 156/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 0.0470 - val_accuracy: 0.9910\n",
            "Epoch 157/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0212 - accuracy: 0.9940 - val_loss: 0.0503 - val_accuracy: 0.9891\n",
            "Epoch 158/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0159 - accuracy: 0.9955 - val_loss: 0.0436 - val_accuracy: 0.9904\n",
            "Epoch 159/200\n",
            "278/278 [==============================] - 48s 174ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 0.0529 - val_accuracy: 0.9906\n",
            "Epoch 160/200\n",
            "278/278 [==============================] - 49s 175ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.0421 - val_accuracy: 0.9913\n",
            "Epoch 161/200\n",
            "278/278 [==============================] - 48s 174ms/step - loss: 0.0164 - accuracy: 0.9951 - val_loss: 0.0511 - val_accuracy: 0.9910\n",
            "Epoch 162/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.0452 - val_accuracy: 0.9903\n",
            "Epoch 163/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.0465 - val_accuracy: 0.9914\n",
            "Epoch 164/200\n",
            "278/278 [==============================] - 49s 175ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.0520 - val_accuracy: 0.9899\n",
            "Epoch 165/200\n",
            "278/278 [==============================] - 49s 176ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.0616 - val_accuracy: 0.9891\n",
            "Epoch 166/200\n",
            "278/278 [==============================] - 48s 174ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.0589 - val_accuracy: 0.9903\n",
            "Epoch 167/200\n",
            "278/278 [==============================] - 49s 176ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 0.0645 - val_accuracy: 0.9900\n",
            "Epoch 168/200\n",
            "278/278 [==============================] - 49s 175ms/step - loss: 0.0098 - accuracy: 0.9973 - val_loss: 0.0500 - val_accuracy: 0.9906\n",
            "Epoch 169/200\n",
            "278/278 [==============================] - 48s 172ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.0409 - val_accuracy: 0.9913\n",
            "Epoch 170/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.0526 - val_accuracy: 0.9901\n",
            "Epoch 171/200\n",
            "278/278 [==============================] - 48s 174ms/step - loss: 0.0217 - accuracy: 0.9938 - val_loss: 0.0605 - val_accuracy: 0.9875\n",
            "Epoch 172/200\n",
            "278/278 [==============================] - 49s 175ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.0464 - val_accuracy: 0.9904\n",
            "Epoch 173/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0185 - accuracy: 0.9946 - val_loss: 0.0567 - val_accuracy: 0.9892\n",
            "Epoch 174/200\n",
            "278/278 [==============================] - 49s 175ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.0499 - val_accuracy: 0.9896\n",
            "Epoch 175/200\n",
            "278/278 [==============================] - 48s 172ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.0482 - val_accuracy: 0.9912\n",
            "Epoch 176/200\n",
            "278/278 [==============================] - 48s 174ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 0.0396 - val_accuracy: 0.9911\n",
            "Epoch 177/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.0408 - val_accuracy: 0.9911\n",
            "Epoch 178/200\n",
            "278/278 [==============================] - 48s 172ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.0467 - val_accuracy: 0.9915\n",
            "Epoch 179/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0217 - accuracy: 0.9941 - val_loss: 0.0503 - val_accuracy: 0.9886\n",
            "Epoch 180/200\n",
            "278/278 [==============================] - 49s 175ms/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.0454 - val_accuracy: 0.9904\n",
            "Epoch 181/200\n",
            "278/278 [==============================] - 49s 176ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.0621 - val_accuracy: 0.9896\n",
            "Epoch 182/200\n",
            "278/278 [==============================] - 48s 171ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.0479 - val_accuracy: 0.9906\n",
            "Epoch 183/200\n",
            "278/278 [==============================] - 49s 175ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.0555 - val_accuracy: 0.9908\n",
            "Epoch 184/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 0.0447 - val_accuracy: 0.9913\n",
            "Epoch 185/200\n",
            "278/278 [==============================] - 48s 174ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.0489 - val_accuracy: 0.9910\n",
            "Epoch 186/200\n",
            "278/278 [==============================] - 49s 176ms/step - loss: 0.0166 - accuracy: 0.9950 - val_loss: 0.0428 - val_accuracy: 0.9910\n",
            "Epoch 187/200\n",
            "278/278 [==============================] - 48s 174ms/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 0.0508 - val_accuracy: 0.9889\n",
            "Epoch 188/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.0522 - val_accuracy: 0.9894\n",
            "Epoch 189/200\n",
            "278/278 [==============================] - 49s 175ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.0447 - val_accuracy: 0.9906\n",
            "Epoch 190/200\n",
            "278/278 [==============================] - 48s 174ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.0493 - val_accuracy: 0.9902\n",
            "Epoch 191/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.0503 - val_accuracy: 0.9902\n",
            "Epoch 192/200\n",
            "278/278 [==============================] - 48s 174ms/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 0.0474 - val_accuracy: 0.9911\n",
            "Epoch 193/200\n",
            "278/278 [==============================] - 48s 174ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.0472 - val_accuracy: 0.9914\n",
            "Epoch 194/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0127 - accuracy: 0.9964 - val_loss: 0.0492 - val_accuracy: 0.9911\n",
            "Epoch 195/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0183 - accuracy: 0.9944 - val_loss: 0.0447 - val_accuracy: 0.9912\n",
            "Epoch 196/200\n",
            "278/278 [==============================] - 48s 172ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 0.0511 - val_accuracy: 0.9910\n",
            "Epoch 197/200\n",
            "278/278 [==============================] - 49s 176ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.0587 - val_accuracy: 0.9897\n",
            "Epoch 198/200\n",
            "278/278 [==============================] - 49s 175ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.0418 - val_accuracy: 0.9926\n",
            "Epoch 199/200\n",
            "278/278 [==============================] - 49s 175ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.0486 - val_accuracy: 0.9905\n",
            "Epoch 200/200\n",
            "278/278 [==============================] - 48s 173ms/step - loss: 0.0163 - accuracy: 0.9955 - val_loss: 0.0565 - val_accuracy: 0.9899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "loss, accuracy = model2.evaluate(X_validation, y_validation, verbose=False)\n",
        "print(\"Validation Accuracy:  {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model2.evaluate(x_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy: {:.4f}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-opKeVI3Wy3",
        "outputId": "973154ff-88a9-4737-f3d4-8ca40c806fd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy:  0.9899\n",
            "Testing Accuracy: 0.9577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tbrerHld3aQ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN+LSTM_D1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuJ7zPRn7lDh",
        "outputId": "20389606-34b5-4b5e-a5b4-25c37fed586d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Mounted at /content/gdrive\n",
            "(33104, 128, 6) (33104, 118) (3740, 128, 6) (3740, 118)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/'  #change dir to your project folder\n",
        "\n",
        "import numpy as np\n",
        "x_train = np.load('gdrive/My Drive/D1/trainX.npy')\n",
        "y_train = np.load('gdrive/My Drive/D1/trainy.npy')\n",
        "x_test = np.load('gdrive/My Drive/D1/testX.npy')\n",
        "y_test = np.load('gdrive/My Drive/D1/testy.npy')\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "from numpy import save, load\n",
        "from tensorflow import keras\n",
        "from pandas import read_csv\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras import Model\n",
        "from keras.layers import LSTM, Conv1D, concatenate,GlobalMaxPooling1D,TimeDistributed, MaxPooling1D\n",
        "# from keras.utils import to_categorical\n",
        "from matplotlib import pyplot\n",
        "from keras import regularizers\n",
        "import tensorflow as tfs"
      ],
      "metadata": {
        "id": "URLFkLBN7zAC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape data into time steps of sub-sequences\n",
        "n_timesteps, n_features, n_outputs = x_train.shape[1], x_train.shape[2], y_train.shape[1]\n",
        "n_steps, n_length = 4, 32\n",
        "x_train = x_train.reshape((x_train.shape[0], n_steps, n_length, n_features))\n",
        "x_test = x_test.reshape((x_test.shape[0], n_steps, n_length, n_features))"
      ],
      "metadata": {
        "id": "Kaq2qtuZ7_V9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_training, X_validation, y_training, y_validation = train_test_split(x_train, y_train, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "u8WJHqC88CU2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "model2.add(TimeDistributed(Conv1D(filters=64, kernel_size=5, activation='relu'), input_shape=(None,n_length,n_features)))\n",
        "model2.add(TimeDistributed(Conv1D(filters=64, kernel_size=5, activation='relu')))\n",
        "model2.add(TimeDistributed(Conv1D(filters=64, kernel_size=5, activation='relu')))\n",
        "model2.add(TimeDistributed(Conv1D(filters=64, kernel_size=5, activation='relu')))\n",
        "model2.add(TimeDistributed(Dropout(0.5)))\n",
        "model2.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
        "model2.add(TimeDistributed(Flatten()))\n",
        "model2.add(LSTM(100))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Dense(128, activation='relu'))\n",
        "model2.add(Dense(128, activation='relu'))\n",
        "model2.add(Dense(n_outputs, activation='softmax'))\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model2.summary()\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drI1dvHx8XlJ",
        "outputId": "549c32d2-4a44-42ec-cfa5-169094afa06c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed (TimeDistr  (None, None, 28, 64)     1984      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, None, 24, 64)     20544     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, None, 20, 64)     20544     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDis  (None, None, 16, 64)     20544     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDis  (None, None, 16, 64)     0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_5 (TimeDis  (None, None, 8, 64)      0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_6 (TimeDis  (None, None, 512)        0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               245200    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               12928     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 118)               15222     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353,478\n",
            "Trainable params: 353,478\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit network\n",
        "history = model2.fit(X_training, y_training, epochs=200, verbose=True, validation_data=(X_validation, y_validation), batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq00Zn4S8a4l",
        "outputId": "d07256fd-66ea-41a9-ef9a-d1b0a1b81a1e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "207/207 [==============================] - 46s 202ms/step - loss: 3.0955 - accuracy: 0.2199 - val_loss: 1.7564 - val_accuracy: 0.5264\n",
            "Epoch 2/200\n",
            "207/207 [==============================] - 42s 203ms/step - loss: 1.4998 - accuracy: 0.5775 - val_loss: 0.8630 - val_accuracy: 0.7608\n",
            "Epoch 3/200\n",
            "207/207 [==============================] - 43s 210ms/step - loss: 0.9694 - accuracy: 0.7344 - val_loss: 0.5477 - val_accuracy: 0.8565\n",
            "Epoch 4/200\n",
            "207/207 [==============================] - 42s 201ms/step - loss: 0.7248 - accuracy: 0.8033 - val_loss: 0.4436 - val_accuracy: 0.8817\n",
            "Epoch 5/200\n",
            "207/207 [==============================] - 42s 202ms/step - loss: 0.6067 - accuracy: 0.8311 - val_loss: 0.3771 - val_accuracy: 0.8888\n",
            "Epoch 6/200\n",
            "207/207 [==============================] - 43s 206ms/step - loss: 0.5136 - accuracy: 0.8576 - val_loss: 0.3870 - val_accuracy: 0.8872\n",
            "Epoch 7/200\n",
            "207/207 [==============================] - 42s 202ms/step - loss: 0.4707 - accuracy: 0.8643 - val_loss: 0.3162 - val_accuracy: 0.9100\n",
            "Epoch 8/200\n",
            "207/207 [==============================] - 41s 200ms/step - loss: 0.4172 - accuracy: 0.8797 - val_loss: 0.2765 - val_accuracy: 0.9213\n",
            "Epoch 9/200\n",
            "207/207 [==============================] - 43s 210ms/step - loss: 0.3773 - accuracy: 0.8911 - val_loss: 0.2676 - val_accuracy: 0.9219\n",
            "Epoch 10/200\n",
            "207/207 [==============================] - 42s 202ms/step - loss: 0.3566 - accuracy: 0.8967 - val_loss: 0.2669 - val_accuracy: 0.9261\n",
            "Epoch 11/200\n",
            "207/207 [==============================] - 46s 223ms/step - loss: 0.3331 - accuracy: 0.9036 - val_loss: 0.2249 - val_accuracy: 0.9385\n",
            "Epoch 12/200\n",
            "207/207 [==============================] - 50s 241ms/step - loss: 0.3043 - accuracy: 0.9106 - val_loss: 0.2243 - val_accuracy: 0.9367\n",
            "Epoch 13/200\n",
            "207/207 [==============================] - 45s 220ms/step - loss: 0.2791 - accuracy: 0.9172 - val_loss: 0.2299 - val_accuracy: 0.9287\n",
            "Epoch 14/200\n",
            "207/207 [==============================] - 46s 221ms/step - loss: 0.2743 - accuracy: 0.9198 - val_loss: 0.2020 - val_accuracy: 0.9440\n",
            "Epoch 15/200\n",
            "207/207 [==============================] - 45s 217ms/step - loss: 0.2529 - accuracy: 0.9256 - val_loss: 0.2032 - val_accuracy: 0.9438\n",
            "Epoch 16/200\n",
            "207/207 [==============================] - 46s 222ms/step - loss: 0.2547 - accuracy: 0.9255 - val_loss: 0.1861 - val_accuracy: 0.9456\n",
            "Epoch 17/200\n",
            "207/207 [==============================] - 45s 218ms/step - loss: 0.2305 - accuracy: 0.9310 - val_loss: 0.1697 - val_accuracy: 0.9545\n",
            "Epoch 18/200\n",
            "207/207 [==============================] - 44s 213ms/step - loss: 0.2209 - accuracy: 0.9338 - val_loss: 0.1763 - val_accuracy: 0.9512\n",
            "Epoch 19/200\n",
            "207/207 [==============================] - 46s 221ms/step - loss: 0.2119 - accuracy: 0.9357 - val_loss: 0.1755 - val_accuracy: 0.9508\n",
            "Epoch 20/200\n",
            "207/207 [==============================] - 46s 222ms/step - loss: 0.1991 - accuracy: 0.9398 - val_loss: 0.1723 - val_accuracy: 0.9529\n",
            "Epoch 21/200\n",
            "207/207 [==============================] - 50s 244ms/step - loss: 0.2029 - accuracy: 0.9393 - val_loss: 0.1872 - val_accuracy: 0.9485\n",
            "Epoch 22/200\n",
            "207/207 [==============================] - 47s 225ms/step - loss: 0.1940 - accuracy: 0.9409 - val_loss: 0.1660 - val_accuracy: 0.9529\n",
            "Epoch 23/200\n",
            "207/207 [==============================] - 45s 220ms/step - loss: 0.1871 - accuracy: 0.9427 - val_loss: 0.1650 - val_accuracy: 0.9553\n",
            "Epoch 24/200\n",
            "207/207 [==============================] - 45s 215ms/step - loss: 0.1819 - accuracy: 0.9445 - val_loss: 0.1612 - val_accuracy: 0.9535\n",
            "Epoch 25/200\n",
            "207/207 [==============================] - 50s 239ms/step - loss: 0.1693 - accuracy: 0.9489 - val_loss: 0.1582 - val_accuracy: 0.9567\n",
            "Epoch 26/200\n",
            "207/207 [==============================] - 49s 238ms/step - loss: 0.1680 - accuracy: 0.9485 - val_loss: 0.1973 - val_accuracy: 0.9473\n",
            "Epoch 27/200\n",
            "207/207 [==============================] - 45s 218ms/step - loss: 0.1686 - accuracy: 0.9478 - val_loss: 0.1436 - val_accuracy: 0.9624\n",
            "Epoch 28/200\n",
            "207/207 [==============================] - 42s 202ms/step - loss: 0.1638 - accuracy: 0.9509 - val_loss: 0.1720 - val_accuracy: 0.9529\n",
            "Epoch 29/200\n",
            "207/207 [==============================] - 43s 210ms/step - loss: 0.1698 - accuracy: 0.9483 - val_loss: 0.1642 - val_accuracy: 0.9577\n",
            "Epoch 30/200\n",
            "207/207 [==============================] - 45s 217ms/step - loss: 0.1542 - accuracy: 0.9526 - val_loss: 0.1679 - val_accuracy: 0.9574\n",
            "Epoch 31/200\n",
            "207/207 [==============================] - 42s 203ms/step - loss: 0.1507 - accuracy: 0.9532 - val_loss: 0.1432 - val_accuracy: 0.9610\n",
            "Epoch 32/200\n",
            "207/207 [==============================] - 43s 209ms/step - loss: 0.1433 - accuracy: 0.9568 - val_loss: 0.1562 - val_accuracy: 0.9613\n",
            "Epoch 33/200\n",
            "207/207 [==============================] - 43s 210ms/step - loss: 0.1417 - accuracy: 0.9574 - val_loss: 0.1412 - val_accuracy: 0.9665\n",
            "Epoch 34/200\n",
            "207/207 [==============================] - 46s 223ms/step - loss: 0.1342 - accuracy: 0.9598 - val_loss: 0.1339 - val_accuracy: 0.9630\n",
            "Epoch 35/200\n",
            "207/207 [==============================] - 42s 202ms/step - loss: 0.1330 - accuracy: 0.9588 - val_loss: 0.1428 - val_accuracy: 0.9624\n",
            "Epoch 36/200\n",
            "207/207 [==============================] - 43s 208ms/step - loss: 0.1364 - accuracy: 0.9580 - val_loss: 0.1859 - val_accuracy: 0.9553\n",
            "Epoch 37/200\n",
            "207/207 [==============================] - 45s 217ms/step - loss: 0.1242 - accuracy: 0.9630 - val_loss: 0.1463 - val_accuracy: 0.9634\n",
            "Epoch 38/200\n",
            "207/207 [==============================] - 42s 204ms/step - loss: 0.1406 - accuracy: 0.9568 - val_loss: 0.1551 - val_accuracy: 0.9628\n",
            "Epoch 39/200\n",
            "207/207 [==============================] - 43s 206ms/step - loss: 0.1192 - accuracy: 0.9636 - val_loss: 0.1366 - val_accuracy: 0.9666\n",
            "Epoch 40/200\n",
            "207/207 [==============================] - 44s 215ms/step - loss: 0.1264 - accuracy: 0.9596 - val_loss: 0.1438 - val_accuracy: 0.9639\n",
            "Epoch 41/200\n",
            "207/207 [==============================] - 49s 236ms/step - loss: 0.1240 - accuracy: 0.9611 - val_loss: 0.1384 - val_accuracy: 0.9644\n",
            "Epoch 42/200\n",
            "207/207 [==============================] - 45s 219ms/step - loss: 0.1209 - accuracy: 0.9628 - val_loss: 0.1360 - val_accuracy: 0.9680\n",
            "Epoch 43/200\n",
            "207/207 [==============================] - 47s 226ms/step - loss: 0.1149 - accuracy: 0.9647 - val_loss: 0.1336 - val_accuracy: 0.9677\n",
            "Epoch 44/200\n",
            "207/207 [==============================] - 46s 220ms/step - loss: 0.1057 - accuracy: 0.9682 - val_loss: 0.1326 - val_accuracy: 0.9674\n",
            "Epoch 45/200\n",
            "207/207 [==============================] - 47s 226ms/step - loss: 0.1192 - accuracy: 0.9624 - val_loss: 0.1398 - val_accuracy: 0.9638\n",
            "Epoch 46/200\n",
            "207/207 [==============================] - 51s 247ms/step - loss: 0.1091 - accuracy: 0.9656 - val_loss: 0.1261 - val_accuracy: 0.9695\n",
            "Epoch 47/200\n",
            "207/207 [==============================] - 47s 227ms/step - loss: 0.1077 - accuracy: 0.9670 - val_loss: 0.1370 - val_accuracy: 0.9660\n",
            "Epoch 48/200\n",
            "207/207 [==============================] - 45s 216ms/step - loss: 0.1092 - accuracy: 0.9671 - val_loss: 0.1392 - val_accuracy: 0.9665\n",
            "Epoch 49/200\n",
            "207/207 [==============================] - 42s 203ms/step - loss: 0.1083 - accuracy: 0.9660 - val_loss: 0.1383 - val_accuracy: 0.9677\n",
            "Epoch 50/200\n",
            "207/207 [==============================] - 42s 203ms/step - loss: 0.1086 - accuracy: 0.9663 - val_loss: 0.1243 - val_accuracy: 0.9674\n",
            "Epoch 51/200\n",
            "207/207 [==============================] - 41s 200ms/step - loss: 0.1045 - accuracy: 0.9677 - val_loss: 0.1425 - val_accuracy: 0.9645\n",
            "Epoch 52/200\n",
            "207/207 [==============================] - 42s 204ms/step - loss: 0.0990 - accuracy: 0.9688 - val_loss: 0.1240 - val_accuracy: 0.9701\n",
            "Epoch 53/200\n",
            "207/207 [==============================] - 45s 219ms/step - loss: 0.0907 - accuracy: 0.9725 - val_loss: 0.1183 - val_accuracy: 0.9710\n",
            "Epoch 54/200\n",
            "207/207 [==============================] - 43s 207ms/step - loss: 0.0902 - accuracy: 0.9725 - val_loss: 0.1280 - val_accuracy: 0.9668\n",
            "Epoch 55/200\n",
            "207/207 [==============================] - 42s 204ms/step - loss: 0.0958 - accuracy: 0.9701 - val_loss: 0.1267 - val_accuracy: 0.9675\n",
            "Epoch 56/200\n",
            "207/207 [==============================] - 43s 209ms/step - loss: 0.0953 - accuracy: 0.9717 - val_loss: 0.1304 - val_accuracy: 0.9690\n",
            "Epoch 57/200\n",
            "207/207 [==============================] - 44s 211ms/step - loss: 0.0978 - accuracy: 0.9687 - val_loss: 0.1164 - val_accuracy: 0.9719\n",
            "Epoch 58/200\n",
            "207/207 [==============================] - 44s 215ms/step - loss: 0.0924 - accuracy: 0.9718 - val_loss: 0.1267 - val_accuracy: 0.9693\n",
            "Epoch 59/200\n",
            "207/207 [==============================] - 46s 220ms/step - loss: 0.0847 - accuracy: 0.9730 - val_loss: 0.1445 - val_accuracy: 0.9660\n",
            "Epoch 60/200\n",
            "207/207 [==============================] - 47s 225ms/step - loss: 0.0922 - accuracy: 0.9723 - val_loss: 0.1260 - val_accuracy: 0.9699\n",
            "Epoch 61/200\n",
            "207/207 [==============================] - 45s 218ms/step - loss: 0.0962 - accuracy: 0.9703 - val_loss: 0.1272 - val_accuracy: 0.9710\n",
            "Epoch 62/200\n",
            "207/207 [==============================] - 45s 218ms/step - loss: 0.0979 - accuracy: 0.9700 - val_loss: 0.1265 - val_accuracy: 0.9683\n",
            "Epoch 63/200\n",
            "207/207 [==============================] - 44s 214ms/step - loss: 0.0773 - accuracy: 0.9764 - val_loss: 0.1322 - val_accuracy: 0.9672\n",
            "Epoch 64/200\n",
            "207/207 [==============================] - 42s 201ms/step - loss: 0.0791 - accuracy: 0.9755 - val_loss: 0.1354 - val_accuracy: 0.9672\n",
            "Epoch 65/200\n",
            "207/207 [==============================] - 42s 202ms/step - loss: 0.0909 - accuracy: 0.9721 - val_loss: 0.1156 - val_accuracy: 0.9713\n",
            "Epoch 66/200\n",
            "207/207 [==============================] - 43s 207ms/step - loss: 0.0862 - accuracy: 0.9727 - val_loss: 0.1495 - val_accuracy: 0.9636\n",
            "Epoch 67/200\n",
            "207/207 [==============================] - 43s 208ms/step - loss: 0.0926 - accuracy: 0.9722 - val_loss: 0.1223 - val_accuracy: 0.9696\n",
            "Epoch 68/200\n",
            "207/207 [==============================] - 43s 206ms/step - loss: 0.0774 - accuracy: 0.9755 - val_loss: 0.1321 - val_accuracy: 0.9693\n",
            "Epoch 69/200\n",
            "207/207 [==============================] - 41s 198ms/step - loss: 0.0761 - accuracy: 0.9758 - val_loss: 0.1199 - val_accuracy: 0.9721\n",
            "Epoch 70/200\n",
            "207/207 [==============================] - 40s 194ms/step - loss: 0.0839 - accuracy: 0.9741 - val_loss: 0.1394 - val_accuracy: 0.9669\n",
            "Epoch 71/200\n",
            "207/207 [==============================] - 41s 197ms/step - loss: 0.0863 - accuracy: 0.9738 - val_loss: 0.1204 - val_accuracy: 0.9722\n",
            "Epoch 72/200\n",
            "207/207 [==============================] - 42s 205ms/step - loss: 0.0804 - accuracy: 0.9747 - val_loss: 0.1314 - val_accuracy: 0.9684\n",
            "Epoch 73/200\n",
            "207/207 [==============================] - 40s 195ms/step - loss: 0.0786 - accuracy: 0.9752 - val_loss: 0.1231 - val_accuracy: 0.9710\n",
            "Epoch 74/200\n",
            "207/207 [==============================] - 41s 198ms/step - loss: 0.0832 - accuracy: 0.9736 - val_loss: 0.1271 - val_accuracy: 0.9672\n",
            "Epoch 75/200\n",
            "207/207 [==============================] - 39s 189ms/step - loss: 0.0715 - accuracy: 0.9777 - val_loss: 0.1213 - val_accuracy: 0.9734\n",
            "Epoch 76/200\n",
            "207/207 [==============================] - 40s 193ms/step - loss: 0.0685 - accuracy: 0.9789 - val_loss: 0.1118 - val_accuracy: 0.9719\n",
            "Epoch 77/200\n",
            "207/207 [==============================] - 38s 185ms/step - loss: 0.0861 - accuracy: 0.9730 - val_loss: 0.1254 - val_accuracy: 0.9692\n",
            "Epoch 78/200\n",
            "207/207 [==============================] - 38s 183ms/step - loss: 0.0761 - accuracy: 0.9764 - val_loss: 0.1150 - val_accuracy: 0.9731\n",
            "Epoch 79/200\n",
            "207/207 [==============================] - 38s 184ms/step - loss: 0.0764 - accuracy: 0.9765 - val_loss: 0.1282 - val_accuracy: 0.9686\n",
            "Epoch 80/200\n",
            "207/207 [==============================] - 39s 186ms/step - loss: 0.0724 - accuracy: 0.9775 - val_loss: 0.1168 - val_accuracy: 0.9721\n",
            "Epoch 81/200\n",
            "207/207 [==============================] - 41s 196ms/step - loss: 0.0727 - accuracy: 0.9768 - val_loss: 0.1162 - val_accuracy: 0.9725\n",
            "Epoch 82/200\n",
            "207/207 [==============================] - 38s 185ms/step - loss: 0.0738 - accuracy: 0.9767 - val_loss: 0.1275 - val_accuracy: 0.9692\n",
            "Epoch 83/200\n",
            "207/207 [==============================] - 42s 204ms/step - loss: 0.0726 - accuracy: 0.9768 - val_loss: 0.1229 - val_accuracy: 0.9712\n",
            "Epoch 84/200\n",
            "207/207 [==============================] - 42s 203ms/step - loss: 0.0696 - accuracy: 0.9775 - val_loss: 0.1165 - val_accuracy: 0.9740\n",
            "Epoch 85/200\n",
            "207/207 [==============================] - 41s 199ms/step - loss: 0.0751 - accuracy: 0.9761 - val_loss: 0.1157 - val_accuracy: 0.9718\n",
            "Epoch 86/200\n",
            "207/207 [==============================] - 40s 194ms/step - loss: 0.0668 - accuracy: 0.9792 - val_loss: 0.1296 - val_accuracy: 0.9698\n",
            "Epoch 87/200\n",
            "207/207 [==============================] - 41s 200ms/step - loss: 0.0621 - accuracy: 0.9805 - val_loss: 0.1323 - val_accuracy: 0.9674\n",
            "Epoch 88/200\n",
            "207/207 [==============================] - 42s 203ms/step - loss: 0.0731 - accuracy: 0.9784 - val_loss: 0.1347 - val_accuracy: 0.9712\n",
            "Epoch 89/200\n",
            "207/207 [==============================] - 40s 193ms/step - loss: 0.0586 - accuracy: 0.9801 - val_loss: 0.1082 - val_accuracy: 0.9752\n",
            "Epoch 90/200\n",
            "207/207 [==============================] - 39s 189ms/step - loss: 0.0709 - accuracy: 0.9785 - val_loss: 0.1250 - val_accuracy: 0.9716\n",
            "Epoch 91/200\n",
            "207/207 [==============================] - 39s 191ms/step - loss: 0.0711 - accuracy: 0.9783 - val_loss: 0.1166 - val_accuracy: 0.9710\n",
            "Epoch 92/200\n",
            "207/207 [==============================] - 42s 205ms/step - loss: 0.0693 - accuracy: 0.9779 - val_loss: 0.1276 - val_accuracy: 0.9728\n",
            "Epoch 93/200\n",
            "207/207 [==============================] - 40s 196ms/step - loss: 0.0608 - accuracy: 0.9796 - val_loss: 0.1177 - val_accuracy: 0.9743\n",
            "Epoch 94/200\n",
            "207/207 [==============================] - 40s 193ms/step - loss: 0.0668 - accuracy: 0.9795 - val_loss: 0.1068 - val_accuracy: 0.9767\n",
            "Epoch 95/200\n",
            "207/207 [==============================] - 43s 208ms/step - loss: 0.0583 - accuracy: 0.9816 - val_loss: 0.1174 - val_accuracy: 0.9739\n",
            "Epoch 96/200\n",
            "207/207 [==============================] - 39s 189ms/step - loss: 0.0708 - accuracy: 0.9773 - val_loss: 0.1449 - val_accuracy: 0.9672\n",
            "Epoch 97/200\n",
            "207/207 [==============================] - 43s 206ms/step - loss: 0.0685 - accuracy: 0.9789 - val_loss: 0.1105 - val_accuracy: 0.9752\n",
            "Epoch 98/200\n",
            "207/207 [==============================] - 41s 200ms/step - loss: 0.0626 - accuracy: 0.9802 - val_loss: 0.1344 - val_accuracy: 0.9683\n",
            "Epoch 99/200\n",
            "207/207 [==============================] - 41s 198ms/step - loss: 0.0643 - accuracy: 0.9793 - val_loss: 0.1201 - val_accuracy: 0.9731\n",
            "Epoch 100/200\n",
            "207/207 [==============================] - 41s 196ms/step - loss: 0.0621 - accuracy: 0.9801 - val_loss: 0.1136 - val_accuracy: 0.9749\n",
            "Epoch 101/200\n",
            "207/207 [==============================] - 40s 192ms/step - loss: 0.0588 - accuracy: 0.9813 - val_loss: 0.1188 - val_accuracy: 0.9754\n",
            "Epoch 102/200\n",
            "207/207 [==============================] - 39s 188ms/step - loss: 0.0673 - accuracy: 0.9795 - val_loss: 0.1217 - val_accuracy: 0.9731\n",
            "Epoch 103/200\n",
            "207/207 [==============================] - 38s 185ms/step - loss: 0.0582 - accuracy: 0.9816 - val_loss: 0.1159 - val_accuracy: 0.9755\n",
            "Epoch 104/200\n",
            "207/207 [==============================] - 40s 192ms/step - loss: 0.0541 - accuracy: 0.9822 - val_loss: 0.1214 - val_accuracy: 0.9733\n",
            "Epoch 105/200\n",
            "207/207 [==============================] - 40s 192ms/step - loss: 0.0686 - accuracy: 0.9783 - val_loss: 0.1314 - val_accuracy: 0.9686\n",
            "Epoch 106/200\n",
            "207/207 [==============================] - 42s 205ms/step - loss: 0.0630 - accuracy: 0.9799 - val_loss: 0.1189 - val_accuracy: 0.9731\n",
            "Epoch 107/200\n",
            "207/207 [==============================] - 41s 197ms/step - loss: 0.0573 - accuracy: 0.9826 - val_loss: 0.1240 - val_accuracy: 0.9715\n",
            "Epoch 108/200\n",
            "207/207 [==============================] - 40s 193ms/step - loss: 0.0629 - accuracy: 0.9813 - val_loss: 0.1202 - val_accuracy: 0.9728\n",
            "Epoch 109/200\n",
            "207/207 [==============================] - 41s 196ms/step - loss: 0.0552 - accuracy: 0.9828 - val_loss: 0.1124 - val_accuracy: 0.9752\n",
            "Epoch 110/200\n",
            "207/207 [==============================] - 41s 197ms/step - loss: 0.0574 - accuracy: 0.9818 - val_loss: 0.1642 - val_accuracy: 0.9674\n",
            "Epoch 111/200\n",
            "207/207 [==============================] - 40s 191ms/step - loss: 0.0685 - accuracy: 0.9784 - val_loss: 0.1219 - val_accuracy: 0.9731\n",
            "Epoch 112/200\n",
            "207/207 [==============================] - 39s 188ms/step - loss: 0.0625 - accuracy: 0.9803 - val_loss: 0.1216 - val_accuracy: 0.9733\n",
            "Epoch 113/200\n",
            "207/207 [==============================] - 39s 188ms/step - loss: 0.0580 - accuracy: 0.9812 - val_loss: 0.1219 - val_accuracy: 0.9737\n",
            "Epoch 114/200\n",
            "207/207 [==============================] - 40s 192ms/step - loss: 0.0536 - accuracy: 0.9831 - val_loss: 0.1137 - val_accuracy: 0.9752\n",
            "Epoch 115/200\n",
            "207/207 [==============================] - 40s 194ms/step - loss: 0.0586 - accuracy: 0.9823 - val_loss: 0.1061 - val_accuracy: 0.9766\n",
            "Epoch 116/200\n",
            "207/207 [==============================] - 41s 198ms/step - loss: 0.0607 - accuracy: 0.9814 - val_loss: 0.1160 - val_accuracy: 0.9749\n",
            "Epoch 117/200\n",
            "207/207 [==============================] - 41s 197ms/step - loss: 0.0567 - accuracy: 0.9830 - val_loss: 0.1047 - val_accuracy: 0.9764\n",
            "Epoch 118/200\n",
            "207/207 [==============================] - 40s 192ms/step - loss: 0.0594 - accuracy: 0.9809 - val_loss: 0.1318 - val_accuracy: 0.9707\n",
            "Epoch 119/200\n",
            "207/207 [==============================] - 42s 202ms/step - loss: 0.0604 - accuracy: 0.9813 - val_loss: 0.1199 - val_accuracy: 0.9739\n",
            "Epoch 120/200\n",
            "207/207 [==============================] - 42s 203ms/step - loss: 0.0560 - accuracy: 0.9827 - val_loss: 0.1155 - val_accuracy: 0.9737\n",
            "Epoch 121/200\n",
            "207/207 [==============================] - 43s 208ms/step - loss: 0.0465 - accuracy: 0.9850 - val_loss: 0.1092 - val_accuracy: 0.9761\n",
            "Epoch 122/200\n",
            "207/207 [==============================] - 43s 209ms/step - loss: 0.0584 - accuracy: 0.9819 - val_loss: 0.1082 - val_accuracy: 0.9783\n",
            "Epoch 123/200\n",
            "207/207 [==============================] - 46s 223ms/step - loss: 0.0633 - accuracy: 0.9802 - val_loss: 0.1287 - val_accuracy: 0.9716\n",
            "Epoch 124/200\n",
            "207/207 [==============================] - 46s 221ms/step - loss: 0.0516 - accuracy: 0.9840 - val_loss: 0.1022 - val_accuracy: 0.9778\n",
            "Epoch 125/200\n",
            "207/207 [==============================] - 50s 242ms/step - loss: 0.0511 - accuracy: 0.9839 - val_loss: 0.1112 - val_accuracy: 0.9758\n",
            "Epoch 126/200\n",
            "207/207 [==============================] - 50s 243ms/step - loss: 0.0540 - accuracy: 0.9838 - val_loss: 0.1252 - val_accuracy: 0.9722\n",
            "Epoch 127/200\n",
            "207/207 [==============================] - 46s 224ms/step - loss: 0.0575 - accuracy: 0.9826 - val_loss: 0.1065 - val_accuracy: 0.9776\n",
            "Epoch 128/200\n",
            "207/207 [==============================] - 43s 210ms/step - loss: 0.0452 - accuracy: 0.9856 - val_loss: 0.1242 - val_accuracy: 0.9746\n",
            "Epoch 129/200\n",
            "207/207 [==============================] - 39s 191ms/step - loss: 0.0508 - accuracy: 0.9836 - val_loss: 0.1152 - val_accuracy: 0.9751\n",
            "Epoch 130/200\n",
            "207/207 [==============================] - 42s 202ms/step - loss: 0.0607 - accuracy: 0.9809 - val_loss: 0.1115 - val_accuracy: 0.9755\n",
            "Epoch 131/200\n",
            "207/207 [==============================] - 44s 211ms/step - loss: 0.0521 - accuracy: 0.9841 - val_loss: 0.1128 - val_accuracy: 0.9755\n",
            "Epoch 132/200\n",
            "207/207 [==============================] - 41s 199ms/step - loss: 0.0512 - accuracy: 0.9842 - val_loss: 0.1313 - val_accuracy: 0.9740\n",
            "Epoch 133/200\n",
            "207/207 [==============================] - 43s 207ms/step - loss: 0.0450 - accuracy: 0.9854 - val_loss: 0.1072 - val_accuracy: 0.9793\n",
            "Epoch 134/200\n",
            "207/207 [==============================] - 45s 218ms/step - loss: 0.0488 - accuracy: 0.9844 - val_loss: 0.1195 - val_accuracy: 0.9754\n",
            "Epoch 135/200\n",
            "207/207 [==============================] - 47s 229ms/step - loss: 0.0529 - accuracy: 0.9832 - val_loss: 0.1128 - val_accuracy: 0.9749\n",
            "Epoch 136/200\n",
            "207/207 [==============================] - 44s 213ms/step - loss: 0.0538 - accuracy: 0.9842 - val_loss: 0.1092 - val_accuracy: 0.9776\n",
            "Epoch 137/200\n",
            "207/207 [==============================] - 43s 208ms/step - loss: 0.0580 - accuracy: 0.9824 - val_loss: 0.1148 - val_accuracy: 0.9755\n",
            "Epoch 138/200\n",
            "207/207 [==============================] - 45s 218ms/step - loss: 0.0519 - accuracy: 0.9831 - val_loss: 0.1115 - val_accuracy: 0.9766\n",
            "Epoch 139/200\n",
            "207/207 [==============================] - 45s 218ms/step - loss: 0.0549 - accuracy: 0.9835 - val_loss: 0.1113 - val_accuracy: 0.9760\n",
            "Epoch 140/200\n",
            "207/207 [==============================] - 44s 211ms/step - loss: 0.0440 - accuracy: 0.9864 - val_loss: 0.0943 - val_accuracy: 0.9786\n",
            "Epoch 141/200\n",
            "207/207 [==============================] - 43s 207ms/step - loss: 0.0516 - accuracy: 0.9840 - val_loss: 0.1183 - val_accuracy: 0.9760\n",
            "Epoch 142/200\n",
            "207/207 [==============================] - 43s 206ms/step - loss: 0.0526 - accuracy: 0.9834 - val_loss: 0.1260 - val_accuracy: 0.9734\n",
            "Epoch 143/200\n",
            "207/207 [==============================] - 41s 200ms/step - loss: 0.0575 - accuracy: 0.9829 - val_loss: 0.1151 - val_accuracy: 0.9752\n",
            "Epoch 144/200\n",
            "207/207 [==============================] - 43s 207ms/step - loss: 0.0470 - accuracy: 0.9860 - val_loss: 0.1110 - val_accuracy: 0.9743\n",
            "Epoch 145/200\n",
            "207/207 [==============================] - 43s 208ms/step - loss: 0.0482 - accuracy: 0.9840 - val_loss: 0.1160 - val_accuracy: 0.9772\n",
            "Epoch 146/200\n",
            "207/207 [==============================] - 43s 208ms/step - loss: 0.0559 - accuracy: 0.9831 - val_loss: 0.1245 - val_accuracy: 0.9745\n",
            "Epoch 147/200\n",
            "207/207 [==============================] - 42s 204ms/step - loss: 0.0564 - accuracy: 0.9826 - val_loss: 0.1198 - val_accuracy: 0.9772\n",
            "Epoch 148/200\n",
            "207/207 [==============================] - 41s 198ms/step - loss: 0.0506 - accuracy: 0.9842 - val_loss: 0.0992 - val_accuracy: 0.9779\n",
            "Epoch 149/200\n",
            "207/207 [==============================] - 38s 186ms/step - loss: 0.0520 - accuracy: 0.9840 - val_loss: 0.1270 - val_accuracy: 0.9754\n",
            "Epoch 150/200\n",
            "207/207 [==============================] - 40s 191ms/step - loss: 0.0447 - accuracy: 0.9856 - val_loss: 0.1219 - val_accuracy: 0.9773\n",
            "Epoch 151/200\n",
            "207/207 [==============================] - 40s 196ms/step - loss: 0.0546 - accuracy: 0.9839 - val_loss: 0.1132 - val_accuracy: 0.9767\n",
            "Epoch 152/200\n",
            "207/207 [==============================] - 43s 210ms/step - loss: 0.0575 - accuracy: 0.9814 - val_loss: 0.1079 - val_accuracy: 0.9781\n",
            "Epoch 153/200\n",
            "207/207 [==============================] - 44s 214ms/step - loss: 0.0472 - accuracy: 0.9867 - val_loss: 0.0942 - val_accuracy: 0.9801\n",
            "Epoch 154/200\n",
            "207/207 [==============================] - 43s 206ms/step - loss: 0.0477 - accuracy: 0.9850 - val_loss: 0.1065 - val_accuracy: 0.9773\n",
            "Epoch 155/200\n",
            "207/207 [==============================] - 41s 199ms/step - loss: 0.0449 - accuracy: 0.9859 - val_loss: 0.1019 - val_accuracy: 0.9776\n",
            "Epoch 156/200\n",
            "207/207 [==============================] - 43s 208ms/step - loss: 0.0440 - accuracy: 0.9861 - val_loss: 0.1283 - val_accuracy: 0.9755\n",
            "Epoch 157/200\n",
            "207/207 [==============================] - 39s 191ms/step - loss: 0.0569 - accuracy: 0.9829 - val_loss: 0.1032 - val_accuracy: 0.9760\n",
            "Epoch 158/200\n",
            "207/207 [==============================] - 38s 186ms/step - loss: 0.0453 - accuracy: 0.9852 - val_loss: 0.1139 - val_accuracy: 0.9767\n",
            "Epoch 159/200\n",
            "207/207 [==============================] - 40s 195ms/step - loss: 0.0433 - accuracy: 0.9867 - val_loss: 0.1134 - val_accuracy: 0.9773\n",
            "Epoch 160/200\n",
            "207/207 [==============================] - 41s 199ms/step - loss: 0.0561 - accuracy: 0.9830 - val_loss: 0.1218 - val_accuracy: 0.9761\n",
            "Epoch 161/200\n",
            "207/207 [==============================] - 43s 208ms/step - loss: 0.0443 - accuracy: 0.9863 - val_loss: 0.1126 - val_accuracy: 0.9776\n",
            "Epoch 162/200\n",
            "207/207 [==============================] - 43s 208ms/step - loss: 0.0439 - accuracy: 0.9855 - val_loss: 0.1106 - val_accuracy: 0.9778\n",
            "Epoch 163/200\n",
            "207/207 [==============================] - 42s 205ms/step - loss: 0.0508 - accuracy: 0.9844 - val_loss: 0.1155 - val_accuracy: 0.9748\n",
            "Epoch 164/200\n",
            "207/207 [==============================] - 41s 199ms/step - loss: 0.0526 - accuracy: 0.9837 - val_loss: 0.1129 - val_accuracy: 0.9737\n",
            "Epoch 165/200\n",
            "207/207 [==============================] - 42s 203ms/step - loss: 0.0469 - accuracy: 0.9854 - val_loss: 0.1008 - val_accuracy: 0.9787\n",
            "Epoch 166/200\n",
            "207/207 [==============================] - 42s 205ms/step - loss: 0.0425 - accuracy: 0.9861 - val_loss: 0.1004 - val_accuracy: 0.9786\n",
            "Epoch 167/200\n",
            "207/207 [==============================] - 41s 197ms/step - loss: 0.0491 - accuracy: 0.9841 - val_loss: 0.1107 - val_accuracy: 0.9778\n",
            "Epoch 168/200\n",
            "207/207 [==============================] - 41s 198ms/step - loss: 0.0515 - accuracy: 0.9834 - val_loss: 0.1105 - val_accuracy: 0.9749\n",
            "Epoch 169/200\n",
            "207/207 [==============================] - 41s 199ms/step - loss: 0.0517 - accuracy: 0.9841 - val_loss: 0.1054 - val_accuracy: 0.9787\n",
            "Epoch 170/200\n",
            "207/207 [==============================] - 41s 198ms/step - loss: 0.0417 - accuracy: 0.9878 - val_loss: 0.1192 - val_accuracy: 0.9776\n",
            "Epoch 171/200\n",
            "207/207 [==============================] - 40s 195ms/step - loss: 0.0418 - accuracy: 0.9867 - val_loss: 0.1270 - val_accuracy: 0.9760\n",
            "Epoch 172/200\n",
            "207/207 [==============================] - 41s 199ms/step - loss: 0.0473 - accuracy: 0.9850 - val_loss: 0.1096 - val_accuracy: 0.9773\n",
            "Epoch 173/200\n",
            "207/207 [==============================] - 42s 204ms/step - loss: 0.0510 - accuracy: 0.9836 - val_loss: 0.1106 - val_accuracy: 0.9781\n",
            "Epoch 174/200\n",
            "207/207 [==============================] - 43s 206ms/step - loss: 0.0504 - accuracy: 0.9847 - val_loss: 0.1047 - val_accuracy: 0.9783\n",
            "Epoch 175/200\n",
            "207/207 [==============================] - 42s 205ms/step - loss: 0.0444 - accuracy: 0.9872 - val_loss: 0.1037 - val_accuracy: 0.9784\n",
            "Epoch 176/200\n",
            "207/207 [==============================] - 42s 201ms/step - loss: 0.0365 - accuracy: 0.9893 - val_loss: 0.1059 - val_accuracy: 0.9787\n",
            "Epoch 177/200\n",
            "207/207 [==============================] - 43s 210ms/step - loss: 0.0438 - accuracy: 0.9859 - val_loss: 0.1117 - val_accuracy: 0.9772\n",
            "Epoch 178/200\n",
            "207/207 [==============================] - 42s 204ms/step - loss: 0.0476 - accuracy: 0.9856 - val_loss: 0.1452 - val_accuracy: 0.9731\n",
            "Epoch 179/200\n",
            "207/207 [==============================] - 40s 193ms/step - loss: 0.0479 - accuracy: 0.9852 - val_loss: 0.1181 - val_accuracy: 0.9763\n",
            "Epoch 180/200\n",
            "207/207 [==============================] - 39s 188ms/step - loss: 0.0585 - accuracy: 0.9837 - val_loss: 0.1049 - val_accuracy: 0.9783\n",
            "Epoch 181/200\n",
            "207/207 [==============================] - 39s 187ms/step - loss: 0.0400 - accuracy: 0.9877 - val_loss: 0.1263 - val_accuracy: 0.9766\n",
            "Epoch 182/200\n",
            "207/207 [==============================] - 39s 187ms/step - loss: 0.0379 - accuracy: 0.9873 - val_loss: 0.1090 - val_accuracy: 0.9786\n",
            "Epoch 183/200\n",
            "207/207 [==============================] - 41s 196ms/step - loss: 0.0410 - accuracy: 0.9873 - val_loss: 0.1149 - val_accuracy: 0.9778\n",
            "Epoch 184/200\n",
            "207/207 [==============================] - 42s 201ms/step - loss: 0.0564 - accuracy: 0.9820 - val_loss: 0.1117 - val_accuracy: 0.9773\n",
            "Epoch 185/200\n",
            "207/207 [==============================] - 44s 210ms/step - loss: 0.0515 - accuracy: 0.9848 - val_loss: 0.1235 - val_accuracy: 0.9754\n",
            "Epoch 186/200\n",
            "207/207 [==============================] - 47s 227ms/step - loss: 0.0464 - accuracy: 0.9851 - val_loss: 0.1265 - val_accuracy: 0.9763\n",
            "Epoch 187/200\n",
            "207/207 [==============================] - 44s 213ms/step - loss: 0.0449 - accuracy: 0.9860 - val_loss: 0.1240 - val_accuracy: 0.9772\n",
            "Epoch 188/200\n",
            "207/207 [==============================] - 42s 204ms/step - loss: 0.0462 - accuracy: 0.9854 - val_loss: 0.1021 - val_accuracy: 0.9790\n",
            "Epoch 189/200\n",
            "207/207 [==============================] - 40s 195ms/step - loss: 0.0456 - accuracy: 0.9858 - val_loss: 0.1214 - val_accuracy: 0.9769\n",
            "Epoch 190/200\n",
            "207/207 [==============================] - 39s 189ms/step - loss: 0.0441 - accuracy: 0.9875 - val_loss: 0.1046 - val_accuracy: 0.9781\n",
            "Epoch 191/200\n",
            "207/207 [==============================] - 38s 182ms/step - loss: 0.0370 - accuracy: 0.9879 - val_loss: 0.1121 - val_accuracy: 0.9772\n",
            "Epoch 192/200\n",
            "207/207 [==============================] - 38s 183ms/step - loss: 0.0450 - accuracy: 0.9864 - val_loss: 0.1034 - val_accuracy: 0.9795\n",
            "Epoch 193/200\n",
            "207/207 [==============================] - 37s 179ms/step - loss: 0.0452 - accuracy: 0.9863 - val_loss: 0.1163 - val_accuracy: 0.9781\n",
            "Epoch 194/200\n",
            "207/207 [==============================] - 37s 180ms/step - loss: 0.0517 - accuracy: 0.9855 - val_loss: 0.1052 - val_accuracy: 0.9789\n",
            "Epoch 195/200\n",
            "207/207 [==============================] - 38s 185ms/step - loss: 0.0442 - accuracy: 0.9863 - val_loss: 0.1146 - val_accuracy: 0.9769\n",
            "Epoch 196/200\n",
            "207/207 [==============================] - 43s 206ms/step - loss: 0.0456 - accuracy: 0.9872 - val_loss: 0.1070 - val_accuracy: 0.9804\n",
            "Epoch 197/200\n",
            "207/207 [==============================] - 42s 201ms/step - loss: 0.0403 - accuracy: 0.9876 - val_loss: 0.1083 - val_accuracy: 0.9745\n",
            "Epoch 198/200\n",
            "207/207 [==============================] - 42s 204ms/step - loss: 0.0417 - accuracy: 0.9865 - val_loss: 0.1218 - val_accuracy: 0.9757\n",
            "Epoch 199/200\n",
            "207/207 [==============================] - 43s 205ms/step - loss: 0.0481 - accuracy: 0.9855 - val_loss: 0.1189 - val_accuracy: 0.9766\n",
            "Epoch 200/200\n",
            "207/207 [==============================] - 43s 210ms/step - loss: 0.0475 - accuracy: 0.9850 - val_loss: 0.1732 - val_accuracy: 0.9686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "loss, accuracy = model2.evaluate(X_validation, y_validation, verbose=False)\n",
        "print(\"Validation Accuracy:  {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model2.evaluate(x_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy: {:.4f}\".format(accuracy))"
      ],
      "metadata": {
        "id": "UHm8vT-e8i_V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29e83e37-973b-4f87-a971-97854645b119"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy:  0.9686\n",
            "Testing Accuracy: 0.8898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hUPVPwoNWRU2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
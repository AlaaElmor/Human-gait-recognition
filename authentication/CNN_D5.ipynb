{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_D5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3n0Tp6K1Orsu"
      },
      "outputs": [],
      "source": [
        "from numpy import save, load\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "from numpy import save, load\n",
        "from pandas import read_csv\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras import Model\n",
        "from keras.layers import Conv1D, SpatialDropout1D\n",
        "from keras.layers import Convolution1D, Dense,Activation\n",
        "from keras.models import Input, Model\n",
        "from keras.layers import LSTM, Conv1D, concatenate,GlobalMaxPooling1D,GlobalAveragePooling1D,TimeDistributed, MaxPooling1D\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "import tensorflow as keras\n",
        "import keras.backend as K\n",
        "import keras.layers\n",
        "from keras import optimizers\n",
        "from keras.layers import Activation, Lambda\n",
        "from keras.layers import Convolution1D, Dense\n",
        "from keras.models import Input, Model\n",
        "from typing import List, Tuple\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/'  #change dir to your project folder\n",
        "\n",
        "import numpy as np\n",
        "x_train = np.load('gdrive/My Drive/dataset5/trainX.npy')\n",
        "y_train = np.load('gdrive/My Drive/dataset5/trainy.npy')\n",
        "x_test = np.load('gdrive/My Drive/dataset5/testX.npy')\n",
        "y_test = np.load('gdrive/My Drive/dataset5/testy.npy')\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "LYFTfDgJO37T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "063daebc-22f2-4bfc-ce95-c9c1b51a9483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Mounted at /content/gdrive\n",
            "(66542, 256, 6) (66542, 2) (7600, 256, 6) (7600, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_training, X_validation, y_training, y_validation = train_test_split(x_train, y_train, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "fIPNEOEHUd7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_timesteps, n_features, n_outputs = x_train.shape[1], x_train.shape[2], y_train.shape[1]"
      ],
      "metadata": {
        "id": "neGKv8tYVrYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(n_outputs, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhYGLvK8WX7-",
        "outputId": "55c6bf8b-c4c8-4db0-ed48-606cd7216264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 254, 64)           1216      \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 252, 64)           12352     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 252, 64)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 126, 64)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8064)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               806500    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 820,270\n",
            "Trainable params: 820,270\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_training, y_training, epochs=200, verbose=True, validation_data=(X_validation, y_validation), batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR7mEPexY_cF",
        "outputId": "3ad49ce2-5ac3-41d8-c3b0-657e227eef39"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "416/416 [==============================] - 48s 117ms/step - loss: 0.3739 - accuracy: 0.8370 - val_loss: 0.2815 - val_accuracy: 0.8867\n",
            "Epoch 2/200\n",
            "416/416 [==============================] - 48s 116ms/step - loss: 0.2313 - accuracy: 0.9107 - val_loss: 0.2219 - val_accuracy: 0.9170\n",
            "Epoch 3/200\n",
            "416/416 [==============================] - 48s 116ms/step - loss: 0.1746 - accuracy: 0.9350 - val_loss: 0.1724 - val_accuracy: 0.9358\n",
            "Epoch 4/200\n",
            "416/416 [==============================] - 48s 116ms/step - loss: 0.1430 - accuracy: 0.9455 - val_loss: 0.1543 - val_accuracy: 0.9431\n",
            "Epoch 5/200\n",
            "416/416 [==============================] - 48s 114ms/step - loss: 0.1174 - accuracy: 0.9566 - val_loss: 0.1437 - val_accuracy: 0.9467\n",
            "Epoch 6/200\n",
            "416/416 [==============================] - 49s 118ms/step - loss: 0.0994 - accuracy: 0.9628 - val_loss: 0.1339 - val_accuracy: 0.9494\n",
            "Epoch 7/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0867 - accuracy: 0.9685 - val_loss: 0.1195 - val_accuracy: 0.9576\n",
            "Epoch 8/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0758 - accuracy: 0.9728 - val_loss: 0.1199 - val_accuracy: 0.9558\n",
            "Epoch 9/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0650 - accuracy: 0.9764 - val_loss: 0.1227 - val_accuracy: 0.9548\n",
            "Epoch 10/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0594 - accuracy: 0.9784 - val_loss: 0.1164 - val_accuracy: 0.9580\n",
            "Epoch 11/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0518 - accuracy: 0.9823 - val_loss: 0.1077 - val_accuracy: 0.9633\n",
            "Epoch 12/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0507 - accuracy: 0.9822 - val_loss: 0.1055 - val_accuracy: 0.9635\n",
            "Epoch 13/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0433 - accuracy: 0.9838 - val_loss: 0.1038 - val_accuracy: 0.9643\n",
            "Epoch 14/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0428 - accuracy: 0.9846 - val_loss: 0.1053 - val_accuracy: 0.9649\n",
            "Epoch 15/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0382 - accuracy: 0.9868 - val_loss: 0.1045 - val_accuracy: 0.9655\n",
            "Epoch 16/200\n",
            "416/416 [==============================] - 48s 114ms/step - loss: 0.0356 - accuracy: 0.9875 - val_loss: 0.0981 - val_accuracy: 0.9680\n",
            "Epoch 17/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0345 - accuracy: 0.9875 - val_loss: 0.1210 - val_accuracy: 0.9605\n",
            "Epoch 18/200\n",
            "416/416 [==============================] - 46s 111ms/step - loss: 0.0285 - accuracy: 0.9903 - val_loss: 0.1199 - val_accuracy: 0.9627\n",
            "Epoch 19/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0312 - accuracy: 0.9894 - val_loss: 0.1062 - val_accuracy: 0.9671\n",
            "Epoch 20/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0330 - accuracy: 0.9886 - val_loss: 0.1085 - val_accuracy: 0.9666\n",
            "Epoch 21/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0268 - accuracy: 0.9905 - val_loss: 0.1281 - val_accuracy: 0.9618\n",
            "Epoch 22/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0287 - accuracy: 0.9894 - val_loss: 0.1110 - val_accuracy: 0.9680\n",
            "Epoch 23/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0256 - accuracy: 0.9911 - val_loss: 0.1037 - val_accuracy: 0.9687\n",
            "Epoch 24/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0238 - accuracy: 0.9917 - val_loss: 0.1202 - val_accuracy: 0.9667\n",
            "Epoch 25/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0218 - accuracy: 0.9925 - val_loss: 0.1328 - val_accuracy: 0.9627\n",
            "Epoch 26/200\n",
            "416/416 [==============================] - 46s 111ms/step - loss: 0.0236 - accuracy: 0.9918 - val_loss: 0.1041 - val_accuracy: 0.9699\n",
            "Epoch 27/200\n",
            "416/416 [==============================] - 46s 112ms/step - loss: 0.0220 - accuracy: 0.9925 - val_loss: 0.1154 - val_accuracy: 0.9672\n",
            "Epoch 28/200\n",
            "416/416 [==============================] - 52s 124ms/step - loss: 0.0205 - accuracy: 0.9928 - val_loss: 0.1124 - val_accuracy: 0.9696\n",
            "Epoch 29/200\n",
            "416/416 [==============================] - 48s 116ms/step - loss: 0.0192 - accuracy: 0.9930 - val_loss: 0.1168 - val_accuracy: 0.9685\n",
            "Epoch 30/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0195 - accuracy: 0.9931 - val_loss: 0.1236 - val_accuracy: 0.9652\n",
            "Epoch 31/200\n",
            "416/416 [==============================] - 48s 114ms/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 0.1040 - val_accuracy: 0.9739\n",
            "Epoch 32/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0170 - accuracy: 0.9940 - val_loss: 0.1122 - val_accuracy: 0.9699\n",
            "Epoch 33/200\n",
            "416/416 [==============================] - 46s 112ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.1165 - val_accuracy: 0.9690\n",
            "Epoch 34/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0198 - accuracy: 0.9934 - val_loss: 0.1178 - val_accuracy: 0.9692\n",
            "Epoch 35/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0167 - accuracy: 0.9940 - val_loss: 0.1091 - val_accuracy: 0.9702\n",
            "Epoch 36/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0165 - accuracy: 0.9941 - val_loss: 0.1287 - val_accuracy: 0.9668\n",
            "Epoch 37/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0165 - accuracy: 0.9944 - val_loss: 0.1129 - val_accuracy: 0.9687\n",
            "Epoch 38/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 0.1228 - val_accuracy: 0.9675\n",
            "Epoch 39/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0155 - accuracy: 0.9946 - val_loss: 0.1292 - val_accuracy: 0.9667\n",
            "Epoch 40/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0135 - accuracy: 0.9952 - val_loss: 0.1333 - val_accuracy: 0.9672\n",
            "Epoch 41/200\n",
            "416/416 [==============================] - 46s 112ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.1126 - val_accuracy: 0.9717\n",
            "Epoch 42/200\n",
            "416/416 [==============================] - 46s 112ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 0.1381 - val_accuracy: 0.9669\n",
            "Epoch 43/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.1188 - val_accuracy: 0.9699\n",
            "Epoch 44/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0155 - accuracy: 0.9946 - val_loss: 0.1398 - val_accuracy: 0.9673\n",
            "Epoch 45/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 0.1124 - val_accuracy: 0.9711\n",
            "Epoch 46/200\n",
            "416/416 [==============================] - 48s 114ms/step - loss: 0.0147 - accuracy: 0.9947 - val_loss: 0.1295 - val_accuracy: 0.9696\n",
            "Epoch 47/200\n",
            "416/416 [==============================] - 48s 114ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.1237 - val_accuracy: 0.9703\n",
            "Epoch 48/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.1244 - val_accuracy: 0.9700\n",
            "Epoch 49/200\n",
            "416/416 [==============================] - 48s 114ms/step - loss: 0.0131 - accuracy: 0.9955 - val_loss: 0.1322 - val_accuracy: 0.9676\n",
            "Epoch 50/200\n",
            "416/416 [==============================] - 48s 114ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.1320 - val_accuracy: 0.9699\n",
            "Epoch 51/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.1290 - val_accuracy: 0.9708\n",
            "Epoch 52/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.1162 - val_accuracy: 0.9734\n",
            "Epoch 53/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.1362 - val_accuracy: 0.9708\n",
            "Epoch 54/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0131 - accuracy: 0.9955 - val_loss: 0.1186 - val_accuracy: 0.9708\n",
            "Epoch 55/200\n",
            "416/416 [==============================] - 48s 114ms/step - loss: 0.0127 - accuracy: 0.9955 - val_loss: 0.1418 - val_accuracy: 0.9676\n",
            "Epoch 56/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.1324 - val_accuracy: 0.9702\n",
            "Epoch 57/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.1309 - val_accuracy: 0.9693\n",
            "Epoch 58/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.1356 - val_accuracy: 0.9705\n",
            "Epoch 59/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.1319 - val_accuracy: 0.9715\n",
            "Epoch 60/200\n",
            "416/416 [==============================] - 48s 114ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.1313 - val_accuracy: 0.9718\n",
            "Epoch 61/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.1319 - val_accuracy: 0.9696\n",
            "Epoch 62/200\n",
            "416/416 [==============================] - 48s 114ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.1103 - val_accuracy: 0.9748\n",
            "Epoch 63/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.1288 - val_accuracy: 0.9719\n",
            "Epoch 64/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 0.1298 - val_accuracy: 0.9710\n",
            "Epoch 65/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.1209 - val_accuracy: 0.9730\n",
            "Epoch 66/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.1679 - val_accuracy: 0.9651\n",
            "Epoch 67/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.1279 - val_accuracy: 0.9715\n",
            "Epoch 68/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.1692 - val_accuracy: 0.9634\n",
            "Epoch 69/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.1283 - val_accuracy: 0.9710\n",
            "Epoch 70/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.1423 - val_accuracy: 0.9693\n",
            "Epoch 71/200\n",
            "416/416 [==============================] - 48s 116ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.1344 - val_accuracy: 0.9691\n",
            "Epoch 72/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.1490 - val_accuracy: 0.9707\n",
            "Epoch 73/200\n",
            "416/416 [==============================] - 48s 116ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.1588 - val_accuracy: 0.9675\n",
            "Epoch 74/200\n",
            "416/416 [==============================] - 48s 116ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.1201 - val_accuracy: 0.9747\n",
            "Epoch 75/200\n",
            "416/416 [==============================] - 48s 116ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.1363 - val_accuracy: 0.9707\n",
            "Epoch 76/200\n",
            "416/416 [==============================] - 48s 114ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.1383 - val_accuracy: 0.9693\n",
            "Epoch 77/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.1412 - val_accuracy: 0.9696\n",
            "Epoch 78/200\n",
            "416/416 [==============================] - 48s 116ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.1588 - val_accuracy: 0.9682\n",
            "Epoch 79/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.1381 - val_accuracy: 0.9697\n",
            "Epoch 80/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.1270 - val_accuracy: 0.9713\n",
            "Epoch 81/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.1538 - val_accuracy: 0.9688\n",
            "Epoch 82/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.1259 - val_accuracy: 0.9739\n",
            "Epoch 83/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.1477 - val_accuracy: 0.9688\n",
            "Epoch 84/200\n",
            "416/416 [==============================] - 48s 114ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.1488 - val_accuracy: 0.9681\n",
            "Epoch 85/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.1250 - val_accuracy: 0.9711\n",
            "Epoch 86/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.1487 - val_accuracy: 0.9681\n",
            "Epoch 87/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.1219 - val_accuracy: 0.9742\n",
            "Epoch 88/200\n",
            "416/416 [==============================] - 48s 116ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.1273 - val_accuracy: 0.9736\n",
            "Epoch 89/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.1365 - val_accuracy: 0.9718\n",
            "Epoch 90/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.1292 - val_accuracy: 0.9729\n",
            "Epoch 91/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.1634 - val_accuracy: 0.9681\n",
            "Epoch 92/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.1296 - val_accuracy: 0.9723\n",
            "Epoch 93/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 0.1409 - val_accuracy: 0.9722\n",
            "Epoch 94/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.1579 - val_accuracy: 0.9705\n",
            "Epoch 95/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.1469 - val_accuracy: 0.9720\n",
            "Epoch 96/200\n",
            "416/416 [==============================] - 48s 114ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.1261 - val_accuracy: 0.9736\n",
            "Epoch 97/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.1397 - val_accuracy: 0.9706\n",
            "Epoch 98/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.1395 - val_accuracy: 0.9724\n",
            "Epoch 99/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1690 - val_accuracy: 0.9688\n",
            "Epoch 100/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.1313 - val_accuracy: 0.9728\n",
            "Epoch 101/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.1267 - val_accuracy: 0.9732\n",
            "Epoch 102/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1461 - val_accuracy: 0.9702\n",
            "Epoch 103/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.1331 - val_accuracy: 0.9748\n",
            "Epoch 104/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.1339 - val_accuracy: 0.9743\n",
            "Epoch 105/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.1430 - val_accuracy: 0.9730\n",
            "Epoch 106/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.1571 - val_accuracy: 0.9715\n",
            "Epoch 107/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.1374 - val_accuracy: 0.9755\n",
            "Epoch 108/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.1484 - val_accuracy: 0.9720\n",
            "Epoch 109/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.1549 - val_accuracy: 0.9702\n",
            "Epoch 110/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.1460 - val_accuracy: 0.9721\n",
            "Epoch 111/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.1599 - val_accuracy: 0.9715\n",
            "Epoch 112/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.1363 - val_accuracy: 0.9730\n",
            "Epoch 113/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.1430 - val_accuracy: 0.9738\n",
            "Epoch 114/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.1808 - val_accuracy: 0.9690\n",
            "Epoch 115/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.1479 - val_accuracy: 0.9726\n",
            "Epoch 116/200\n",
            "416/416 [==============================] - 48s 114ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.1396 - val_accuracy: 0.9728\n",
            "Epoch 117/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.1477 - val_accuracy: 0.9699\n",
            "Epoch 118/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.1391 - val_accuracy: 0.9735\n",
            "Epoch 119/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.1479 - val_accuracy: 0.9727\n",
            "Epoch 120/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1458 - val_accuracy: 0.9717\n",
            "Epoch 121/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.1299 - val_accuracy: 0.9742\n",
            "Epoch 122/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.1382 - val_accuracy: 0.9729\n",
            "Epoch 123/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.1502 - val_accuracy: 0.9706\n",
            "Epoch 124/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.1703 - val_accuracy: 0.9682\n",
            "Epoch 125/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.1557 - val_accuracy: 0.9714\n",
            "Epoch 126/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.1401 - val_accuracy: 0.9734\n",
            "Epoch 127/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.1690 - val_accuracy: 0.9709\n",
            "Epoch 128/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.1540 - val_accuracy: 0.9719\n",
            "Epoch 129/200\n",
            "416/416 [==============================] - 48s 114ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.1621 - val_accuracy: 0.9714\n",
            "Epoch 130/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.1545 - val_accuracy: 0.9723\n",
            "Epoch 131/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.1621 - val_accuracy: 0.9707\n",
            "Epoch 132/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.1447 - val_accuracy: 0.9739\n",
            "Epoch 133/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.1480 - val_accuracy: 0.9736\n",
            "Epoch 134/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.1402 - val_accuracy: 0.9755\n",
            "Epoch 135/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.1555 - val_accuracy: 0.9726\n",
            "Epoch 136/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.1431 - val_accuracy: 0.9742\n",
            "Epoch 137/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1534 - val_accuracy: 0.9739\n",
            "Epoch 138/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.1636 - val_accuracy: 0.9702\n",
            "Epoch 139/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.1494 - val_accuracy: 0.9734\n",
            "Epoch 140/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.1511 - val_accuracy: 0.9749\n",
            "Epoch 141/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.1809 - val_accuracy: 0.9699\n",
            "Epoch 142/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.1588 - val_accuracy: 0.9733\n",
            "Epoch 143/200\n",
            "416/416 [==============================] - 48s 114ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.1619 - val_accuracy: 0.9721\n",
            "Epoch 144/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.1521 - val_accuracy: 0.9752\n",
            "Epoch 145/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1513 - val_accuracy: 0.9739\n",
            "Epoch 146/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.1469 - val_accuracy: 0.9742\n",
            "Epoch 147/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.1590 - val_accuracy: 0.9759\n",
            "Epoch 148/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.1418 - val_accuracy: 0.9738\n",
            "Epoch 149/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.1509 - val_accuracy: 0.9739\n",
            "Epoch 150/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.1447 - val_accuracy: 0.9760\n",
            "Epoch 151/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.1660 - val_accuracy: 0.9720\n",
            "Epoch 152/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.1881 - val_accuracy: 0.9709\n",
            "Epoch 153/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.1606 - val_accuracy: 0.9720\n",
            "Epoch 154/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1630 - val_accuracy: 0.9723\n",
            "Epoch 155/200\n",
            "416/416 [==============================] - 46s 112ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.1528 - val_accuracy: 0.9737\n",
            "Epoch 156/200\n",
            "416/416 [==============================] - 46s 111ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.1821 - val_accuracy: 0.9696\n",
            "Epoch 157/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.1705 - val_accuracy: 0.9712\n",
            "Epoch 158/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.1582 - val_accuracy: 0.9732\n",
            "Epoch 159/200\n",
            "416/416 [==============================] - 46s 111ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.1537 - val_accuracy: 0.9748\n",
            "Epoch 160/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.1562 - val_accuracy: 0.9733\n",
            "Epoch 161/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.1778 - val_accuracy: 0.9704\n",
            "Epoch 162/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.1687 - val_accuracy: 0.9712\n",
            "Epoch 163/200\n",
            "416/416 [==============================] - 46s 111ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.1662 - val_accuracy: 0.9705\n",
            "Epoch 164/200\n",
            "416/416 [==============================] - 46s 111ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.1551 - val_accuracy: 0.9739\n",
            "Epoch 165/200\n",
            "416/416 [==============================] - 46s 111ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.1570 - val_accuracy: 0.9718\n",
            "Epoch 166/200\n",
            "416/416 [==============================] - 46s 111ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.1828 - val_accuracy: 0.9679\n",
            "Epoch 167/200\n",
            "416/416 [==============================] - 46s 110ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.1562 - val_accuracy: 0.9723\n",
            "Epoch 168/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.1593 - val_accuracy: 0.9723\n",
            "Epoch 169/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.1477 - val_accuracy: 0.9745\n",
            "Epoch 170/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 0.1487 - val_accuracy: 0.9750\n",
            "Epoch 171/200\n",
            "416/416 [==============================] - 48s 114ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.1856 - val_accuracy: 0.9719\n",
            "Epoch 172/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0117 - accuracy: 0.9971 - val_loss: 0.1525 - val_accuracy: 0.9718\n",
            "Epoch 173/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.1580 - val_accuracy: 0.9726\n",
            "Epoch 174/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.1725 - val_accuracy: 0.9731\n",
            "Epoch 175/200\n",
            "416/416 [==============================] - 48s 116ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.1672 - val_accuracy: 0.9719\n",
            "Epoch 176/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.1689 - val_accuracy: 0.9710\n",
            "Epoch 177/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.1524 - val_accuracy: 0.9719\n",
            "Epoch 178/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.1579 - val_accuracy: 0.9720\n",
            "Epoch 179/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.1701 - val_accuracy: 0.9725\n",
            "Epoch 180/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.1750 - val_accuracy: 0.9699\n",
            "Epoch 181/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.1683 - val_accuracy: 0.9720\n",
            "Epoch 182/200\n",
            "416/416 [==============================] - 48s 114ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.1728 - val_accuracy: 0.9725\n",
            "Epoch 183/200\n",
            "416/416 [==============================] - 48s 114ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1588 - val_accuracy: 0.9740\n",
            "Epoch 184/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.1563 - val_accuracy: 0.9737\n",
            "Epoch 185/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.1590 - val_accuracy: 0.9724\n",
            "Epoch 186/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.1674 - val_accuracy: 0.9717\n",
            "Epoch 187/200\n",
            "416/416 [==============================] - 47s 112ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.1602 - val_accuracy: 0.9742\n",
            "Epoch 188/200\n",
            "416/416 [==============================] - 47s 113ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.1805 - val_accuracy: 0.9720\n",
            "Epoch 189/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.1576 - val_accuracy: 0.9736\n",
            "Epoch 190/200\n",
            "416/416 [==============================] - 48s 114ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.1648 - val_accuracy: 0.9748\n",
            "Epoch 191/200\n",
            "416/416 [==============================] - 48s 116ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1570 - val_accuracy: 0.9742\n",
            "Epoch 192/200\n",
            "416/416 [==============================] - 48s 116ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.2017 - val_accuracy: 0.9684\n",
            "Epoch 193/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.1864 - val_accuracy: 0.9690\n",
            "Epoch 194/200\n",
            "416/416 [==============================] - 47s 114ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.1607 - val_accuracy: 0.9732\n",
            "Epoch 195/200\n",
            "416/416 [==============================] - 48s 114ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.1438 - val_accuracy: 0.9761\n",
            "Epoch 196/200\n",
            "416/416 [==============================] - 48s 116ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.1597 - val_accuracy: 0.9717\n",
            "Epoch 197/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.1610 - val_accuracy: 0.9739\n",
            "Epoch 198/200\n",
            "416/416 [==============================] - 48s 114ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.1466 - val_accuracy: 0.9754\n",
            "Epoch 199/200\n",
            "416/416 [==============================] - 48s 115ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.1837 - val_accuracy: 0.9723\n",
            "Epoch 200/200\n",
            "416/416 [==============================] - 48s 114ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.1704 - val_accuracy: 0.9738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_validation, y_validation, verbose=False)\n",
        "print(\"Validation Accuracy:  {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy: {:.4f}\".format(accuracy))"
      ],
      "metadata": {
        "id": "qrh_lRGbZUve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "772d7394-152f-40f7-89da-c9858331d8b9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy:  0.9738\n",
            "Testing Accuracy: 0.8855\n"
          ]
        }
      ]
    }
  ]
}
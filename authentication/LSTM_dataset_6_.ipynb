{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM / dataset 6 .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60sYXkj6uiHr",
        "outputId": "8f2b09a4-50b9-4402-8e0d-aee1f1a4c6f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Mounted at /content/gdrive\n",
            "(66542, 128, 12) (66542, 2) (7600, 128, 12) (7600, 2)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/'  #change dir to your project folder\n",
        "\n",
        "import numpy as np\n",
        "x_train = np.load('gdrive/My Drive/dataset/dataset6/trainX.npy')\n",
        "y_train = np.load('gdrive/My Drive/dataset/dataset6/trainy.npy')\n",
        "x_test = np.load('gdrive/My Drive/dataset/dataset6/testX.npy')\n",
        "y_test = np.load('gdrive/My Drive/dataset/dataset6/testy.npy')\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "from numpy import save, load\n",
        "from pandas import read_csv\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras import Model\n",
        "from keras.layers import LSTM, Conv1D, concatenate,GlobalMaxPooling1D,TimeDistributed, MaxPooling1D\n",
        "from matplotlib import pyplot\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "7GIfDLRKu09B"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_training, X_validation, y_training, y_validation = train_test_split(x_train, y_train, test_size=0.20, random_state=42)\n"
      ],
      "metadata": {
        "id": "FYBVYgWhvAXm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_timesteps, n_features, n_outputs = x_train.shape[1], x_train.shape[2], y_train.shape[1]\n"
      ],
      "metadata": {
        "id": "bNn9TzlDvLvG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential()\n",
        "model1.add(LSTM(500, input_shape=(n_timesteps,n_features)))\n",
        "model1.add(Dense(340, activation='relu'))\n",
        "model1.add(Dropout(0.1))\n",
        "model1.add(Dense(100, activation='relu'))\n",
        "model1.add(Dense(n_outputs, activation='softmax'))\n",
        "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model1.summary()\n",
        "callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights= True)]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeLlRAkUvRD_",
        "outputId": "778799ed-5aa2-442a-a6c7-6088ce96c810"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 500)               1026000   \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 340)               170340    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 340)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 100)               34100     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,230,642\n",
            "Trainable params: 1,230,642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model1.fit(X_training, y_training, epochs=200, verbose=True, validation_data=(X_validation, y_validation), batch_size=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqLqyRGUvT3H",
        "outputId": "3f8d296c-b126-4120-a38e-2c566005938f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "533/533 [==============================] - 22s 41ms/step - loss: 0.2319 - accuracy: 0.9071 - val_loss: 0.2388 - val_accuracy: 0.9032\n",
            "Epoch 2/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.2063 - accuracy: 0.9173 - val_loss: 0.2010 - val_accuracy: 0.9219\n",
            "Epoch 3/200\n",
            "533/533 [==============================] - 23s 43ms/step - loss: 0.1767 - accuracy: 0.9304 - val_loss: 0.1794 - val_accuracy: 0.9273\n",
            "Epoch 4/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.1565 - accuracy: 0.9398 - val_loss: 0.1734 - val_accuracy: 0.9320\n",
            "Epoch 5/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.1406 - accuracy: 0.9457 - val_loss: 0.1589 - val_accuracy: 0.9388\n",
            "Epoch 6/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.1241 - accuracy: 0.9528 - val_loss: 0.1477 - val_accuracy: 0.9457\n",
            "Epoch 7/200\n",
            "533/533 [==============================] - 23s 42ms/step - loss: 0.1043 - accuracy: 0.9601 - val_loss: 0.1455 - val_accuracy: 0.9491\n",
            "Epoch 8/200\n",
            "533/533 [==============================] - 23s 42ms/step - loss: 0.0942 - accuracy: 0.9647 - val_loss: 0.1389 - val_accuracy: 0.9487\n",
            "Epoch 9/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0854 - accuracy: 0.9678 - val_loss: 0.1296 - val_accuracy: 0.9519\n",
            "Epoch 10/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0752 - accuracy: 0.9717 - val_loss: 0.1423 - val_accuracy: 0.9518\n",
            "Epoch 11/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0676 - accuracy: 0.9742 - val_loss: 0.1342 - val_accuracy: 0.9546\n",
            "Epoch 12/200\n",
            "533/533 [==============================] - 23s 43ms/step - loss: 0.0582 - accuracy: 0.9783 - val_loss: 0.1275 - val_accuracy: 0.9539\n",
            "Epoch 13/200\n",
            "533/533 [==============================] - 23s 42ms/step - loss: 0.0491 - accuracy: 0.9818 - val_loss: 0.1465 - val_accuracy: 0.9513\n",
            "Epoch 14/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0499 - accuracy: 0.9813 - val_loss: 0.1342 - val_accuracy: 0.9587\n",
            "Epoch 15/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0451 - accuracy: 0.9833 - val_loss: 0.1344 - val_accuracy: 0.9573\n",
            "Epoch 16/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0378 - accuracy: 0.9861 - val_loss: 0.1427 - val_accuracy: 0.9595\n",
            "Epoch 17/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0373 - accuracy: 0.9862 - val_loss: 0.1313 - val_accuracy: 0.9604\n",
            "Epoch 18/200\n",
            "533/533 [==============================] - 23s 42ms/step - loss: 0.0322 - accuracy: 0.9882 - val_loss: 0.1388 - val_accuracy: 0.9603\n",
            "Epoch 19/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0324 - accuracy: 0.9881 - val_loss: 0.1577 - val_accuracy: 0.9571\n",
            "Epoch 20/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0341 - accuracy: 0.9876 - val_loss: 0.1446 - val_accuracy: 0.9607\n",
            "Epoch 21/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0277 - accuracy: 0.9906 - val_loss: 0.1655 - val_accuracy: 0.9601\n",
            "Epoch 22/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0227 - accuracy: 0.9919 - val_loss: 0.1394 - val_accuracy: 0.9594\n",
            "Epoch 23/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0244 - accuracy: 0.9913 - val_loss: 0.1486 - val_accuracy: 0.9604\n",
            "Epoch 24/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 0.1700 - val_accuracy: 0.9612\n",
            "Epoch 25/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0192 - accuracy: 0.9936 - val_loss: 0.1534 - val_accuracy: 0.9617\n",
            "Epoch 26/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0210 - accuracy: 0.9928 - val_loss: 0.1601 - val_accuracy: 0.9627\n",
            "Epoch 27/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0211 - accuracy: 0.9929 - val_loss: 0.1723 - val_accuracy: 0.9614\n",
            "Epoch 28/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0210 - accuracy: 0.9926 - val_loss: 0.1495 - val_accuracy: 0.9627\n",
            "Epoch 29/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.1605 - val_accuracy: 0.9636\n",
            "Epoch 30/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.1691 - val_accuracy: 0.9630\n",
            "Epoch 31/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0177 - accuracy: 0.9940 - val_loss: 0.1460 - val_accuracy: 0.9639\n",
            "Epoch 32/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0172 - accuracy: 0.9940 - val_loss: 0.1735 - val_accuracy: 0.9643\n",
            "Epoch 33/200\n",
            "533/533 [==============================] - 23s 42ms/step - loss: 0.0174 - accuracy: 0.9941 - val_loss: 0.1544 - val_accuracy: 0.9615\n",
            "Epoch 34/200\n",
            "533/533 [==============================] - 23s 43ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.1651 - val_accuracy: 0.9645\n",
            "Epoch 35/200\n",
            "533/533 [==============================] - 23s 42ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.1944 - val_accuracy: 0.9636\n",
            "Epoch 36/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.1732 - val_accuracy: 0.9628\n",
            "Epoch 37/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.1790 - val_accuracy: 0.9627\n",
            "Epoch 38/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.1547 - val_accuracy: 0.9649\n",
            "Epoch 39/200\n",
            "533/533 [==============================] - 23s 42ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.1828 - val_accuracy: 0.9643\n",
            "Epoch 40/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.1365 - val_accuracy: 0.9645\n",
            "Epoch 41/200\n",
            "533/533 [==============================] - 23s 42ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.2057 - val_accuracy: 0.9625\n",
            "Epoch 42/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 0.1674 - val_accuracy: 0.9648\n",
            "Epoch 43/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.1860 - val_accuracy: 0.9655\n",
            "Epoch 44/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.1658 - val_accuracy: 0.9641\n",
            "Epoch 45/200\n",
            "533/533 [==============================] - 23s 42ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.1991 - val_accuracy: 0.9630\n",
            "Epoch 46/200\n",
            "533/533 [==============================] - 23s 42ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.1622 - val_accuracy: 0.9672\n",
            "Epoch 47/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.1682 - val_accuracy: 0.9667\n",
            "Epoch 48/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.1634 - val_accuracy: 0.9653\n",
            "Epoch 49/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 0.1783 - val_accuracy: 0.9629\n",
            "Epoch 50/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.1746 - val_accuracy: 0.9645\n",
            "Epoch 51/200\n",
            "533/533 [==============================] - 23s 42ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.1842 - val_accuracy: 0.9636\n",
            "Epoch 52/200\n",
            "533/533 [==============================] - 23s 42ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.1655 - val_accuracy: 0.9664\n",
            "Epoch 53/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.1664 - val_accuracy: 0.9689\n",
            "Epoch 54/200\n",
            "533/533 [==============================] - 23s 42ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.2011 - val_accuracy: 0.9648\n",
            "Epoch 55/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 0.1763 - val_accuracy: 0.9653\n",
            "Epoch 56/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.1676 - val_accuracy: 0.9632\n",
            "Epoch 57/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.2013 - val_accuracy: 0.9678\n",
            "Epoch 58/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1494 - val_accuracy: 0.9661\n",
            "Epoch 59/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.1716 - val_accuracy: 0.9666\n",
            "Epoch 60/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.1887 - val_accuracy: 0.9672\n",
            "Epoch 61/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.1792 - val_accuracy: 0.9654\n",
            "Epoch 62/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.1828 - val_accuracy: 0.9669\n",
            "Epoch 63/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.1984 - val_accuracy: 0.9625\n",
            "Epoch 64/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.1714 - val_accuracy: 0.9647\n",
            "Epoch 65/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.1883 - val_accuracy: 0.9667\n",
            "Epoch 66/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.2035 - val_accuracy: 0.9674\n",
            "Epoch 67/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.1772 - val_accuracy: 0.9658\n",
            "Epoch 68/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.2041 - val_accuracy: 0.9657\n",
            "Epoch 69/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.1792 - val_accuracy: 0.9656\n",
            "Epoch 70/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.2210 - val_accuracy: 0.9657\n",
            "Epoch 71/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.2071 - val_accuracy: 0.9643\n",
            "Epoch 72/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.1679 - val_accuracy: 0.9657\n",
            "Epoch 73/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.2196 - val_accuracy: 0.9630\n",
            "Epoch 74/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1554 - val_accuracy: 0.9679\n",
            "Epoch 75/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.1616 - val_accuracy: 0.9661\n",
            "Epoch 76/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.2377 - val_accuracy: 0.9682\n",
            "Epoch 77/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.1600 - val_accuracy: 0.9668\n",
            "Epoch 78/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.1670 - val_accuracy: 0.9667\n",
            "Epoch 79/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.1562 - val_accuracy: 0.9668\n",
            "Epoch 80/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.1793 - val_accuracy: 0.9681\n",
            "Epoch 81/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1645 - val_accuracy: 0.9689\n",
            "Epoch 82/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.1826 - val_accuracy: 0.9672\n",
            "Epoch 83/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.1719 - val_accuracy: 0.9677\n",
            "Epoch 84/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 0.1975 - val_accuracy: 0.9687\n",
            "Epoch 85/200\n",
            "533/533 [==============================] - 23s 43ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.1686 - val_accuracy: 0.9663\n",
            "Epoch 86/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.1448 - val_accuracy: 0.9690\n",
            "Epoch 87/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.1510 - val_accuracy: 0.9672\n",
            "Epoch 88/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.1759 - val_accuracy: 0.9663\n",
            "Epoch 89/200\n",
            "533/533 [==============================] - 23s 43ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.1657 - val_accuracy: 0.9660\n",
            "Epoch 90/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.1767 - val_accuracy: 0.9678\n",
            "Epoch 91/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.1727 - val_accuracy: 0.9697\n",
            "Epoch 92/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.1865 - val_accuracy: 0.9684\n",
            "Epoch 93/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1838 - val_accuracy: 0.9682\n",
            "Epoch 94/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.1898 - val_accuracy: 0.9645\n",
            "Epoch 95/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.1461 - val_accuracy: 0.9667\n",
            "Epoch 96/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.1813 - val_accuracy: 0.9679\n",
            "Epoch 97/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.1848 - val_accuracy: 0.9656\n",
            "Epoch 98/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.2072 - val_accuracy: 0.9654\n",
            "Epoch 99/200\n",
            "533/533 [==============================] - 23s 43ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.1901 - val_accuracy: 0.9684\n",
            "Epoch 100/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.2198 - val_accuracy: 0.9660\n",
            "Epoch 101/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.1611 - val_accuracy: 0.9711\n",
            "Epoch 102/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.2017 - val_accuracy: 0.9652\n",
            "Epoch 103/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.1881 - val_accuracy: 0.9685\n",
            "Epoch 104/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.1920 - val_accuracy: 0.9711\n",
            "Epoch 105/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.1788 - val_accuracy: 0.9673\n",
            "Epoch 106/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 0.1596 - val_accuracy: 0.9678\n",
            "Epoch 107/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1857 - val_accuracy: 0.9686\n",
            "Epoch 108/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.2175 - val_accuracy: 0.9678\n",
            "Epoch 109/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.2032 - val_accuracy: 0.9681\n",
            "Epoch 110/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.2011 - val_accuracy: 0.9679\n",
            "Epoch 111/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1856 - val_accuracy: 0.9651\n",
            "Epoch 112/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.2052 - val_accuracy: 0.9669\n",
            "Epoch 113/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.2604 - val_accuracy: 0.9664\n",
            "Epoch 114/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.1855 - val_accuracy: 0.9674\n",
            "Epoch 115/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.2004 - val_accuracy: 0.9656\n",
            "Epoch 116/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.2221 - val_accuracy: 0.9678\n",
            "Epoch 117/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.2006 - val_accuracy: 0.9675\n",
            "Epoch 118/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.2532 - val_accuracy: 0.9694\n",
            "Epoch 119/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.2183 - val_accuracy: 0.9682\n",
            "Epoch 120/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.2052 - val_accuracy: 0.9684\n",
            "Epoch 121/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.1756 - val_accuracy: 0.9681\n",
            "Epoch 122/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.2072 - val_accuracy: 0.9693\n",
            "Epoch 123/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.1635 - val_accuracy: 0.9684\n",
            "Epoch 124/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.2040 - val_accuracy: 0.9677\n",
            "Epoch 125/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1903 - val_accuracy: 0.9701\n",
            "Epoch 126/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 8.7543e-04 - accuracy: 0.9998 - val_loss: 0.2425 - val_accuracy: 0.9702\n",
            "Epoch 127/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.1869 - val_accuracy: 0.9618\n",
            "Epoch 128/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.1789 - val_accuracy: 0.9675\n",
            "Epoch 129/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.2265 - val_accuracy: 0.9690\n",
            "Epoch 130/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.2000 - val_accuracy: 0.9688\n",
            "Epoch 131/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.2123 - val_accuracy: 0.9669\n",
            "Epoch 132/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.2031 - val_accuracy: 0.9671\n",
            "Epoch 133/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.1782 - val_accuracy: 0.9680\n",
            "Epoch 134/200\n",
            "533/533 [==============================] - 23s 43ms/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.1728 - val_accuracy: 0.9669\n",
            "Epoch 135/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0063 - accuracy: 0.9977 - val_loss: 0.2186 - val_accuracy: 0.9672\n",
            "Epoch 136/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.2212 - val_accuracy: 0.9681\n",
            "Epoch 137/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.2031 - val_accuracy: 0.9671\n",
            "Epoch 138/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.2184 - val_accuracy: 0.9687\n",
            "Epoch 139/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.2156 - val_accuracy: 0.9657\n",
            "Epoch 140/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.2312 - val_accuracy: 0.9678\n",
            "Epoch 141/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.2173 - val_accuracy: 0.9687\n",
            "Epoch 142/200\n",
            "533/533 [==============================] - 23s 42ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.1990 - val_accuracy: 0.9667\n",
            "Epoch 143/200\n",
            "533/533 [==============================] - 23s 43ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.1781 - val_accuracy: 0.9669\n",
            "Epoch 144/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1900 - val_accuracy: 0.9705\n",
            "Epoch 145/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.1854 - val_accuracy: 0.9692\n",
            "Epoch 146/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.2317 - val_accuracy: 0.9672\n",
            "Epoch 147/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.1777 - val_accuracy: 0.9690\n",
            "Epoch 148/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.1678 - val_accuracy: 0.9701\n",
            "Epoch 149/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.2182 - val_accuracy: 0.9685\n",
            "Epoch 150/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.1540 - val_accuracy: 0.9667\n",
            "Epoch 151/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.2186 - val_accuracy: 0.9657\n",
            "Epoch 152/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.2678 - val_accuracy: 0.9672\n",
            "Epoch 153/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.1874 - val_accuracy: 0.9679\n",
            "Epoch 154/200\n",
            "533/533 [==============================] - 23s 43ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.1868 - val_accuracy: 0.9676\n",
            "Epoch 155/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.2248 - val_accuracy: 0.9658\n",
            "Epoch 156/200\n",
            "533/533 [==============================] - 23s 42ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.1701 - val_accuracy: 0.9693\n",
            "Epoch 157/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.1684 - val_accuracy: 0.9639\n",
            "Epoch 158/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.1805 - val_accuracy: 0.9691\n",
            "Epoch 159/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.2050 - val_accuracy: 0.9664\n",
            "Epoch 160/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.2089 - val_accuracy: 0.9667\n",
            "Epoch 161/200\n",
            "533/533 [==============================] - 23s 42ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.2044 - val_accuracy: 0.9684\n",
            "Epoch 162/200\n",
            "533/533 [==============================] - 23s 43ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.2303 - val_accuracy: 0.9654\n",
            "Epoch 163/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.2001 - val_accuracy: 0.9689\n",
            "Epoch 164/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.1448 - val_accuracy: 0.9678\n",
            "Epoch 165/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.1642 - val_accuracy: 0.9681\n",
            "Epoch 166/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.1879 - val_accuracy: 0.9666\n",
            "Epoch 167/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.1886 - val_accuracy: 0.9668\n",
            "Epoch 168/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.2376 - val_accuracy: 0.9653\n",
            "Epoch 169/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.2182 - val_accuracy: 0.9661\n",
            "Epoch 170/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.2027 - val_accuracy: 0.9678\n",
            "Epoch 171/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.2244 - val_accuracy: 0.9694\n",
            "Epoch 172/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.3261 - val_accuracy: 0.9685\n",
            "Epoch 173/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.1769 - val_accuracy: 0.9668\n",
            "Epoch 174/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.2678 - val_accuracy: 0.9655\n",
            "Epoch 175/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.2283 - val_accuracy: 0.9677\n",
            "Epoch 176/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.1960 - val_accuracy: 0.9652\n",
            "Epoch 177/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 0.1533 - val_accuracy: 0.9623\n",
            "Epoch 178/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0169 - accuracy: 0.9941 - val_loss: 0.1807 - val_accuracy: 0.9648\n",
            "Epoch 179/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.2480 - val_accuracy: 0.9669\n",
            "Epoch 180/200\n",
            "533/533 [==============================] - 23s 42ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.3102 - val_accuracy: 0.9651\n",
            "Epoch 181/200\n",
            "533/533 [==============================] - 23s 42ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.2860 - val_accuracy: 0.9662\n",
            "Epoch 182/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.2126 - val_accuracy: 0.9651\n",
            "Epoch 183/200\n",
            "533/533 [==============================] - 23s 42ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.2532 - val_accuracy: 0.9643\n",
            "Epoch 184/200\n",
            "533/533 [==============================] - 23s 42ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.2878 - val_accuracy: 0.9654\n",
            "Epoch 185/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.2971 - val_accuracy: 0.9639\n",
            "Epoch 186/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.2839 - val_accuracy: 0.9660\n",
            "Epoch 187/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.2822 - val_accuracy: 0.9660\n",
            "Epoch 188/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.2450 - val_accuracy: 0.9672\n",
            "Epoch 189/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.3003 - val_accuracy: 0.9651\n",
            "Epoch 190/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.2607 - val_accuracy: 0.9669\n",
            "Epoch 191/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.2643 - val_accuracy: 0.9659\n",
            "Epoch 192/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.2790 - val_accuracy: 0.9660\n",
            "Epoch 193/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.2293 - val_accuracy: 0.9651\n",
            "Epoch 194/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.1873 - val_accuracy: 0.9660\n",
            "Epoch 195/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.2297 - val_accuracy: 0.9679\n",
            "Epoch 196/200\n",
            "533/533 [==============================] - 23s 42ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.2414 - val_accuracy: 0.9661\n",
            "Epoch 197/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.2340 - val_accuracy: 0.9689\n",
            "Epoch 198/200\n",
            "533/533 [==============================] - 23s 42ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.2146 - val_accuracy: 0.9663\n",
            "Epoch 199/200\n",
            "533/533 [==============================] - 22s 42ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.2453 - val_accuracy: 0.9692\n",
            "Epoch 200/200\n",
            "533/533 [==============================] - 23s 43ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.2783 - val_accuracy: 0.9676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model1.evaluate(X_validation, y_validation, verbose=False)\n",
        "print(\"Validation Accuracy:  {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model1.evaluate(x_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy: {:.4f}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-hmFpgavXOJ",
        "outputId": "7feb6220-40e6-4380-e926-44eb5379c5ed"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy:  0.9676\n",
            "Testing Accuracy: 0.9126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3Zu2sgv9vY8d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "490615f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from numpy import save, load\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras import Model\n",
    "from keras.layers import LSTM, Conv1D, concatenate,GlobalMaxPooling1D,TimeDistributed, MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e0a2ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "\treturn dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cace638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        scaler = StandardScaler()\n",
    "        data = scaler.fit_transform(data)\n",
    "        loaded.append(data)\n",
    "    # stack group so that features are the 3rd dimension\n",
    "    loaded = dstack(loaded)\n",
    "    return loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12d9146c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_group(group, prefix=''):\n",
    "\tfilepath = prefix + group + '/Inertial_Signals/'\n",
    "\t# load all 9 files as a single array\n",
    "\tfilenames = list()\n",
    "\t# body acceleration\n",
    "\t#filenames += ['acc_x.txt', 'acc_y.txt', 'acc_z.txt']\n",
    "\t# body gyroscope\n",
    "\tfilenames += ['gyr_x.txt', 'gyr_y.txt', 'gyr_z.txt']\n",
    "\t# load input data\n",
    "\tX = load_group(filenames, filepath)\n",
    "\t# load class output\n",
    "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e46b3e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(prefix=''):\n",
    "\t# load all train\n",
    "\ttrainX, trainy = load_dataset_group('train', prefix + 'Dataset1/')\n",
    "\t# load all test\n",
    "\ttestX, testy = load_dataset_group('test', prefix + 'Dataset1/')\n",
    "\t# zero-offset class values\n",
    "\ttrainy = trainy - 1\n",
    "\ttesty = testy - 1\n",
    "\t# one hot encode y\n",
    "\ttrainy = to_categorical(trainy)\n",
    "\ttesty = to_categorical(testy)\n",
    "\treturn trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20534ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainy, testX, testy=load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27cd4b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33104, 128, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "485b681b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3740, 128, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "600f41bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save('trainX.npy', trainX)\n",
    "save('trainY.npy', trainy)\n",
    "save('testX.npy', testX)\n",
    "save('testY.npy', testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cbb2692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33104, 128, 3) (33104, 118) (3740, 128, 3) (3740, 118)\n"
     ]
    }
   ],
   "source": [
    "X_train = load('trainX.npy')\n",
    "X_test = load('testX.npy')\n",
    "y_train = load('trainy.npy')\n",
    "y_test = load('testy.npy')\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55e3f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_training, X_validation, y_training, y_validation = train_test_split(X_train, y_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5392b512",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0ef7473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 500)               1008000   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 340)               170340    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 340)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               34100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 118)               11918     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,224,358\n",
      "Trainable params: 1,224,358\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(LSTM(500, input_shape=(n_timesteps,n_features)))\n",
    "model1.add(Dense(340, activation='relu'))\n",
    "model1.add(Dropout(0.1))\n",
    "model1.add(Dense(100, activation='relu'))\n",
    "model1.add(Dense(n_outputs, activation='softmax'))\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0e2af0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model1.fit(X_training, y_training, epochs=10, verbose=False, validation_data=(X_validation, y_validation), batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8b825ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.9112\n",
      "Testing Accuracy: 0.8487\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model1.evaluate(X_validation, y_validation, verbose=False)\n",
    "print(\"Validation Accuracy:  {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model1.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0da50f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

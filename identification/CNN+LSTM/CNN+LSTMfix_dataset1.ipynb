{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDZ6vXdUtrsp",
        "outputId": "ed864463-54a4-4ff0-d094-296ed3d28903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Mounted at /content/gdrive\n",
            "(33104, 128, 6) (33104, 118) (3740, 128, 6) (3740, 118)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/'  #change dir to your project folder\n",
        "\n",
        "import numpy as np\n",
        "X_train = np.load('gdrive/My Drive/dataset/acc+gyr/trainX.npy')\n",
        "y_train = np.load('gdrive/My Drive/dataset1/acc+gyr/trainy.npy')\n",
        "X_test = np.load('gdrive/My Drive/dataset1/acc+gyr/testX.npy')\n",
        "y_test = np.load('gdrive/My Drive/dataset1/acc+gyr/testy.npy')\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "from numpy import save, load\n",
        "from pandas import read_csv\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense , Input ,concatenate\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import LSTM, Conv1D, concatenate,GlobalMaxPooling1D,TimeDistributed, MaxPooling1D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "-Qkx_EZ2uxRJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_training, X_validation, y_training, y_validation = train_test_split(X_train, y_train, test_size=0.20, random_state=42)\n",
        "n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
        "validation_data=(X_validation, y_validation)"
      ],
      "metadata": {
        "id": "QRMig4JduxUD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_model= Sequential()\n",
        "LSTM_model.add(LSTM(512,input_shape=(n_timesteps,n_features),return_sequences=True))\n",
        "LSTM_model.add(LSTM(256))\n",
        "LSTM_model.add(Dropout(0.2))\n",
        "LSTM_model.add(Dense(128, activation='relu'))\n",
        "LSTM_model.add(Dense(n_outputs, activation='softmax'))\n",
        "LSTM_model.summary()\n",
        "LSTM_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]\n",
        "LSTM_model.fit(X_training, y_training, epochs=200, verbose=True, validation_data=(X_validation, y_validation), batch_size=128,callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt-4cl-yuxXF",
        "outputId": "cc9ca876-125d-4247-e459-c862b5cc61e2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_11 (LSTM)              (None, 128, 512)          1062912   \n",
            "                                                                 \n",
            " lstm_12 (LSTM)              (None, 256)               787456    \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 118)               15222     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,898,486\n",
            "Trainable params: 1,898,486\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "207/207 [==============================] - 20s 81ms/step - loss: 2.2055 - accuracy: 0.4419 - val_loss: 1.0286 - val_accuracy: 0.7295\n",
            "Epoch 2/200\n",
            "207/207 [==============================] - 16s 78ms/step - loss: 0.8278 - accuracy: 0.7770 - val_loss: 0.5851 - val_accuracy: 0.8467\n",
            "Epoch 3/200\n",
            "207/207 [==============================] - 17s 81ms/step - loss: 0.5378 - accuracy: 0.8566 - val_loss: 0.4480 - val_accuracy: 0.8768\n",
            "Epoch 4/200\n",
            "207/207 [==============================] - 17s 81ms/step - loss: 0.3917 - accuracy: 0.8939 - val_loss: 0.3330 - val_accuracy: 0.9055\n",
            "Epoch 5/200\n",
            "207/207 [==============================] - 17s 80ms/step - loss: 0.3281 - accuracy: 0.9096 - val_loss: 0.3201 - val_accuracy: 0.9136\n",
            "Epoch 6/200\n",
            "207/207 [==============================] - 17s 80ms/step - loss: 0.2909 - accuracy: 0.9178 - val_loss: 0.3106 - val_accuracy: 0.9091\n",
            "Epoch 7/200\n",
            "207/207 [==============================] - 17s 81ms/step - loss: 0.2246 - accuracy: 0.9360 - val_loss: 0.2279 - val_accuracy: 0.9354\n",
            "Epoch 8/200\n",
            "207/207 [==============================] - 17s 81ms/step - loss: 0.2222 - accuracy: 0.9340 - val_loss: 0.2165 - val_accuracy: 0.9400\n",
            "Epoch 9/200\n",
            "207/207 [==============================] - 17s 81ms/step - loss: 0.1658 - accuracy: 0.9533 - val_loss: 0.2163 - val_accuracy: 0.9363\n",
            "Epoch 10/200\n",
            "207/207 [==============================] - 17s 80ms/step - loss: 0.1592 - accuracy: 0.9528 - val_loss: 0.1999 - val_accuracy: 0.9437\n",
            "Epoch 11/200\n",
            "207/207 [==============================] - 17s 80ms/step - loss: 0.1422 - accuracy: 0.9586 - val_loss: 0.1699 - val_accuracy: 0.9545\n",
            "Epoch 12/200\n",
            "207/207 [==============================] - 17s 80ms/step - loss: 0.1333 - accuracy: 0.9614 - val_loss: 0.2308 - val_accuracy: 0.9414\n",
            "Epoch 13/200\n",
            "207/207 [==============================] - 17s 80ms/step - loss: 0.1443 - accuracy: 0.9570 - val_loss: 0.1814 - val_accuracy: 0.9520\n",
            "Epoch 14/200\n",
            "207/207 [==============================] - 17s 80ms/step - loss: 0.1183 - accuracy: 0.9661 - val_loss: 0.1572 - val_accuracy: 0.9576\n",
            "Epoch 15/200\n",
            "207/207 [==============================] - 17s 81ms/step - loss: 0.0923 - accuracy: 0.9728 - val_loss: 0.1506 - val_accuracy: 0.9613\n",
            "Epoch 16/200\n",
            "207/207 [==============================] - 17s 80ms/step - loss: 0.1085 - accuracy: 0.9677 - val_loss: 0.1503 - val_accuracy: 0.9592\n",
            "Epoch 17/200\n",
            "207/207 [==============================] - 17s 80ms/step - loss: 0.0949 - accuracy: 0.9718 - val_loss: 0.1385 - val_accuracy: 0.9633\n",
            "Epoch 18/200\n",
            "207/207 [==============================] - 16s 79ms/step - loss: 0.0936 - accuracy: 0.9716 - val_loss: 0.1536 - val_accuracy: 0.9597\n",
            "Epoch 19/200\n",
            "207/207 [==============================] - 16s 78ms/step - loss: 0.0708 - accuracy: 0.9789 - val_loss: 0.1242 - val_accuracy: 0.9693\n",
            "Epoch 20/200\n",
            "207/207 [==============================] - 16s 79ms/step - loss: 0.0760 - accuracy: 0.9769 - val_loss: 0.1627 - val_accuracy: 0.9570\n",
            "Epoch 21/200\n",
            "207/207 [==============================] - 17s 80ms/step - loss: 0.0875 - accuracy: 0.9732 - val_loss: 0.1567 - val_accuracy: 0.9618\n",
            "Epoch 22/200\n",
            "207/207 [==============================] - 17s 80ms/step - loss: 0.0660 - accuracy: 0.9794 - val_loss: 0.1378 - val_accuracy: 0.9662\n",
            "Epoch 23/200\n",
            "207/207 [==============================] - 17s 81ms/step - loss: 0.0560 - accuracy: 0.9830 - val_loss: 0.1488 - val_accuracy: 0.9601\n",
            "Epoch 24/200\n",
            "207/207 [==============================] - 17s 81ms/step - loss: 0.0670 - accuracy: 0.9790 - val_loss: 0.1464 - val_accuracy: 0.9653\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe29018b0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = LSTM_model.evaluate(X_validation, y_validation, verbose=False)\n",
        "print(\"Validation Accuracy:  {:.4f}\".format(accuracy))\n",
        "loss, accuracy = LSTM_model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy: {:.4f}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF3_pawu3KAS",
        "outputId": "25187fa2-2023-4310-e12e-30a52d74ac5b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy:  0.9693\n",
            "Testing Accuracy: 0.9045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lstm_output_layer_weights_values = LSTM_model.layers[4].get_weights()    \n",
        "LSTM_model.trainable = False\n",
        "\n",
        "CNN_model= Sequential()\n",
        "CNN_model.add(Conv1D(filters=32, kernel_size=9, strides=2, activation='relu', input_shape=(n_timesteps,n_features)))\n",
        "CNN_model.add(MaxPooling1D(pool_size=2 ,strides=2))\n",
        "CNN_model.add(Dropout(0.5))\n",
        "CNN_model.add(Conv1D(filters=64, kernel_size=3, strides=1, activation='relu'))\n",
        "CNN_model.add(Conv1D(filters=128, kernel_size=3, strides=1, activation='relu'))\n",
        "CNN_model.add(MaxPooling1D(pool_size=2 ,strides=2))\n",
        "CNN_model.add(Dropout(0.5))\n",
        "CNN_model.add(Conv1D(filters=128, kernel_size=1, strides=1, activation='relu'))\n",
        "CNN_model.add(Flatten())\n",
        "CNN_model.add(Dense(n_outputs, activation='relu'))\n",
        "CNN_model.summary()\n",
        "\n",
        "\n",
        "inputs = Input(shape=(n_timesteps,n_features))\n",
        "mergedInput= concatenate([CNN_model(inputs),LSTM_model(inputs)])\n",
        "out = Dense(n_outputs, activation='softmax')(mergedInput)\n",
        "model3 = Model(inputs,out)\n",
        "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#model3.layers[0].set_weights(LSTM_model.layers[4].get_weights())\n",
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cM0iBU4uxZ9",
        "outputId": "d023dce1-f5c5-4b9f-9562-87287b66a7b8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_16 (Conv1D)          (None, 60, 32)            1760      \n",
            "                                                                 \n",
            " max_pooling1d_8 (MaxPooling  (None, 30, 32)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 30, 32)            0         \n",
            "                                                                 \n",
            " conv1d_17 (Conv1D)          (None, 28, 64)            6208      \n",
            "                                                                 \n",
            " conv1d_18 (Conv1D)          (None, 26, 128)           24704     \n",
            "                                                                 \n",
            " max_pooling1d_9 (MaxPooling  (None, 13, 128)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 13, 128)           0         \n",
            "                                                                 \n",
            " conv1d_19 (Conv1D)          (None, 13, 128)           16512     \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 1664)              0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 118)               196470    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 245,654\n",
            "Trainable params: 245,654\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 128, 6)]     0           []                               \n",
            "                                                                                                  \n",
            " sequential_11 (Sequential)     (None, 118)          245654      ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " sequential_10 (Sequential)     (None, 118)          1898486     ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 236)          0           ['sequential_11[0][0]',          \n",
            "                                                                  'sequential_10[0][0]']          \n",
            "                                                                                                  \n",
            " dense_21 (Dense)               (None, 118)          27966       ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,172,106\n",
            "Trainable params: 273,620\n",
            "Non-trainable params: 1,898,486\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model3.fit(X_training, y_training, epochs=200, verbose=True, validation_data=(X_validation, y_validation), batch_size=128,callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leAK4cae3mSx",
        "outputId": "88d77121-0db0-42ee-8ed4-95f815c63c28"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "207/207 [==============================] - 12s 42ms/step - loss: 2.4559 - accuracy: 0.4206 - val_loss: 0.8304 - val_accuracy: 0.7946\n",
            "Epoch 2/200\n",
            "207/207 [==============================] - 8s 37ms/step - loss: 0.7548 - accuracy: 0.8094 - val_loss: 0.5119 - val_accuracy: 0.8740\n",
            "Epoch 3/200\n",
            "207/207 [==============================] - 8s 37ms/step - loss: 0.5166 - accuracy: 0.8670 - val_loss: 0.3645 - val_accuracy: 0.9121\n",
            "Epoch 4/200\n",
            "207/207 [==============================] - 8s 37ms/step - loss: 0.4046 - accuracy: 0.8948 - val_loss: 0.3082 - val_accuracy: 0.9218\n",
            "Epoch 5/200\n",
            "207/207 [==============================] - 8s 37ms/step - loss: 0.3422 - accuracy: 0.9110 - val_loss: 0.2689 - val_accuracy: 0.9369\n",
            "Epoch 6/200\n",
            "207/207 [==============================] - 8s 38ms/step - loss: 0.2878 - accuracy: 0.9244 - val_loss: 0.2376 - val_accuracy: 0.9388\n",
            "Epoch 7/200\n",
            "207/207 [==============================] - 8s 38ms/step - loss: 0.2476 - accuracy: 0.9355 - val_loss: 0.2120 - val_accuracy: 0.9471\n",
            "Epoch 8/200\n",
            "207/207 [==============================] - 8s 38ms/step - loss: 0.2161 - accuracy: 0.9432 - val_loss: 0.1933 - val_accuracy: 0.9518\n",
            "Epoch 9/200\n",
            "207/207 [==============================] - 8s 38ms/step - loss: 0.1935 - accuracy: 0.9488 - val_loss: 0.1805 - val_accuracy: 0.9571\n",
            "Epoch 10/200\n",
            "207/207 [==============================] - 8s 38ms/step - loss: 0.1719 - accuracy: 0.9546 - val_loss: 0.1785 - val_accuracy: 0.9533\n",
            "Epoch 11/200\n",
            "207/207 [==============================] - 8s 38ms/step - loss: 0.1539 - accuracy: 0.9577 - val_loss: 0.1800 - val_accuracy: 0.9536\n",
            "Epoch 12/200\n",
            "207/207 [==============================] - 8s 37ms/step - loss: 0.1431 - accuracy: 0.9611 - val_loss: 0.1697 - val_accuracy: 0.9556\n",
            "Epoch 13/200\n",
            "207/207 [==============================] - 8s 37ms/step - loss: 0.1306 - accuracy: 0.9641 - val_loss: 0.1548 - val_accuracy: 0.9615\n",
            "Epoch 14/200\n",
            "207/207 [==============================] - 8s 36ms/step - loss: 0.1178 - accuracy: 0.9682 - val_loss: 0.1476 - val_accuracy: 0.9642\n",
            "Epoch 15/200\n",
            "207/207 [==============================] - 8s 37ms/step - loss: 0.1079 - accuracy: 0.9703 - val_loss: 0.1443 - val_accuracy: 0.9662\n",
            "Epoch 16/200\n",
            "207/207 [==============================] - 8s 36ms/step - loss: 0.0975 - accuracy: 0.9729 - val_loss: 0.1358 - val_accuracy: 0.9677\n",
            "Epoch 17/200\n",
            "207/207 [==============================] - 8s 36ms/step - loss: 0.0917 - accuracy: 0.9737 - val_loss: 0.1347 - val_accuracy: 0.9677\n",
            "Epoch 18/200\n",
            "207/207 [==============================] - 7s 36ms/step - loss: 0.0867 - accuracy: 0.9757 - val_loss: 0.1349 - val_accuracy: 0.9660\n",
            "Epoch 19/200\n",
            "207/207 [==============================] - 7s 36ms/step - loss: 0.0836 - accuracy: 0.9772 - val_loss: 0.1299 - val_accuracy: 0.9698\n",
            "Epoch 20/200\n",
            "207/207 [==============================] - 7s 36ms/step - loss: 0.0756 - accuracy: 0.9790 - val_loss: 0.1376 - val_accuracy: 0.9668\n",
            "Epoch 21/200\n",
            "207/207 [==============================] - 7s 36ms/step - loss: 0.0738 - accuracy: 0.9793 - val_loss: 0.1236 - val_accuracy: 0.9699\n",
            "Epoch 22/200\n",
            "207/207 [==============================] - 8s 36ms/step - loss: 0.0679 - accuracy: 0.9815 - val_loss: 0.1218 - val_accuracy: 0.9699\n",
            "Epoch 23/200\n",
            "207/207 [==============================] - 8s 36ms/step - loss: 0.0652 - accuracy: 0.9824 - val_loss: 0.1214 - val_accuracy: 0.9701\n",
            "Epoch 24/200\n",
            "207/207 [==============================] - 8s 37ms/step - loss: 0.0621 - accuracy: 0.9824 - val_loss: 0.1219 - val_accuracy: 0.9698\n",
            "Epoch 25/200\n",
            "207/207 [==============================] - 9s 42ms/step - loss: 0.0576 - accuracy: 0.9836 - val_loss: 0.1203 - val_accuracy: 0.9705\n",
            "Epoch 26/200\n",
            "207/207 [==============================] - 8s 36ms/step - loss: 0.0548 - accuracy: 0.9849 - val_loss: 0.1263 - val_accuracy: 0.9699\n",
            "Epoch 27/200\n",
            "207/207 [==============================] - 8s 37ms/step - loss: 0.0526 - accuracy: 0.9850 - val_loss: 0.1224 - val_accuracy: 0.9699\n",
            "Epoch 28/200\n",
            "207/207 [==============================] - 7s 36ms/step - loss: 0.0520 - accuracy: 0.9855 - val_loss: 0.1162 - val_accuracy: 0.9718\n",
            "Epoch 29/200\n",
            "207/207 [==============================] - 8s 36ms/step - loss: 0.0481 - accuracy: 0.9870 - val_loss: 0.1171 - val_accuracy: 0.9718\n",
            "Epoch 30/200\n",
            "207/207 [==============================] - 7s 36ms/step - loss: 0.0476 - accuracy: 0.9877 - val_loss: 0.1127 - val_accuracy: 0.9719\n",
            "Epoch 31/200\n",
            "207/207 [==============================] - 7s 36ms/step - loss: 0.0439 - accuracy: 0.9883 - val_loss: 0.1147 - val_accuracy: 0.9736\n",
            "Epoch 32/200\n",
            "207/207 [==============================] - 7s 36ms/step - loss: 0.0442 - accuracy: 0.9877 - val_loss: 0.1141 - val_accuracy: 0.9733\n",
            "Epoch 33/200\n",
            "207/207 [==============================] - 7s 36ms/step - loss: 0.0400 - accuracy: 0.9894 - val_loss: 0.1147 - val_accuracy: 0.9702\n",
            "Epoch 34/200\n",
            "207/207 [==============================] - 7s 36ms/step - loss: 0.0398 - accuracy: 0.9891 - val_loss: 0.1224 - val_accuracy: 0.9707\n",
            "Epoch 35/200\n",
            "207/207 [==============================] - 7s 36ms/step - loss: 0.0387 - accuracy: 0.9891 - val_loss: 0.1191 - val_accuracy: 0.9722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model3.evaluate(X_validation, y_validation, verbose=False)\n",
        "print(\"Validation Accuracy:  {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model3.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy: {:.4f}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrRZlOJMuxdZ",
        "outputId": "ab6fe128-04ca-47a6-afbf-bbbdfe2461fd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy:  0.9719\n",
            "Testing Accuracy: 0.9136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "JkKl9CyQvFku",
        "outputId": "5078f996-f19e-4994-cf9d-a165c76960f0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
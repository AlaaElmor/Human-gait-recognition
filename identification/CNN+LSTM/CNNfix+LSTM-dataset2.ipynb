{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDZ6vXdUtrsp",
        "outputId": "5cae5351-bf5d-4fb0-9463-88fbc5bc408c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Mounted at /content/gdrive\n",
            "(44339, 128, 6) (44339, 20) (4936, 128, 6) (4936, 20)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/'  #change dir to your project folder\n",
        "\n",
        "import numpy as np\n",
        "X_train = np.load('gdrive/My Drive/dataset/dataset2/trainX.npy')\n",
        "y_train = np.load('gdrive/My Drive/dataset/dataset2/trainy.npy')\n",
        "X_test = np.load('gdrive/My Drive/dataset/dataset2/testX.npy')\n",
        "y_test = np.load('gdrive/My Drive/dataset/dataset2/testy.npy')\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "from numpy import save, load\n",
        "from pandas import read_csv\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense , Input ,concatenate\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import LSTM, Conv1D, concatenate,GlobalMaxPooling1D,TimeDistributed, MaxPooling1D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "-Qkx_EZ2uxRJ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_training, X_validation, y_training, y_validation = train_test_split(X_train, y_train, test_size=0.20, random_state=42)\n",
        "n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
        "validation_data=(X_validation, y_validation)"
      ],
      "metadata": {
        "id": "QRMig4JduxUD"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_model= Sequential()\n",
        "CNN_model.add(Conv1D(filters=32, kernel_size=9, strides=2, activation='relu', input_shape=(n_timesteps,n_features)))\n",
        "CNN_model.add(MaxPooling1D(pool_size=2 ,strides=2))\n",
        "CNN_model.add(Dropout(0.5))\n",
        "CNN_model.add(Conv1D(filters=64, kernel_size=3, strides=1, activation='relu'))\n",
        "CNN_model.add(Conv1D(filters=128, kernel_size=3, strides=1, activation='relu'))\n",
        "CNN_model.add(MaxPooling1D(pool_size=2 ,strides=2))\n",
        "CNN_model.add(Dropout(0.5))\n",
        "CNN_model.add(Conv1D(filters=128, kernel_size=1, strides=1, activation='relu'))\n",
        "CNN_model.add(Flatten())\n",
        "CNN_model.add(Dense(n_outputs, activation='softmax'))\n",
        "CNN_model.summary()\n",
        "CNN_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]\n",
        "CNN_model.fit(X_training, y_training, epochs=200, verbose=True, validation_data=(X_validation, y_validation), batch_size=128,callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt-4cl-yuxXF",
        "outputId": "eff277a3-ce3e-4b55-a927-c4c49e2497af"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_28 (Conv1D)          (None, 60, 32)            1760      \n",
            "                                                                 \n",
            " max_pooling1d_14 (MaxPoolin  (None, 30, 32)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 30, 32)            0         \n",
            "                                                                 \n",
            " conv1d_29 (Conv1D)          (None, 28, 64)            6208      \n",
            "                                                                 \n",
            " conv1d_30 (Conv1D)          (None, 26, 128)           24704     \n",
            "                                                                 \n",
            " max_pooling1d_15 (MaxPoolin  (None, 13, 128)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 13, 128)           0         \n",
            "                                                                 \n",
            " conv1d_31 (Conv1D)          (None, 13, 128)           16512     \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 1664)              0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 20)                33300     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 82,484\n",
            "Trainable params: 82,484\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "278/278 [==============================] - 2s 6ms/step - loss: 0.8681 - accuracy: 0.7520 - val_loss: 0.2627 - val_accuracy: 0.9260\n",
            "Epoch 2/200\n",
            "278/278 [==============================] - 2s 6ms/step - loss: 0.2806 - accuracy: 0.9219 - val_loss: 0.1669 - val_accuracy: 0.9488\n",
            "Epoch 3/200\n",
            "278/278 [==============================] - 2s 6ms/step - loss: 0.2022 - accuracy: 0.9450 - val_loss: 0.1329 - val_accuracy: 0.9629\n",
            "Epoch 4/200\n",
            "278/278 [==============================] - 2s 6ms/step - loss: 0.1646 - accuracy: 0.9541 - val_loss: 0.0893 - val_accuracy: 0.9753\n",
            "Epoch 5/200\n",
            "278/278 [==============================] - 1s 5ms/step - loss: 0.1444 - accuracy: 0.9600 - val_loss: 0.0841 - val_accuracy: 0.9765\n",
            "Epoch 6/200\n",
            "278/278 [==============================] - 2s 6ms/step - loss: 0.1254 - accuracy: 0.9649 - val_loss: 0.0811 - val_accuracy: 0.9793\n",
            "Epoch 7/200\n",
            "278/278 [==============================] - 1s 5ms/step - loss: 0.1137 - accuracy: 0.9682 - val_loss: 0.0730 - val_accuracy: 0.9794\n",
            "Epoch 8/200\n",
            "278/278 [==============================] - 2s 6ms/step - loss: 0.1030 - accuracy: 0.9709 - val_loss: 0.0675 - val_accuracy: 0.9817\n",
            "Epoch 9/200\n",
            "278/278 [==============================] - 2s 6ms/step - loss: 0.0937 - accuracy: 0.9740 - val_loss: 0.0603 - val_accuracy: 0.9830\n",
            "Epoch 10/200\n",
            "278/278 [==============================] - 2s 6ms/step - loss: 0.0902 - accuracy: 0.9740 - val_loss: 0.0610 - val_accuracy: 0.9843\n",
            "Epoch 11/200\n",
            "278/278 [==============================] - 2s 6ms/step - loss: 0.0824 - accuracy: 0.9764 - val_loss: 0.0587 - val_accuracy: 0.9829\n",
            "Epoch 12/200\n",
            "278/278 [==============================] - 2s 8ms/step - loss: 0.0774 - accuracy: 0.9769 - val_loss: 0.0570 - val_accuracy: 0.9848\n",
            "Epoch 13/200\n",
            "278/278 [==============================] - 3s 10ms/step - loss: 0.0755 - accuracy: 0.9772 - val_loss: 0.0573 - val_accuracy: 0.9844\n",
            "Epoch 14/200\n",
            "278/278 [==============================] - 3s 9ms/step - loss: 0.0674 - accuracy: 0.9798 - val_loss: 0.0534 - val_accuracy: 0.9855\n",
            "Epoch 15/200\n",
            "278/278 [==============================] - 3s 10ms/step - loss: 0.0658 - accuracy: 0.9793 - val_loss: 0.0599 - val_accuracy: 0.9848\n",
            "Epoch 16/200\n",
            "278/278 [==============================] - 3s 9ms/step - loss: 0.0648 - accuracy: 0.9805 - val_loss: 0.0517 - val_accuracy: 0.9852\n",
            "Epoch 17/200\n",
            "278/278 [==============================] - 2s 7ms/step - loss: 0.0594 - accuracy: 0.9811 - val_loss: 0.0473 - val_accuracy: 0.9871\n",
            "Epoch 18/200\n",
            "278/278 [==============================] - 2s 6ms/step - loss: 0.0567 - accuracy: 0.9825 - val_loss: 0.0530 - val_accuracy: 0.9865\n",
            "Epoch 19/200\n",
            "278/278 [==============================] - 2s 5ms/step - loss: 0.0521 - accuracy: 0.9835 - val_loss: 0.0497 - val_accuracy: 0.9871\n",
            "Epoch 20/200\n",
            "278/278 [==============================] - 2s 6ms/step - loss: 0.0524 - accuracy: 0.9839 - val_loss: 0.0494 - val_accuracy: 0.9867\n",
            "Epoch 21/200\n",
            "278/278 [==============================] - 2s 6ms/step - loss: 0.0534 - accuracy: 0.9829 - val_loss: 0.0535 - val_accuracy: 0.9855\n",
            "Epoch 22/200\n",
            "278/278 [==============================] - 2s 6ms/step - loss: 0.0488 - accuracy: 0.9842 - val_loss: 0.0482 - val_accuracy: 0.9870\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe3129eccd0>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = CNN_model.evaluate(X_validation, y_validation, verbose=False)\n",
        "print(\"Validation Accuracy:  {:.4f}\".format(accuracy))\n",
        "loss, accuracy = CNN_model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy: {:.4f}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF3_pawu3KAS",
        "outputId": "9323b3e2-812b-4ca0-8be7-ffa73677c17b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy:  0.9871\n",
            "Testing Accuracy: 0.9597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_model.trainable = False\n",
        "\n",
        "LSTM_model= Sequential()\n",
        "LSTM_model.add(LSTM(512,input_shape=(n_timesteps,n_features),return_sequences=True))\n",
        "LSTM_model.add(LSTM(256))\n",
        "LSTM_model.add(Dropout(0.2))\n",
        "LSTM_model.add(Dense(128, activation='relu'))\n",
        "LSTM_model.add(Dense(n_outputs, activation='relu'))\n",
        "LSTM_model.summary()\n",
        "\n",
        "inputs = Input(shape=(n_timesteps,n_features))\n",
        "mergedInput= concatenate([CNN_model(inputs),LSTM_model(inputs)])\n",
        "out = Dense(n_outputs, activation='softmax')(mergedInput)\n",
        "model3 = Model(inputs,out)\n",
        "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cM0iBU4uxZ9",
        "outputId": "f828b439-9e0f-4eda-aded-4b13ff74d45e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_17 (LSTM)              (None, 128, 512)          1062912   \n",
            "                                                                 \n",
            " lstm_18 (LSTM)              (None, 256)               787456    \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 20)                2580      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,885,844\n",
            "Trainable params: 1,885,844\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)           [(None, 128, 6)]     0           []                               \n",
            "                                                                                                  \n",
            " sequential_15 (Sequential)     (None, 20)           82484       ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " sequential_17 (Sequential)     (None, 20)           1885844     ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 40)           0           ['sequential_15[1][0]',          \n",
            "                                                                  'sequential_17[0][0]']          \n",
            "                                                                                                  \n",
            " dense_33 (Dense)               (None, 20)           820         ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,969,148\n",
            "Trainable params: 1,886,664\n",
            "Non-trainable params: 82,484\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model3.fit(X_training, y_training, epochs=200, verbose=True, validation_data=(X_validation, y_validation), batch_size=128,callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leAK4cae3mSx",
        "outputId": "9f4a73cd-986b-4f03-98ec-96c687a320a1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "278/278 [==============================] - 26s 80ms/step - loss: 0.7750 - accuracy: 0.7840 - val_loss: 0.3221 - val_accuracy: 0.9116\n",
            "Epoch 2/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.2375 - accuracy: 0.9358 - val_loss: 0.2206 - val_accuracy: 0.9385\n",
            "Epoch 3/200\n",
            "278/278 [==============================] - 22s 80ms/step - loss: 0.1474 - accuracy: 0.9603 - val_loss: 0.1471 - val_accuracy: 0.9584\n",
            "Epoch 4/200\n",
            "278/278 [==============================] - 22s 79ms/step - loss: 0.1416 - accuracy: 0.9610 - val_loss: 0.1127 - val_accuracy: 0.9688\n",
            "Epoch 5/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0891 - accuracy: 0.9746 - val_loss: 0.0913 - val_accuracy: 0.9747\n",
            "Epoch 6/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0800 - accuracy: 0.9774 - val_loss: 0.0679 - val_accuracy: 0.9812\n",
            "Epoch 7/200\n",
            "278/278 [==============================] - 22s 79ms/step - loss: 0.0669 - accuracy: 0.9805 - val_loss: 0.0778 - val_accuracy: 0.9767\n",
            "Epoch 8/200\n",
            "278/278 [==============================] - 22s 79ms/step - loss: 0.0570 - accuracy: 0.9836 - val_loss: 0.0568 - val_accuracy: 0.9851\n",
            "Epoch 9/200\n",
            "278/278 [==============================] - 22s 79ms/step - loss: 0.0512 - accuracy: 0.9849 - val_loss: 0.0518 - val_accuracy: 0.9855\n",
            "Epoch 10/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0391 - accuracy: 0.9882 - val_loss: 0.0654 - val_accuracy: 0.9807\n",
            "Epoch 11/200\n",
            "278/278 [==============================] - 22s 79ms/step - loss: 0.0410 - accuracy: 0.9877 - val_loss: 0.0636 - val_accuracy: 0.9835\n",
            "Epoch 12/200\n",
            "278/278 [==============================] - 22s 79ms/step - loss: 0.0411 - accuracy: 0.9880 - val_loss: 0.0516 - val_accuracy: 0.9843\n",
            "Epoch 13/200\n",
            "278/278 [==============================] - 22s 79ms/step - loss: 0.0354 - accuracy: 0.9891 - val_loss: 0.0508 - val_accuracy: 0.9851\n",
            "Epoch 14/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0319 - accuracy: 0.9909 - val_loss: 0.0446 - val_accuracy: 0.9880\n",
            "Epoch 15/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0327 - accuracy: 0.9904 - val_loss: 0.0460 - val_accuracy: 0.9862\n",
            "Epoch 16/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0269 - accuracy: 0.9917 - val_loss: 0.0452 - val_accuracy: 0.9877\n",
            "Epoch 17/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0284 - accuracy: 0.9913 - val_loss: 0.0417 - val_accuracy: 0.9886\n",
            "Epoch 18/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0302 - accuracy: 0.9907 - val_loss: 0.0464 - val_accuracy: 0.9874\n",
            "Epoch 19/200\n",
            "278/278 [==============================] - 22s 79ms/step - loss: 0.0294 - accuracy: 0.9911 - val_loss: 0.0498 - val_accuracy: 0.9865\n",
            "Epoch 20/200\n",
            "278/278 [==============================] - 22s 79ms/step - loss: 0.0288 - accuracy: 0.9911 - val_loss: 0.0330 - val_accuracy: 0.9903\n",
            "Epoch 21/200\n",
            "278/278 [==============================] - 22s 79ms/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 0.0330 - val_accuracy: 0.9905\n",
            "Epoch 22/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.0363 - val_accuracy: 0.9894\n",
            "Epoch 23/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0192 - accuracy: 0.9938 - val_loss: 0.0467 - val_accuracy: 0.9874\n",
            "Epoch 24/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0271 - accuracy: 0.9923 - val_loss: 0.0345 - val_accuracy: 0.9897\n",
            "Epoch 25/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.0329 - val_accuracy: 0.9902\n",
            "Epoch 26/200\n",
            "278/278 [==============================] - 22s 79ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.0319 - val_accuracy: 0.9914\n",
            "Epoch 27/200\n",
            "278/278 [==============================] - 22s 79ms/step - loss: 0.0224 - accuracy: 0.9931 - val_loss: 0.0293 - val_accuracy: 0.9912\n",
            "Epoch 28/200\n",
            "278/278 [==============================] - 22s 79ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 0.0300 - val_accuracy: 0.9908\n",
            "Epoch 29/200\n",
            "278/278 [==============================] - 22s 79ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 0.0290 - val_accuracy: 0.9918\n",
            "Epoch 30/200\n",
            "278/278 [==============================] - 22s 79ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 0.0437 - val_accuracy: 0.9876\n",
            "Epoch 31/200\n",
            "278/278 [==============================] - 22s 79ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.0415 - val_accuracy: 0.9887\n",
            "Epoch 32/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0205 - accuracy: 0.9938 - val_loss: 0.0398 - val_accuracy: 0.9887\n",
            "Epoch 33/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.0296 - val_accuracy: 0.9912\n",
            "Epoch 34/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.0258 - val_accuracy: 0.9920\n",
            "Epoch 35/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.0265 - val_accuracy: 0.9919\n",
            "Epoch 36/200\n",
            "278/278 [==============================] - 22s 79ms/step - loss: 0.0164 - accuracy: 0.9951 - val_loss: 0.0238 - val_accuracy: 0.9929\n",
            "Epoch 37/200\n",
            "278/278 [==============================] - 22s 79ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0329 - val_accuracy: 0.9910\n",
            "Epoch 38/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.0260 - val_accuracy: 0.9926\n",
            "Epoch 39/200\n",
            "278/278 [==============================] - 22s 79ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 0.0454 - val_accuracy: 0.9867\n",
            "Epoch 40/200\n",
            "278/278 [==============================] - 22s 79ms/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 0.0305 - val_accuracy: 0.9910\n",
            "Epoch 41/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.0327 - val_accuracy: 0.9905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model3.evaluate(X_validation, y_validation, verbose=False)\n",
        "print(\"Validation Accuracy:  {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model3.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy: {:.4f}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrRZlOJMuxdZ",
        "outputId": "0a22edee-fe6e-4f40-d2b7-3ab248213c03"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy:  0.9929\n",
            "Testing Accuracy: 0.9607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "JkKl9CyQvFku",
        "outputId": "5af910ce-d50a-4af8-98e1-c068785983ea"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
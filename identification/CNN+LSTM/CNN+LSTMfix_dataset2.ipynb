{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDZ6vXdUtrsp",
        "outputId": "5cae5351-bf5d-4fb0-9463-88fbc5bc408c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Mounted at /content/gdrive\n",
            "(44339, 128, 6) (44339, 20) (4936, 128, 6) (4936, 20)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/'  #change dir to your project folder\n",
        "\n",
        "import numpy as np\n",
        "X_train = np.load('gdrive/My Drive/dataset/dataset2/trainX.npy')\n",
        "y_train = np.load('gdrive/My Drive/dataset/dataset2/trainy.npy')\n",
        "X_test = np.load('gdrive/My Drive/dataset/dataset2/testX.npy')\n",
        "y_test = np.load('gdrive/My Drive/dataset/dataset2/testy.npy')\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "from numpy import save, load\n",
        "from pandas import read_csv\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense , Input ,concatenate\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import LSTM, Conv1D, concatenate,GlobalMaxPooling1D,TimeDistributed, MaxPooling1D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "-Qkx_EZ2uxRJ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_training, X_validation, y_training, y_validation = train_test_split(X_train, y_train, test_size=0.20, random_state=42)\n",
        "n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
        "validation_data=(X_validation, y_validation)"
      ],
      "metadata": {
        "id": "QRMig4JduxUD"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_model= Sequential()\n",
        "LSTM_model.add(LSTM(512,input_shape=(n_timesteps,n_features),return_sequences=True))\n",
        "LSTM_model.add(LSTM(256))\n",
        "LSTM_model.add(Dropout(0.2))\n",
        "LSTM_model.add(Dense(128, activation='relu'))\n",
        "LSTM_model.add(Dense(n_outputs, activation='softmax'))\n",
        "LSTM_model.summary()\n",
        "LSTM_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]\n",
        "LSTM_model.fit(X_training, y_training, epochs=200, verbose=True, validation_data=(X_validation, y_validation), batch_size=128,callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt-4cl-yuxXF",
        "outputId": "45135ec0-8fac-42af-f213-26ab175a77b3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_13 (LSTM)              (None, 128, 512)          1062912   \n",
            "                                                                 \n",
            " lstm_14 (LSTM)              (None, 256)               787456    \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 20)                2580      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,885,844\n",
            "Trainable params: 1,885,844\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "278/278 [==============================] - 25s 79ms/step - loss: 0.5935 - accuracy: 0.8222 - val_loss: 0.2857 - val_accuracy: 0.9123\n",
            "Epoch 2/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.2385 - accuracy: 0.9314 - val_loss: 0.1489 - val_accuracy: 0.9594\n",
            "Epoch 3/200\n",
            "278/278 [==============================] - 22s 79ms/step - loss: 0.1427 - accuracy: 0.9591 - val_loss: 0.1208 - val_accuracy: 0.9653\n",
            "Epoch 4/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.1204 - accuracy: 0.9658 - val_loss: 0.1174 - val_accuracy: 0.9658\n",
            "Epoch 5/200\n",
            "278/278 [==============================] - 22s 77ms/step - loss: 0.1144 - accuracy: 0.9669 - val_loss: 0.0945 - val_accuracy: 0.9712\n",
            "Epoch 6/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0834 - accuracy: 0.9754 - val_loss: 0.0795 - val_accuracy: 0.9765\n",
            "Epoch 7/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0659 - accuracy: 0.9805 - val_loss: 0.0588 - val_accuracy: 0.9826\n",
            "Epoch 8/200\n",
            "278/278 [==============================] - 22s 77ms/step - loss: 0.0569 - accuracy: 0.9827 - val_loss: 0.0903 - val_accuracy: 0.9743\n",
            "Epoch 9/200\n",
            "278/278 [==============================] - 22s 77ms/step - loss: 0.0576 - accuracy: 0.9824 - val_loss: 0.0675 - val_accuracy: 0.9799\n",
            "Epoch 10/200\n",
            "278/278 [==============================] - 22s 77ms/step - loss: 0.0405 - accuracy: 0.9876 - val_loss: 0.0504 - val_accuracy: 0.9860\n",
            "Epoch 11/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0550 - accuracy: 0.9829 - val_loss: 0.0496 - val_accuracy: 0.9852\n",
            "Epoch 12/200\n",
            "278/278 [==============================] - 22s 77ms/step - loss: 0.0438 - accuracy: 0.9860 - val_loss: 0.0585 - val_accuracy: 0.9824\n",
            "Epoch 13/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0363 - accuracy: 0.9888 - val_loss: 0.0746 - val_accuracy: 0.9787\n",
            "Epoch 14/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0458 - accuracy: 0.9853 - val_loss: 0.0555 - val_accuracy: 0.9846\n",
            "Epoch 15/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0367 - accuracy: 0.9888 - val_loss: 0.0626 - val_accuracy: 0.9821\n",
            "Epoch 16/200\n",
            "278/278 [==============================] - 22s 78ms/step - loss: 0.0378 - accuracy: 0.9889 - val_loss: 0.0611 - val_accuracy: 0.9850\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe21428d1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = LSTM_model.evaluate(X_validation, y_validation, verbose=False)\n",
        "print(\"Validation Accuracy:  {:.4f}\".format(accuracy))\n",
        "loss, accuracy = LSTM_model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy: {:.4f}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF3_pawu3KAS",
        "outputId": "d3598775-ffb8-480c-bf83-02a12e4f6627"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy:  0.9852\n",
            "Testing Accuracy: 0.9449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lstm_output_layer_weights_values = LSTM_model.layers[4].get_weights()    \n",
        "LSTM_model.trainable = False\n",
        "\n",
        "CNN_model= Sequential()\n",
        "CNN_model.add(Conv1D(filters=32, kernel_size=9, strides=2, activation='relu', input_shape=(n_timesteps,n_features)))\n",
        "CNN_model.add(MaxPooling1D(pool_size=2 ,strides=2))\n",
        "CNN_model.add(Dropout(0.5))\n",
        "CNN_model.add(Conv1D(filters=64, kernel_size=3, strides=1, activation='relu'))\n",
        "CNN_model.add(Conv1D(filters=128, kernel_size=3, strides=1, activation='relu'))\n",
        "CNN_model.add(MaxPooling1D(pool_size=2 ,strides=2))\n",
        "CNN_model.add(Dropout(0.5))\n",
        "CNN_model.add(Conv1D(filters=128, kernel_size=1, strides=1, activation='relu'))\n",
        "CNN_model.add(Flatten())\n",
        "CNN_model.add(Dense(n_outputs, activation='relu'))\n",
        "CNN_model.summary()\n",
        "\n",
        "\n",
        "inputs = Input(shape=(n_timesteps,n_features))\n",
        "mergedInput= concatenate([CNN_model(inputs),LSTM_model(inputs)])\n",
        "out = Dense(n_outputs, activation='softmax')(mergedInput)\n",
        "model3 = Model(inputs,out)\n",
        "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#model3.layers[0].set_weights(LSTM_model.layers[4].get_weights())\n",
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cM0iBU4uxZ9",
        "outputId": "c8e9ff28-cb2d-4581-ac97-c8deb4ca9197"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_20 (Conv1D)          (None, 60, 32)            1760      \n",
            "                                                                 \n",
            " max_pooling1d_10 (MaxPoolin  (None, 30, 32)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 30, 32)            0         \n",
            "                                                                 \n",
            " conv1d_21 (Conv1D)          (None, 28, 64)            6208      \n",
            "                                                                 \n",
            " conv1d_22 (Conv1D)          (None, 26, 128)           24704     \n",
            "                                                                 \n",
            " max_pooling1d_11 (MaxPoolin  (None, 13, 128)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 13, 128)           0         \n",
            "                                                                 \n",
            " conv1d_23 (Conv1D)          (None, 13, 128)           16512     \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 1664)              0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 20)                33300     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 82,484\n",
            "Trainable params: 82,484\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, 128, 6)]     0           []                               \n",
            "                                                                                                  \n",
            " sequential_13 (Sequential)     (None, 20)           82484       ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " sequential_12 (Sequential)     (None, 20)           1885844     ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 40)           0           ['sequential_13[0][0]',          \n",
            "                                                                  'sequential_12[0][0]']          \n",
            "                                                                                                  \n",
            " dense_25 (Dense)               (None, 20)           820         ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,969,148\n",
            "Trainable params: 83,304\n",
            "Non-trainable params: 1,885,844\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model3.fit(X_training, y_training, epochs=200, verbose=True, validation_data=(X_validation, y_validation), batch_size=128,callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leAK4cae3mSx",
        "outputId": "3fef0906-a70d-40c6-988e-8c68a632aee3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "278/278 [==============================] - 14s 39ms/step - loss: 1.3919 - accuracy: 0.5962 - val_loss: 0.3775 - val_accuracy: 0.9091\n",
            "Epoch 2/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.3791 - accuracy: 0.9052 - val_loss: 0.2047 - val_accuracy: 0.9440\n",
            "Epoch 3/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.2446 - accuracy: 0.9392 - val_loss: 0.1495 - val_accuracy: 0.9610\n",
            "Epoch 4/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.1736 - accuracy: 0.9563 - val_loss: 0.1085 - val_accuracy: 0.9702\n",
            "Epoch 5/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.1403 - accuracy: 0.9653 - val_loss: 0.0946 - val_accuracy: 0.9771\n",
            "Epoch 6/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.1155 - accuracy: 0.9711 - val_loss: 0.0785 - val_accuracy: 0.9796\n",
            "Epoch 7/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.1005 - accuracy: 0.9736 - val_loss: 0.0730 - val_accuracy: 0.9798\n",
            "Epoch 8/200\n",
            "278/278 [==============================] - 10s 35ms/step - loss: 0.0877 - accuracy: 0.9782 - val_loss: 0.0623 - val_accuracy: 0.9851\n",
            "Epoch 9/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0770 - accuracy: 0.9810 - val_loss: 0.0609 - val_accuracy: 0.9838\n",
            "Epoch 10/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0704 - accuracy: 0.9830 - val_loss: 0.0499 - val_accuracy: 0.9862\n",
            "Epoch 11/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0652 - accuracy: 0.9835 - val_loss: 0.0481 - val_accuracy: 0.9869\n",
            "Epoch 12/200\n",
            "278/278 [==============================] - 10s 37ms/step - loss: 0.0581 - accuracy: 0.9860 - val_loss: 0.0442 - val_accuracy: 0.9868\n",
            "Epoch 13/200\n",
            "278/278 [==============================] - 11s 39ms/step - loss: 0.0529 - accuracy: 0.9866 - val_loss: 0.0401 - val_accuracy: 0.9889\n",
            "Epoch 14/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0499 - accuracy: 0.9877 - val_loss: 0.0404 - val_accuracy: 0.9891\n",
            "Epoch 15/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0486 - accuracy: 0.9883 - val_loss: 0.0443 - val_accuracy: 0.9878\n",
            "Epoch 16/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0447 - accuracy: 0.9889 - val_loss: 0.0406 - val_accuracy: 0.9892\n",
            "Epoch 17/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0415 - accuracy: 0.9896 - val_loss: 0.0381 - val_accuracy: 0.9891\n",
            "Epoch 18/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0391 - accuracy: 0.9900 - val_loss: 0.0372 - val_accuracy: 0.9895\n",
            "Epoch 19/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0379 - accuracy: 0.9906 - val_loss: 0.0381 - val_accuracy: 0.9896\n",
            "Epoch 20/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0341 - accuracy: 0.9905 - val_loss: 0.0377 - val_accuracy: 0.9899\n",
            "Epoch 21/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0324 - accuracy: 0.9917 - val_loss: 0.0354 - val_accuracy: 0.9903\n",
            "Epoch 22/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0324 - accuracy: 0.9914 - val_loss: 0.0365 - val_accuracy: 0.9899\n",
            "Epoch 23/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0317 - accuracy: 0.9923 - val_loss: 0.0357 - val_accuracy: 0.9902\n",
            "Epoch 24/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0291 - accuracy: 0.9926 - val_loss: 0.0359 - val_accuracy: 0.9901\n",
            "Epoch 25/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0278 - accuracy: 0.9928 - val_loss: 0.0378 - val_accuracy: 0.9902\n",
            "Epoch 26/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0262 - accuracy: 0.9931 - val_loss: 0.0346 - val_accuracy: 0.9904\n",
            "Epoch 27/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0262 - accuracy: 0.9934 - val_loss: 0.0353 - val_accuracy: 0.9905\n",
            "Epoch 28/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 0.0333 - val_accuracy: 0.9903\n",
            "Epoch 29/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0241 - accuracy: 0.9937 - val_loss: 0.0335 - val_accuracy: 0.9901\n",
            "Epoch 30/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0232 - accuracy: 0.9937 - val_loss: 0.0344 - val_accuracy: 0.9896\n",
            "Epoch 31/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 0.0333 - val_accuracy: 0.9908\n",
            "Epoch 32/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0216 - accuracy: 0.9935 - val_loss: 0.0332 - val_accuracy: 0.9906\n",
            "Epoch 33/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0207 - accuracy: 0.9944 - val_loss: 0.0342 - val_accuracy: 0.9905\n",
            "Epoch 34/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0207 - accuracy: 0.9944 - val_loss: 0.0324 - val_accuracy: 0.9909\n",
            "Epoch 35/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0203 - accuracy: 0.9941 - val_loss: 0.0360 - val_accuracy: 0.9902\n",
            "Epoch 36/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0204 - accuracy: 0.9941 - val_loss: 0.0337 - val_accuracy: 0.9908\n",
            "Epoch 37/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0196 - accuracy: 0.9946 - val_loss: 0.0338 - val_accuracy: 0.9908\n",
            "Epoch 38/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0177 - accuracy: 0.9950 - val_loss: 0.0320 - val_accuracy: 0.9904\n",
            "Epoch 39/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0185 - accuracy: 0.9946 - val_loss: 0.0324 - val_accuracy: 0.9915\n",
            "Epoch 40/200\n",
            "278/278 [==============================] - 10s 35ms/step - loss: 0.0168 - accuracy: 0.9954 - val_loss: 0.0329 - val_accuracy: 0.9909\n",
            "Epoch 41/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.0351 - val_accuracy: 0.9902\n",
            "Epoch 42/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0167 - accuracy: 0.9950 - val_loss: 0.0340 - val_accuracy: 0.9902\n",
            "Epoch 43/200\n",
            "278/278 [==============================] - 10s 36ms/step - loss: 0.0169 - accuracy: 0.9955 - val_loss: 0.0347 - val_accuracy: 0.9912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model3.evaluate(X_validation, y_validation, verbose=False)\n",
        "print(\"Validation Accuracy:  {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model3.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy: {:.4f}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrRZlOJMuxdZ",
        "outputId": "281d4075-68a0-464c-a078-ee4d7bb9947a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy:  0.9904\n",
            "Testing Accuracy: 0.9568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "JkKl9CyQvFku",
        "outputId": "93e0a7c7-6fa9-4023-df80-da6ab2da38ea"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
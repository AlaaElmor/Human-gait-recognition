{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/Dataset #8/'  #change dir to your project folder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9CIstyEsI47",
        "outputId": "59be75dd-5733-4d41-931c-a294e5f68598"
      },
      "id": "B9CIstyEsI47",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/Dataset #8/Dataset #8/'  #change dir to your project folder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z1nCj_D4DdM",
        "outputId": "0c709daf-9641-47af-e592-2a8581655e57"
      },
      "id": "_z1nCj_D4DdM",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b56e19e8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b56e19e8",
        "outputId": "b4677266-4d2c-42e8-8851-fa54a9b00043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1022, 6, 1024, 1)\n",
            "(1022, 1024)\n",
            "(332, 6, 1024, 1)\n",
            "(332, 1024)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import preprocessing\n",
        "from tensorflow.keras import layers ,models\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def read_data(data_path):\n",
        "    data = []\n",
        "    file_names = os.listdir(data_path)\n",
        "    file_names.sort(key=lambda x:int(x[:-4]))\n",
        "    for file_name in file_names:\n",
        "        file_path = os.path.join(data_path, file_name)\n",
        "        signal_data = np.loadtxt(file_path)\n",
        "        data.append(signal_data)\n",
        "    data = np.array(data).transpose(0, 2, 1)\n",
        "    d_shape = data.shape\n",
        "    return data.reshape(d_shape[0], 1, d_shape[1], d_shape[2])\n",
        "\n",
        "\n",
        "def read_label(data_path):\n",
        "    data = []\n",
        "    file_names = os.listdir(data_path)\n",
        "    file_names.sort(key=lambda x:int(x[:-10]))\n",
        "    for file_name in file_names:\n",
        "        file_path = os.path.join(data_path, file_name)\n",
        "        signal_data = np.loadtxt(file_path)\n",
        "        data.append(signal_data)\n",
        "    return np.array(data)\n",
        "\n",
        "\n",
        "\n",
        "train_data_path = 'gdrive/My Drive/Dataset #8/Dataset #8/train/train_data'\n",
        "train_label_path = 'gdrive/My Drive/Dataset #8/Dataset #8/train/train_label'\n",
        "test_data_path = 'gdrive/My Drive/Dataset #8/Dataset #8/test/test_data'\n",
        "test_label_path = 'gdrive/My Drive/Dataset #8/Dataset #8/test/test_label'\n",
        "\n",
        "train_data = read_data(train_data_path).transpose(0, 2, 3, 1) # 519\n",
        "train_label = read_label(train_label_path)\n",
        "test_data = read_data(test_data_path).transpose(0, 2, 3, 1) # 519\n",
        "test_label = read_label(test_label_path)\n",
        "\n",
        "print(train_data.shape)\n",
        "print(train_label.shape)\n",
        "print(test_data.shape)\n",
        "print(test_label.shape)\n",
        "\n",
        "num_classes = len(np.unique(train_label))\n",
        "num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1e695b73",
      "metadata": {
        "id": "1e695b73"
      },
      "outputs": [],
      "source": [
        "idx = np.random.permutation(len(train_data))\n",
        "train_data = train_data[idx]\n",
        "train_label = train_label[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "9c4f5685",
      "metadata": {
        "id": "9c4f5685"
      },
      "outputs": [],
      "source": [
        "#train_label[train_label == -1] = 0\n",
        "#est_label[test_label == -1] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8d0d00b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d0d00b9",
        "outputId": "3f1efd26-714f-4298-cc92-3f6b3b537365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 6, 1024, 1)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 6, 1024, 1)  4           ['input_1[0][0]']                \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 6, 1024, 64)  1088        ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 6, 1024, 64)  256        ['conv2d[0][0]']                 \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                   (None, 6, 1024, 64)  0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 6, 1024, 64)  8256        ['re_lu[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 6, 1024, 64)  256        ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)                 (None, 6, 1024, 64)  0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 6, 512, 64)   0           ['re_lu_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 6, 512, 64)  256         ['max_pooling2d[0][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 6, 512, 128)  131200      ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 6, 512, 128)  512        ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)                 (None, 6, 512, 128)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 6, 512, 128)  262272      ['re_lu_2[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 6, 512, 128)  512        ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)                 (None, 6, 512, 128)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 6, 256, 128)  0          ['re_lu_3[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 6, 256, 128)  512        ['max_pooling2d_1[0][0]']        \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 6, 256, 256)  524544      ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 6, 256, 256)  1024       ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)                 (None, 6, 256, 256)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 6, 256, 256)  1048832     ['re_lu_4[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 6, 256, 256)  1024       ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_5 (ReLU)                 (None, 6, 256, 256)  0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 6, 256, 256)  1048832     ['re_lu_5[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 6, 256, 256)  1024       ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_6 (ReLU)                 (None, 6, 256, 256)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 6, 512, 128)  65664      ['re_lu_6[0][0]']                \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 6, 512, 256)  0           ['conv2d_transpose[0][0]',       \n",
            "                                                                  're_lu_3[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 6, 512, 256)  1024       ['concatenate[0][0]']            \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 6, 512, 128)  524416      ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 6, 512, 128)  512        ['conv2d_7[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_7 (ReLU)                 (None, 6, 512, 128)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 6, 512, 128)  262272      ['re_lu_7[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 6, 512, 128)  512        ['conv2d_8[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)                 (None, 6, 512, 128)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 6, 1024, 64)  16448      ['re_lu_8[0][0]']                \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 6, 1024, 128  0           ['re_lu_1[0][0]',                \n",
            "                                )                                 'conv2d_transpose_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 6, 1024, 128  512        ['concatenate_1[0][0]']          \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 6, 1024, 64)  131136      ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 6, 1024, 64)  256        ['conv2d_9[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_9 (ReLU)                 (None, 6, 1024, 64)  0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 6, 1024, 64)  65600       ['re_lu_9[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 6, 1024, 64)  256        ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_10 (ReLU)                (None, 6, 1024, 64)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 1, 1024, 256  98560       ['re_lu_10[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 1, 1024, 256  1024       ['conv2d_11[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " re_lu_11 (ReLU)                (None, 1, 1024, 256  0           ['batch_normalization_16[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 1, 1024, 1)   257         ['re_lu_11[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 1, 1024, 1)  4           ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.reshape (TFOpLambda)        (None, 1024)         0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,198,857\n",
            "Trainable params: 4,194,117\n",
            "Non-trainable params: 4,740\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def make_model(input_shape):\n",
        "    input_layer = keras.layers.Input(input_shape)\n",
        "    \n",
        "    conv = keras.layers.BatchNormalization()(input_layer)\n",
        "    conv1_1 = keras.layers.Conv2D(filters=64, kernel_size=[1, 16], padding=\"same\")(conv)\n",
        "    conv1_1 = keras.layers.BatchNormalization()(conv1_1)\n",
        "    conv1_1 = keras.layers.ReLU()(conv1_1)\n",
        "\n",
        "    conv1_2 = keras.layers.Conv2D(filters=64, kernel_size=[1, 2], padding=\"same\")(conv1_1)\n",
        "    conv1_2 = keras.layers.BatchNormalization()(conv1_2)\n",
        "    conv1_2 = keras.layers.ReLU()(conv1_2)\n",
        "    \n",
        "    conv2_1= keras.layers.MaxPooling2D(pool_size=[1, 16], strides=[1,2], padding=\"same\")(conv1_2)\n",
        "    conv2_1 = keras.layers.BatchNormalization()(conv2_1)\n",
        "    \n",
        "    conv2_2 = keras.layers.Conv2D(filters=128, kernel_size=[1, 16], padding=\"same\")(conv2_1)\n",
        "    conv2_2 = keras.layers.BatchNormalization()(conv2_2)\n",
        "    conv2_2 = keras.layers.ReLU()(conv2_2)\n",
        "    \n",
        "    conv2_3 = keras.layers.Conv2D(filters=128, kernel_size=[1, 16], padding=\"same\")(conv2_2)\n",
        "    conv2_3 = keras.layers.BatchNormalization()(conv2_3)\n",
        "    conv2_3 = keras.layers.ReLU()(conv2_3)\n",
        "    \n",
        "    conv3_1 = keras.layers.MaxPooling2D(pool_size=(1, 2), strides=[1,2], padding=\"same\", data_format=None)(conv2_3)\n",
        "    conv3_1 = keras.layers.BatchNormalization()(conv3_1)\n",
        "    \n",
        "    conv3_2 = keras.layers.Conv2D(filters=256, kernel_size=[1, 16], padding=\"same\")(conv3_1)\n",
        "    conv3_2 = keras.layers.BatchNormalization()(conv3_2)\n",
        "    conv3_2 = keras.layers.ReLU()(conv3_2)\n",
        "    \n",
        "    conv3_3 = keras.layers.Conv2D(filters=256, kernel_size=[1, 16], padding=\"same\")(conv3_2)\n",
        "    conv3_3 = keras.layers.BatchNormalization()(conv3_3)\n",
        "    conv3_3 = keras.layers.ReLU()(conv3_3)\n",
        "    \n",
        "    conv3_4 = keras.layers.Conv2D(filters=256, kernel_size=[1, 16], padding=\"same\")(conv3_3)\n",
        "    conv3_4 = keras.layers.BatchNormalization()(conv3_4)\n",
        "    conv3_4 = keras.layers.ReLU()(conv3_4)\n",
        "    \n",
        "    conv2_4_1 = keras.layers.Conv2DTranspose(filters=128, kernel_size=[1,2],strides=[1,2], padding=\"same\")(conv3_4)\n",
        "    conv2_4 = tf.keras.layers.Concatenate(axis =3)([conv2_4_1, conv2_3])\n",
        "    conv2_4 = keras.layers.BatchNormalization()(conv2_4)\n",
        "    \n",
        "    conv2_5 = keras.layers.Conv2D(filters=128, kernel_size=[1, 16], padding=\"same\")(conv2_4)\n",
        "    conv2_5 = keras.layers.BatchNormalization()(conv2_5)\n",
        "    conv2_5 = keras.layers.ReLU()(conv2_5)\n",
        "    \n",
        "    conv2_6 = keras.layers.Conv2D(filters=128, kernel_size=[1, 16], padding=\"same\")(conv2_5)\n",
        "    conv2_6 = keras.layers.BatchNormalization()(conv2_6)\n",
        "    conv2_6 = keras.layers.ReLU()(conv2_6)\n",
        "    \n",
        "    conv1_3_1 = keras.layers.Conv2DTranspose(filters=64, kernel_size=[1, 2],strides=[1,2], padding=\"same\")(conv2_6)\n",
        "    conv1_3 = tf.keras.layers.Concatenate(axis =3)([conv1_2, conv1_3_1])\n",
        "    conv1_3 = keras.layers.BatchNormalization()(conv1_3)\n",
        "    \n",
        "    conv1_4 = keras.layers.Conv2D(filters=64, kernel_size=[1, 16], padding=\"same\")(conv1_3)\n",
        "    conv1_4 = keras.layers.BatchNormalization()(conv1_4)\n",
        "    conv1_4 = keras.layers.ReLU()(conv1_4)\n",
        "    \n",
        "    conv1_4 = keras.layers.Conv2D(filters=64, kernel_size=[1, 16], padding=\"same\")(conv1_4)\n",
        "    conv1_4 = keras.layers.BatchNormalization()(conv1_4)\n",
        "    conv1_4 = keras.layers.ReLU()(conv1_4)\n",
        "    \n",
        "    conv1_5 = keras.layers.Conv2D(filters=256, kernel_size=[6,1], padding=\"valid\")(conv1_4)\n",
        "    conv1_5 = keras.layers.BatchNormalization()(conv1_5)\n",
        "    conv1_5 = keras.layers.ReLU()(conv1_5)\n",
        "    \n",
        "    #gap = keras.layers.GlobalAveragePooling2D()(conv1_5)\n",
        "\n",
        "    output_layer = keras.layers.Conv2D(filters=1, kernel_size=[1, 1], padding=\"same\",activation=\"sigmoid\")(conv1_5)\n",
        "    output_layer = keras.layers.BatchNormalization()(output_layer)\n",
        "    out= tf.reshape(output_layer,[-1,1024])\n",
        "    layers.Flatten()\n",
        "\n",
        "    return keras.models.Model(inputs=input_layer, outputs=out)\n",
        "    #out = tf.reshape(output_layer, [-1, 1024])\n",
        "    #return out\n",
        "     \n",
        "model = make_model(input_shape=train_data.shape[1:])\n",
        "keras.utils.plot_model(model, show_shapes=True)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0f58dcc2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0f58dcc2",
        "outputId": "8d9a0c6c-9379-4ba0-d82f-366f496827db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "26/26 [==============================] - 39s 1s/step - loss: 3884.4756 - accuracy: 0.0881 - val_loss: 3687.3184 - val_accuracy: 0.5366\n",
            "Epoch 2/150\n",
            "26/26 [==============================] - 27s 1s/step - loss: 3839.6157 - accuracy: 0.1126 - val_loss: 3719.3406 - val_accuracy: 0.4146\n",
            "Epoch 3/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3807.4163 - accuracy: 0.1077 - val_loss: 3635.1057 - val_accuracy: 0.3561\n",
            "Epoch 4/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3811.3188 - accuracy: 0.0624 - val_loss: 3662.3828 - val_accuracy: 0.3902\n",
            "Epoch 5/150\n",
            "26/26 [==============================] - 27s 1s/step - loss: 3811.0710 - accuracy: 0.0967 - val_loss: 3661.3533 - val_accuracy: 0.4244\n",
            "Epoch 6/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3796.0144 - accuracy: 0.1469 - val_loss: 3700.9800 - val_accuracy: 0.4585\n",
            "Epoch 7/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3830.3284 - accuracy: 0.1432 - val_loss: 3758.3528 - val_accuracy: 0.1902\n",
            "Epoch 8/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3960.2092 - accuracy: 0.1395 - val_loss: 3584.9929 - val_accuracy: 0.3854\n",
            "Epoch 9/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3953.7908 - accuracy: 0.0135 - val_loss: 4402.9624 - val_accuracy: 0.0049\n",
            "Epoch 10/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3886.6992 - accuracy: 0.0147 - val_loss: 3584.8594 - val_accuracy: 0.5610\n",
            "Epoch 11/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 4020.3413 - accuracy: 0.0208 - val_loss: 3896.5686 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 4308.4048 - accuracy: 0.0110 - val_loss: 3582.8459 - val_accuracy: 0.5756\n",
            "Epoch 13/150\n",
            "26/26 [==============================] - 27s 1s/step - loss: 4208.5396 - accuracy: 0.0110 - val_loss: 3819.7905 - val_accuracy: 0.1659\n",
            "Epoch 14/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3941.0674 - accuracy: 0.0037 - val_loss: 3867.0425 - val_accuracy: 0.2244\n",
            "Epoch 15/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3966.4141 - accuracy: 0.0196 - val_loss: 3865.2832 - val_accuracy: 0.2000\n",
            "Epoch 16/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3941.9456 - accuracy: 0.0233 - val_loss: 3778.5662 - val_accuracy: 0.3073\n",
            "Epoch 17/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3958.3311 - accuracy: 0.0428 - val_loss: 3890.4890 - val_accuracy: 0.2585\n",
            "Epoch 18/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3991.7236 - accuracy: 0.0869 - val_loss: 3736.1814 - val_accuracy: 0.3073\n",
            "Epoch 19/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3868.7539 - accuracy: 0.1126 - val_loss: 3705.7522 - val_accuracy: 0.4146\n",
            "Epoch 20/150\n",
            "26/26 [==============================] - 27s 1s/step - loss: 3837.0969 - accuracy: 0.0918 - val_loss: 3706.0054 - val_accuracy: 0.4341\n",
            "Epoch 21/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3942.9443 - accuracy: 0.1371 - val_loss: 3926.3101 - val_accuracy: 0.2829\n",
            "Epoch 22/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 4029.3772 - accuracy: 0.1457 - val_loss: 3596.9475 - val_accuracy: 0.2244\n",
            "Epoch 23/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3681.1482 - accuracy: 0.1469 - val_loss: 3590.1963 - val_accuracy: 0.2195\n",
            "Epoch 24/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3678.3530 - accuracy: 0.1346 - val_loss: 3588.7981 - val_accuracy: 0.2341\n",
            "Epoch 25/150\n",
            "26/26 [==============================] - 27s 1s/step - loss: 3677.1199 - accuracy: 0.1640 - val_loss: 3587.7832 - val_accuracy: 0.2195\n",
            "Epoch 26/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3676.1509 - accuracy: 0.1469 - val_loss: 3586.8628 - val_accuracy: 0.2293\n",
            "Epoch 27/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3675.1448 - accuracy: 0.1652 - val_loss: 3586.0442 - val_accuracy: 0.2293\n",
            "Epoch 28/150\n",
            "26/26 [==============================] - 27s 1s/step - loss: 3674.3850 - accuracy: 0.1481 - val_loss: 3585.1975 - val_accuracy: 0.2244\n",
            "Epoch 29/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3673.6157 - accuracy: 0.1603 - val_loss: 3584.4265 - val_accuracy: 0.2293\n",
            "Epoch 30/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3672.9138 - accuracy: 0.1726 - val_loss: 3583.6924 - val_accuracy: 0.2537\n",
            "Epoch 31/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3672.2715 - accuracy: 0.1836 - val_loss: 3583.0217 - val_accuracy: 0.2683\n",
            "Epoch 32/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3671.6790 - accuracy: 0.1053 - val_loss: 3582.3992 - val_accuracy: 0.1268\n",
            "Epoch 33/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3671.1714 - accuracy: 0.0783 - val_loss: 3581.8040 - val_accuracy: 0.0537\n",
            "Epoch 34/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3670.6868 - accuracy: 0.0722 - val_loss: 3581.2842 - val_accuracy: 0.1268\n",
            "Epoch 35/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3670.2815 - accuracy: 0.0661 - val_loss: 3580.8259 - val_accuracy: 0.1268\n",
            "Epoch 36/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3669.8730 - accuracy: 0.0636 - val_loss: 3580.3533 - val_accuracy: 0.1268\n",
            "Epoch 37/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3669.5679 - accuracy: 0.0612 - val_loss: 3579.9189 - val_accuracy: 0.0439\n",
            "Epoch 38/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3669.2781 - accuracy: 0.0575 - val_loss: 3579.5583 - val_accuracy: 0.0439\n",
            "Epoch 39/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3668.9758 - accuracy: 0.0783 - val_loss: 3579.2397 - val_accuracy: 0.0927\n",
            "Epoch 40/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3668.7527 - accuracy: 0.0514 - val_loss: 3578.9153 - val_accuracy: 0.0439\n",
            "Epoch 41/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3668.4412 - accuracy: 0.0624 - val_loss: 3578.6401 - val_accuracy: 0.0439\n",
            "Epoch 42/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3668.3264 - accuracy: 0.0551 - val_loss: 3578.3726 - val_accuracy: 0.0439\n",
            "Epoch 43/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3668.0945 - accuracy: 0.0588 - val_loss: 3578.1570 - val_accuracy: 0.0439\n",
            "Epoch 44/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3667.9912 - accuracy: 0.0502 - val_loss: 3577.9622 - val_accuracy: 0.0439\n",
            "Epoch 45/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3667.8442 - accuracy: 0.0575 - val_loss: 3577.7795 - val_accuracy: 0.0439\n",
            "Epoch 46/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3667.6460 - accuracy: 0.0636 - val_loss: 3577.6101 - val_accuracy: 0.0439\n",
            "Epoch 47/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3667.6079 - accuracy: 0.0551 - val_loss: 3577.4722 - val_accuracy: 0.0439\n",
            "Epoch 48/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3667.7290 - accuracy: 0.0636 - val_loss: 3577.3708 - val_accuracy: 0.0439\n",
            "Epoch 49/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3667.7100 - accuracy: 0.0575 - val_loss: 3577.2424 - val_accuracy: 0.0439\n",
            "Epoch 50/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3667.4292 - accuracy: 0.0588 - val_loss: 3577.1560 - val_accuracy: 0.0439\n",
            "Epoch 51/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3667.1968 - accuracy: 0.0624 - val_loss: 3577.0298 - val_accuracy: 0.0439\n",
            "Epoch 52/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3667.6375 - accuracy: 0.0698 - val_loss: 3576.9299 - val_accuracy: 0.0439\n",
            "Epoch 53/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3667.4937 - accuracy: 0.0600 - val_loss: 3576.8865 - val_accuracy: 0.0439\n",
            "Epoch 54/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3667.3030 - accuracy: 0.0624 - val_loss: 3576.8320 - val_accuracy: 0.0439\n",
            "Epoch 55/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3667.2415 - accuracy: 0.0502 - val_loss: 3576.7439 - val_accuracy: 0.0439\n",
            "Epoch 56/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3667.1582 - accuracy: 0.0526 - val_loss: 3576.6458 - val_accuracy: 0.0439\n",
            "Epoch 57/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3666.8259 - accuracy: 0.0673 - val_loss: 3576.5298 - val_accuracy: 0.0439\n",
            "Epoch 58/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3667.1470 - accuracy: 0.0636 - val_loss: 3576.4622 - val_accuracy: 0.0439\n",
            "Epoch 59/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3667.2605 - accuracy: 0.0636 - val_loss: 3576.4165 - val_accuracy: 0.0439\n",
            "Epoch 60/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3667.0938 - accuracy: 0.0514 - val_loss: 3576.3398 - val_accuracy: 0.0439\n",
            "Epoch 61/150\n",
            "26/26 [==============================] - 26s 1s/step - loss: 3667.1501 - accuracy: 0.0661 - val_loss: 3576.2803 - val_accuracy: 0.0439\n",
            "Epoch 62/150\n",
            "26/26 [==============================] - 27s 1s/step - loss: 3666.7625 - accuracy: 0.0612 - val_loss: 3576.1401 - val_accuracy: 0.0439\n",
            "Epoch 63/150\n",
            " 3/26 [==>...........................] - ETA: 22s - loss: 4072.9336 - accuracy: 0.0521"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-baa97c61d886>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "opt = SGD(learning_rate=0.001)\n",
        "\n",
        "epochs = 150\n",
        "batch_size = 32\n",
        "display_step = 1\n",
        "data_len = len(train_data)\n",
        "\n",
        "#model.compile(loss = \"categorical_crossentropy\", optimizer = 'adam' ,metrics=[\"accuracy\"],)\n",
        "optimizer = keras.optimizers.Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    train_label,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.2,\n",
        "    verbose=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0b8209d2",
      "metadata": {
        "id": "0b8209d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2455d69f-d8cc-471d-84e5-4e211ab77c24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 3s 254ms/step - loss: 4570.0625 - accuracy: 0.0241\n",
            "Test accuracy 0.024096384644508362\n",
            "Test loss 4570.0625\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.load_model(\"best_model.h5\")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_data, test_label)\n",
        "\n",
        "print(\"Test accuracy\", test_acc)\n",
        "print(\"Test loss\", test_loss)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "Gait extraction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2993f124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import save, load\n",
    "from pandas import read_csv\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras import Model\n",
    "from keras.layers import Conv1D, SpatialDropout1D\n",
    "from keras.layers import Convolution1D, Dense,Activation\n",
    "from keras.models import Input, Model\n",
    "from keras.layers import LSTM, Conv1D, concatenate,GlobalMaxPooling1D,GlobalAveragePooling1D,TimeDistributed, MaxPooling1D\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "import keras.layers\n",
    "from keras import optimizers\n",
    "from keras.layers import Activation, Lambda\n",
    "from keras.layers import Convolution1D, Dense\n",
    "from keras.models import Input, Model\n",
    "from typing import List, Tuple\n",
    "from sklearn.model_selection import LeavePOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57e716b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44339, 128, 6) (44339, 20) (4936, 128, 6) (4936, 20)\n"
     ]
    }
   ],
   "source": [
    "x_train = load('trainX.npy')\n",
    "x_test = load('testX.npy')\n",
    "y_train = load('trainy.npy')\n",
    "y_test = load('testy.npy')\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea5b885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeavePOut\n",
    "\n",
    "Lpo = LeavePOut(2)\n",
    "for train_idx , val_idx in Lpo.split(x_train):\n",
    "    X_train, X_val = x_train[train_idx], x_train[val_idx]\n",
    "    Y_train, Y_val = y_train[train_idx], y_train[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f45a900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_normalization(x):\n",
    "    max_values = K.max(K.abs(x), 2, keepdims=True) + 1e-5\n",
    "    out = x / max_values\n",
    "    return out\n",
    "\n",
    "def residual_block(x, s, i, activation, nb_filters, kernel_size, padding, dropout_rate=0, name=''):\n",
    "    original_x = x\n",
    "    conv = Conv1D(filters=nb_filters, kernel_size=kernel_size,\n",
    "                  dilation_rate=i, padding=padding,\n",
    "                  name=name + '_dilated_conv_%d_tanh_s%d' % (i, s))(x)\n",
    "    if activation == 'norm_relu':\n",
    "        x = Activation('relu')(conv)\n",
    "        x = Lambda(channel_normalization)(x)\n",
    "    else:\n",
    "        x = Activation(activation)(conv)\n",
    "\n",
    "    x = SpatialDropout1D(dropout_rate, name=name + '_spatial_dropout1d_%d_s%d_%f' % (i, s, dropout_rate))(x)\n",
    "\n",
    "    # 1x1 conv.\n",
    "    x = Convolution1D(nb_filters, 1, padding='same')(x)\n",
    "    res_x = keras.layers.add([original_x, x])\n",
    "    return res_x, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ef389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCN:\n",
    "\n",
    "    def __init__(self,\n",
    "                 nb_filters=64,\n",
    "                 kernel_size=2,\n",
    "                 nb_stacks=1,\n",
    "                 dilations=None,\n",
    "                 activation='norm_relu',\n",
    "                 padding='causal',\n",
    "                 use_skip_connections=True,\n",
    "                 dropout_rate=0.0,\n",
    "                 return_sequences=True,\n",
    "                 name='tcn'):\n",
    "        self.name = name\n",
    "        self.return_sequences = return_sequences\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.use_skip_connections = use_skip_connections\n",
    "        self.activation = activation\n",
    "        self.dilations = dilations\n",
    "        self.nb_stacks = nb_stacks\n",
    "        self.kernel_size = kernel_size\n",
    "        self.nb_filters = nb_filters\n",
    "        self.padding = padding\n",
    "        \n",
    "        if padding != 'causal' and padding != 'same':\n",
    "            raise ValueError(\"Only 'causal' or 'same' paddings are compatible for this layer.\")\n",
    "\n",
    "        if not isinstance(nb_filters, int):\n",
    "            print('An interface change occurred after the version 2.1.2.')\n",
    "            print('Before: tcn.TCN(i, return_sequences=False, ...)')\n",
    "            print('Now should be: tcn.TCN(return_sequences=False, ...)(i)')\n",
    "            print('Second solution is to pip install keras-tcn==2.1.2 to downgrade.')\n",
    "            raise Exception()\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        if self.dilations is None:\n",
    "            self.dilations = [1, 2, 4, 8, 16, 32]\n",
    "        x = inputs\n",
    "        x = Convolution1D(self.nb_filters, 1, padding=self.padding, name=self.name + '_initial_conv')(x)\n",
    "        skip_connections = []\n",
    "        for s in range(self.nb_stacks):\n",
    "            for i in self.dilations:\n",
    "                x, skip_out = residual_block(x, s, i, self.activation, self.nb_filters,\n",
    "                                             self.kernel_size, self.padding, self.dropout_rate, name=self.name)\n",
    "                skip_connections.append(skip_out)\n",
    "        if self.use_skip_connections:\n",
    "            x = keras.layers.add(skip_connections)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        if not self.return_sequences:\n",
    "            output_slice_index = -1\n",
    "            x = Lambda(lambda tt: tt[:, output_slice_index, :])(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca07e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "input = Input(shape=X_train.shape[1:])\n",
    "x = SpatialDropout1D(0.2)(input)\n",
    "x = TCN(128,dilations = [1, 2, 4, 8, 16],kernel_size = 3, return_sequences=True, name = 'tnc1')(x)\n",
    "x = TCN(128,dilations = [1, 2, 4, 8, 16],kernel_size = 3, return_sequences=True, name = 'tnc2')(x)\n",
    "max_pool = GlobalMaxPooling1D()(x)\n",
    "x = Dense(128, activation=\"relu\")(max_pool)\n",
    "x = Dropout(0.2)(x)\n",
    "output = Dense(118, activation=\"softmax\")(x)    \n",
    "model = Model(inputs=input, outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c852c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=200, verbose=True, validation_data=(X_val, Y_val), batch_size=128,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed13568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_val, Y_val, verbose=False)\n",
    "print(\"Validation Accuracy:  {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86241d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Training accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Validation accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

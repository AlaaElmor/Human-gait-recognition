{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "HzTuqLMwGxiF"
      },
      "outputs": [],
      "source": [
        "from numpy import save, load\n",
        "from pandas import read_csv\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras import Model\n",
        "from keras.layers import Conv1D, SpatialDropout1D\n",
        "from keras.layers import Convolution1D, Dense,Activation\n",
        "from keras.models import Input, Model\n",
        "from keras.layers import LSTM, Conv1D, concatenate,GlobalMaxPooling1D,GlobalAveragePooling1D,TimeDistributed, MaxPooling1D\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "import keras.layers\n",
        "from keras import optimizers\n",
        "from keras.layers import Activation, Lambda\n",
        "from keras.layers import Convolution1D, Dense\n",
        "from keras.models import Input, Model\n",
        "from typing import List, Tuple \n",
        "from statistics import mean, stdev\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import linear_model\n",
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RS-oWhjJcBj",
        "outputId": "eaced447-7ef2-41e4-cbb2-3c40754b3b4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Mounted at /content/gdrive\n",
            "(44339, 128, 6) (44339, 20) (4936, 128, 6) (4936, 20)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/'  #change dir to your project folder\n",
        "\n",
        "import numpy as np\n",
        "x_train = np.load('gdrive/MyDrive/Colab Notebooks/Dataset2/trainX2.npy')\n",
        "y_train = np.load('gdrive/My Drive/Colab Notebooks/Dataset2/trainy2.npy')\n",
        "x_test = np.load('gdrive/My Drive/Colab Notebooks/Dataset2/testX2.npy')\n",
        "y_test = np.load('gdrive/My Drive/Colab Notebooks/Dataset2/testy2.npy')\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "NJd0grO3JbFR"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size=0.20, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "iuybbVmRJa6l"
      },
      "outputs": [],
      "source": [
        "def channel_normalization(x):\n",
        "    max_values = K.max(K.abs(x), 2, keepdims=True) + 1e-5\n",
        "    out = x / max_values\n",
        "    return out\n",
        "\n",
        "def residual_block(x, s, i, activation, nb_filters, kernel_size, padding, dropout_rate=0, name=''):\n",
        "    original_x = x\n",
        "    conv = Conv1D(filters=nb_filters, kernel_size=kernel_size,\n",
        "                  dilation_rate=i, padding=padding,\n",
        "                  name=name + '_dilated_conv_%d_tanh_s%d' % (i, s))(x)\n",
        "    if activation == 'norm_relu':\n",
        "        x = Activation('relu')(conv)\n",
        "        x = Lambda(channel_normalization)(x)\n",
        "    else:\n",
        "        x = Activation(activation)(conv)\n",
        "\n",
        "    x = SpatialDropout1D(dropout_rate, name=name + '_spatial_dropout1d_%d_s%d_%f' % (i, s, dropout_rate))(x)\n",
        "\n",
        "    # 1x1 conv.\n",
        "    x = Convolution1D(nb_filters, 1, padding='same')(x)\n",
        "    res_x = keras.layers.add([original_x, x])\n",
        "    return res_x, x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "I-aKoSJzJayg"
      },
      "outputs": [],
      "source": [
        "class TCN:\n",
        "\n",
        "    def __init__(self,\n",
        "                 nb_filters=64,\n",
        "                 kernel_size=2,\n",
        "                 nb_stacks=1,\n",
        "                 dilations=None,\n",
        "                 activation='norm_relu',\n",
        "                 padding='causal',\n",
        "                 use_skip_connections=True,\n",
        "                 dropout_rate=0.0,\n",
        "                 return_sequences=True,\n",
        "                 name='tcn'):\n",
        "        self.name = name\n",
        "        self.return_sequences = return_sequences\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.use_skip_connections = use_skip_connections\n",
        "        self.activation = activation\n",
        "        self.dilations = dilations\n",
        "        self.nb_stacks = nb_stacks\n",
        "        self.kernel_size = kernel_size\n",
        "        self.nb_filters = nb_filters\n",
        "        self.padding = padding\n",
        "        \n",
        "\n",
        "        if padding != 'causal' and padding != 'same':\n",
        "            raise ValueError(\"Only 'causal' or 'same' paddings are compatible for this layer.\")\n",
        "\n",
        "        if not isinstance(nb_filters, int):\n",
        "            print('An interface change occurred after the version 2.1.2.')\n",
        "            print('Before: tcn.TCN(i, return_sequences=False, ...)')\n",
        "            print('Now should be: tcn.TCN(return_sequences=False, ...)(i)')\n",
        "            print('Second solution is to pip install keras-tcn==2.1.2 to downgrade.')\n",
        "            raise Exception()\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        if self.dilations is None:\n",
        "            self.dilations = [1, 2, 4, 8, 16, 32]\n",
        "        x = inputs\n",
        "        x = Convolution1D(self.nb_filters, 1, padding=self.padding, name=self.name + '_initial_conv')(x)\n",
        "        skip_connections = []\n",
        "        for s in range(self.nb_stacks):\n",
        "            for i in self.dilations:\n",
        "                x, skip_out = residual_block(x, s, i, self.activation, self.nb_filters,\n",
        "                                             self.kernel_size, self.padding, self.dropout_rate, name=self.name)\n",
        "                skip_connections.append(skip_out)\n",
        "        if self.use_skip_connections:\n",
        "            x = keras.layers.add(skip_connections)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "        if not self.return_sequences:\n",
        "            output_slice_index = -1\n",
        "            x = Lambda(lambda tt: tt[:, output_slice_index, :])(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]"
      ],
      "metadata": {
        "id": "a_BCk4qP089c"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = x_train.shape[1:]\n",
        "input = Input(shape=x_train.shape[1:])"
      ],
      "metadata": {
        "id": "ciO2dStM1JX8"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYzcyeLC4iZn",
        "outputId": "52c3a14c-4ac1-490f-fcb9-a4808eafd889"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35471, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = (np.argmax(y_train, axis=1)).reshape(-1, 1)\n",
        "y_test =  (np.argmax(y_test, axis=1)).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "CpyXZutNXUvi"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyskGFWS9G8C",
        "outputId": "a1a768d3-23b1-4f49-9a00-b52e9aec809d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35471, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "num_folds = 2\n",
        "inputs = np.concatenate((x_train, x_test), axis=0)\n",
        "targets = np.concatenate((y_train, y_test), axis=0)\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "fold_no = 1\n",
        "input_shape = x_train.shape[1:]\n",
        "input = Input(shape=x_train.shape[1:])\n",
        "for train, test in skf.split(inputs, targets):\n",
        "\n",
        "  x = SpatialDropout1D(0.2)(input)\n",
        "  x = TCN(128,dilations = [1, 2, 4, 8, 16],kernel_size = 3, return_sequences=True, name = 'tnc1')(x)\n",
        "  x = TCN(128,dilations = [1, 2, 4, 8, 16],kernel_size = 3, return_sequences=True, name = 'tnc2')(x)\n",
        "  max_pool = GlobalMaxPooling1D()(x)\n",
        "  x = Dense(128, activation=\"relu\")(max_pool)\n",
        "  x = Dropout(0.2)(x)\n",
        "  output = Dense(118, activation=\"softmax\")(x)    \n",
        "  model = Model(inputs=input, outputs=output)\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  history = model.fit(inputs[train], targets[train], epochs=10, verbose=True, batch_size=128,callbacks=[keras.callbacks.EarlyStopping(monitor='loss', patience=5,restore_best_weights=True)])\n",
        "    # Generate generalization metrics\n",
        "  scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1NlnQvaZxR9",
        "outputId": "841f07ed-f4f4-42d0-9af3-2aa1a696c5c8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "253/253 [==============================] - 42s 150ms/step - loss: 1.0502 - accuracy: 0.7130\n",
            "Epoch 2/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.2231 - accuracy: 0.9392\n",
            "Epoch 3/10\n",
            "253/253 [==============================] - 38s 150ms/step - loss: 0.1491 - accuracy: 0.9592\n",
            "Epoch 4/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.1158 - accuracy: 0.9683\n",
            "Epoch 5/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0898 - accuracy: 0.9747\n",
            "Epoch 6/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0796 - accuracy: 0.9774\n",
            "Epoch 7/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0691 - accuracy: 0.9802\n",
            "Epoch 8/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0633 - accuracy: 0.9817\n",
            "Epoch 9/10\n",
            "253/253 [==============================] - 38s 148ms/step - loss: 0.0618 - accuracy: 0.9814\n",
            "Epoch 10/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0577 - accuracy: 0.9827\n",
            "Score for fold 1: loss of 0.03483825549483299; accuracy of 99.09675717353821%\n",
            "Epoch 1/10\n",
            "253/253 [==============================] - 89s 150ms/step - loss: 0.9701 - accuracy: 0.7330\n",
            "Epoch 2/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.2134 - accuracy: 0.9410\n",
            "Epoch 3/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.1378 - accuracy: 0.9615\n",
            "Epoch 4/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.1092 - accuracy: 0.9697\n",
            "Epoch 5/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0936 - accuracy: 0.9731\n",
            "Epoch 6/10\n",
            "253/253 [==============================] - 38s 148ms/step - loss: 0.0806 - accuracy: 0.9769\n",
            "Epoch 7/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0726 - accuracy: 0.9791\n",
            "Epoch 8/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0659 - accuracy: 0.9813\n",
            "Epoch 9/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0589 - accuracy: 0.9828\n",
            "Epoch 10/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0557 - accuracy: 0.9827\n",
            "Score for fold 2: loss of 0.0334651842713356; accuracy of 99.03489351272583%\n",
            "Epoch 1/10\n",
            "253/253 [==============================] - 41s 148ms/step - loss: 0.9439 - accuracy: 0.7350\n",
            "Epoch 2/10\n",
            "253/253 [==============================] - 38s 148ms/step - loss: 0.2095 - accuracy: 0.9439\n",
            "Epoch 3/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.1364 - accuracy: 0.9627\n",
            "Epoch 4/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.1057 - accuracy: 0.9712\n",
            "Epoch 5/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0892 - accuracy: 0.9752\n",
            "Epoch 6/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0810 - accuracy: 0.9766\n",
            "Epoch 7/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0695 - accuracy: 0.9800\n",
            "Epoch 8/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0654 - accuracy: 0.9806\n",
            "Epoch 9/10\n",
            "253/253 [==============================] - 38s 148ms/step - loss: 0.0596 - accuracy: 0.9834\n",
            "Epoch 10/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0561 - accuracy: 0.9834\n",
            "Score for fold 3: loss of 0.04454832896590233; accuracy of 98.71302843093872%\n",
            "Epoch 1/10\n",
            "253/253 [==============================] - 42s 149ms/step - loss: 0.9286 - accuracy: 0.7402\n",
            "Epoch 2/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.2110 - accuracy: 0.9424\n",
            "Epoch 3/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.1357 - accuracy: 0.9632\n",
            "Epoch 4/10\n",
            "253/253 [==============================] - 38s 150ms/step - loss: 0.1060 - accuracy: 0.9704\n",
            "Epoch 5/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0954 - accuracy: 0.9734\n",
            "Epoch 6/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0849 - accuracy: 0.9747\n",
            "Epoch 7/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0666 - accuracy: 0.9812\n",
            "Epoch 8/10\n",
            "253/253 [==============================] - 38s 150ms/step - loss: 0.0688 - accuracy: 0.9805\n",
            "Epoch 9/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0591 - accuracy: 0.9842\n",
            "Epoch 10/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0550 - accuracy: 0.9834\n",
            "Score for fold 4: loss of 0.030938971787691116; accuracy of 99.12139773368835%\n",
            "Epoch 1/10\n",
            "253/253 [==============================] - 42s 150ms/step - loss: 0.9644 - accuracy: 0.7322\n",
            "Epoch 2/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.2087 - accuracy: 0.9422\n",
            "Epoch 3/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.1361 - accuracy: 0.9620\n",
            "Epoch 4/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.1095 - accuracy: 0.9687\n",
            "Epoch 5/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0883 - accuracy: 0.9748\n",
            "Epoch 6/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0839 - accuracy: 0.9756\n",
            "Epoch 7/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0711 - accuracy: 0.9797\n",
            "Epoch 8/10\n",
            "253/253 [==============================] - 38s 150ms/step - loss: 0.0696 - accuracy: 0.9794\n",
            "Epoch 9/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0615 - accuracy: 0.9833\n",
            "Epoch 10/10\n",
            "253/253 [==============================] - 38s 149ms/step - loss: 0.0543 - accuracy: 0.9841\n",
            "Score for fold 5: loss of 0.04448337480425835; accuracy of 98.53978753089905%\n",
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 128, 6)]     0           []                               \n",
            "                                                                                                  \n",
            " spatial_dropout1d_13 (SpatialD  (None, 128, 6)      0           ['input_5[0][0]']                \n",
            " ropout1D)                                                                                        \n",
            "                                                                                                  \n",
            " tnc1_initial_conv (Conv1D)     (None, 128, 128)     896         ['spatial_dropout1d_13[0][0]']   \n",
            "                                                                                                  \n",
            " tnc1_dilated_conv_1_tanh_s0 (C  (None, 128, 128)    49280       ['tnc1_initial_conv[0][0]']      \n",
            " onv1D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_156 (Activation)    (None, 128, 128)     0           ['tnc1_dilated_conv_1_tanh_s0[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " lambda_130 (Lambda)            (None, 128, 128)     0           ['activation_156[0][0]']         \n",
            "                                                                                                  \n",
            " tnc1_spatial_dropout1d_1_s0_0.  (None, 128, 128)    0           ['lambda_130[0][0]']             \n",
            " 000000 (SpatialDropout1D)                                                                        \n",
            "                                                                                                  \n",
            " conv1d_130 (Conv1D)            (None, 128, 128)     16512       ['tnc1_spatial_dropout1d_1_s0_0.0\n",
            "                                                                 00000[0][0]']                    \n",
            "                                                                                                  \n",
            " add_156 (Add)                  (None, 128, 128)     0           ['tnc1_initial_conv[0][0]',      \n",
            "                                                                  'conv1d_130[0][0]']             \n",
            "                                                                                                  \n",
            " tnc1_dilated_conv_2_tanh_s0 (C  (None, 128, 128)    49280       ['add_156[0][0]']                \n",
            " onv1D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_157 (Activation)    (None, 128, 128)     0           ['tnc1_dilated_conv_2_tanh_s0[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " lambda_131 (Lambda)            (None, 128, 128)     0           ['activation_157[0][0]']         \n",
            "                                                                                                  \n",
            " tnc1_spatial_dropout1d_2_s0_0.  (None, 128, 128)    0           ['lambda_131[0][0]']             \n",
            " 000000 (SpatialDropout1D)                                                                        \n",
            "                                                                                                  \n",
            " conv1d_131 (Conv1D)            (None, 128, 128)     16512       ['tnc1_spatial_dropout1d_2_s0_0.0\n",
            "                                                                 00000[0][0]']                    \n",
            "                                                                                                  \n",
            " add_157 (Add)                  (None, 128, 128)     0           ['add_156[0][0]',                \n",
            "                                                                  'conv1d_131[0][0]']             \n",
            "                                                                                                  \n",
            " tnc1_dilated_conv_4_tanh_s0 (C  (None, 128, 128)    49280       ['add_157[0][0]']                \n",
            " onv1D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_158 (Activation)    (None, 128, 128)     0           ['tnc1_dilated_conv_4_tanh_s0[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " lambda_132 (Lambda)            (None, 128, 128)     0           ['activation_158[0][0]']         \n",
            "                                                                                                  \n",
            " tnc1_spatial_dropout1d_4_s0_0.  (None, 128, 128)    0           ['lambda_132[0][0]']             \n",
            " 000000 (SpatialDropout1D)                                                                        \n",
            "                                                                                                  \n",
            " conv1d_132 (Conv1D)            (None, 128, 128)     16512       ['tnc1_spatial_dropout1d_4_s0_0.0\n",
            "                                                                 00000[0][0]']                    \n",
            "                                                                                                  \n",
            " add_158 (Add)                  (None, 128, 128)     0           ['add_157[0][0]',                \n",
            "                                                                  'conv1d_132[0][0]']             \n",
            "                                                                                                  \n",
            " tnc1_dilated_conv_8_tanh_s0 (C  (None, 128, 128)    49280       ['add_158[0][0]']                \n",
            " onv1D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_159 (Activation)    (None, 128, 128)     0           ['tnc1_dilated_conv_8_tanh_s0[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " lambda_133 (Lambda)            (None, 128, 128)     0           ['activation_159[0][0]']         \n",
            "                                                                                                  \n",
            " tnc1_spatial_dropout1d_8_s0_0.  (None, 128, 128)    0           ['lambda_133[0][0]']             \n",
            " 000000 (SpatialDropout1D)                                                                        \n",
            "                                                                                                  \n",
            " conv1d_133 (Conv1D)            (None, 128, 128)     16512       ['tnc1_spatial_dropout1d_8_s0_0.0\n",
            "                                                                 00000[0][0]']                    \n",
            "                                                                                                  \n",
            " add_159 (Add)                  (None, 128, 128)     0           ['add_158[0][0]',                \n",
            "                                                                  'conv1d_133[0][0]']             \n",
            "                                                                                                  \n",
            " tnc1_dilated_conv_16_tanh_s0 (  (None, 128, 128)    49280       ['add_159[0][0]']                \n",
            " Conv1D)                                                                                          \n",
            "                                                                                                  \n",
            " activation_160 (Activation)    (None, 128, 128)     0           ['tnc1_dilated_conv_16_tanh_s0[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " lambda_134 (Lambda)            (None, 128, 128)     0           ['activation_160[0][0]']         \n",
            "                                                                                                  \n",
            " tnc1_spatial_dropout1d_16_s0_0  (None, 128, 128)    0           ['lambda_134[0][0]']             \n",
            " .000000 (SpatialDropout1D)                                                                       \n",
            "                                                                                                  \n",
            " conv1d_134 (Conv1D)            (None, 128, 128)     16512       ['tnc1_spatial_dropout1d_16_s0_0.\n",
            "                                                                 000000[0][0]']                   \n",
            "                                                                                                  \n",
            " add_161 (Add)                  (None, 128, 128)     0           ['conv1d_130[0][0]',             \n",
            "                                                                  'conv1d_131[0][0]',             \n",
            "                                                                  'conv1d_132[0][0]',             \n",
            "                                                                  'conv1d_133[0][0]',             \n",
            "                                                                  'conv1d_134[0][0]']             \n",
            "                                                                                                  \n",
            " activation_161 (Activation)    (None, 128, 128)     0           ['add_161[0][0]']                \n",
            "                                                                                                  \n",
            " tnc2_initial_conv (Conv1D)     (None, 128, 128)     16512       ['activation_161[0][0]']         \n",
            "                                                                                                  \n",
            " tnc2_dilated_conv_1_tanh_s0 (C  (None, 128, 128)    49280       ['tnc2_initial_conv[0][0]']      \n",
            " onv1D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_162 (Activation)    (None, 128, 128)     0           ['tnc2_dilated_conv_1_tanh_s0[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " lambda_135 (Lambda)            (None, 128, 128)     0           ['activation_162[0][0]']         \n",
            "                                                                                                  \n",
            " tnc2_spatial_dropout1d_1_s0_0.  (None, 128, 128)    0           ['lambda_135[0][0]']             \n",
            " 000000 (SpatialDropout1D)                                                                        \n",
            "                                                                                                  \n",
            " conv1d_135 (Conv1D)            (None, 128, 128)     16512       ['tnc2_spatial_dropout1d_1_s0_0.0\n",
            "                                                                 00000[0][0]']                    \n",
            "                                                                                                  \n",
            " add_162 (Add)                  (None, 128, 128)     0           ['tnc2_initial_conv[0][0]',      \n",
            "                                                                  'conv1d_135[0][0]']             \n",
            "                                                                                                  \n",
            " tnc2_dilated_conv_2_tanh_s0 (C  (None, 128, 128)    49280       ['add_162[0][0]']                \n",
            " onv1D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_163 (Activation)    (None, 128, 128)     0           ['tnc2_dilated_conv_2_tanh_s0[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " lambda_136 (Lambda)            (None, 128, 128)     0           ['activation_163[0][0]']         \n",
            "                                                                                                  \n",
            " tnc2_spatial_dropout1d_2_s0_0.  (None, 128, 128)    0           ['lambda_136[0][0]']             \n",
            " 000000 (SpatialDropout1D)                                                                        \n",
            "                                                                                                  \n",
            " conv1d_136 (Conv1D)            (None, 128, 128)     16512       ['tnc2_spatial_dropout1d_2_s0_0.0\n",
            "                                                                 00000[0][0]']                    \n",
            "                                                                                                  \n",
            " add_163 (Add)                  (None, 128, 128)     0           ['add_162[0][0]',                \n",
            "                                                                  'conv1d_136[0][0]']             \n",
            "                                                                                                  \n",
            " tnc2_dilated_conv_4_tanh_s0 (C  (None, 128, 128)    49280       ['add_163[0][0]']                \n",
            " onv1D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_164 (Activation)    (None, 128, 128)     0           ['tnc2_dilated_conv_4_tanh_s0[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " lambda_137 (Lambda)            (None, 128, 128)     0           ['activation_164[0][0]']         \n",
            "                                                                                                  \n",
            " tnc2_spatial_dropout1d_4_s0_0.  (None, 128, 128)    0           ['lambda_137[0][0]']             \n",
            " 000000 (SpatialDropout1D)                                                                        \n",
            "                                                                                                  \n",
            " conv1d_137 (Conv1D)            (None, 128, 128)     16512       ['tnc2_spatial_dropout1d_4_s0_0.0\n",
            "                                                                 00000[0][0]']                    \n",
            "                                                                                                  \n",
            " add_164 (Add)                  (None, 128, 128)     0           ['add_163[0][0]',                \n",
            "                                                                  'conv1d_137[0][0]']             \n",
            "                                                                                                  \n",
            " tnc2_dilated_conv_8_tanh_s0 (C  (None, 128, 128)    49280       ['add_164[0][0]']                \n",
            " onv1D)                                                                                           \n",
            "                                                                                                  \n",
            " activation_165 (Activation)    (None, 128, 128)     0           ['tnc2_dilated_conv_8_tanh_s0[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " lambda_138 (Lambda)            (None, 128, 128)     0           ['activation_165[0][0]']         \n",
            "                                                                                                  \n",
            " tnc2_spatial_dropout1d_8_s0_0.  (None, 128, 128)    0           ['lambda_138[0][0]']             \n",
            " 000000 (SpatialDropout1D)                                                                        \n",
            "                                                                                                  \n",
            " conv1d_138 (Conv1D)            (None, 128, 128)     16512       ['tnc2_spatial_dropout1d_8_s0_0.0\n",
            "                                                                 00000[0][0]']                    \n",
            "                                                                                                  \n",
            " add_165 (Add)                  (None, 128, 128)     0           ['add_164[0][0]',                \n",
            "                                                                  'conv1d_138[0][0]']             \n",
            "                                                                                                  \n",
            " tnc2_dilated_conv_16_tanh_s0 (  (None, 128, 128)    49280       ['add_165[0][0]']                \n",
            " Conv1D)                                                                                          \n",
            "                                                                                                  \n",
            " activation_166 (Activation)    (None, 128, 128)     0           ['tnc2_dilated_conv_16_tanh_s0[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " lambda_139 (Lambda)            (None, 128, 128)     0           ['activation_166[0][0]']         \n",
            "                                                                                                  \n",
            " tnc2_spatial_dropout1d_16_s0_0  (None, 128, 128)    0           ['lambda_139[0][0]']             \n",
            " .000000 (SpatialDropout1D)                                                                       \n",
            "                                                                                                  \n",
            " conv1d_139 (Conv1D)            (None, 128, 128)     16512       ['tnc2_spatial_dropout1d_16_s0_0.\n",
            "                                                                 000000[0][0]']                   \n",
            "                                                                                                  \n",
            " add_167 (Add)                  (None, 128, 128)     0           ['conv1d_135[0][0]',             \n",
            "                                                                  'conv1d_136[0][0]',             \n",
            "                                                                  'conv1d_137[0][0]',             \n",
            "                                                                  'conv1d_138[0][0]',             \n",
            "                                                                  'conv1d_139[0][0]']             \n",
            "                                                                                                  \n",
            " activation_167 (Activation)    (None, 128, 128)     0           ['add_167[0][0]']                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_13 (Globa  (None, 128)         0           ['activation_167[0][0]']         \n",
            " lMaxPooling1D)                                                                                   \n",
            "                                                                                                  \n",
            " dense_26 (Dense)               (None, 128)          16512       ['global_max_pooling1d_13[0][0]']\n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)           (None, 128)          0           ['dense_26[0][0]']               \n",
            "                                                                                                  \n",
            " dense_27 (Dense)               (None, 118)          15222       ['dropout_13[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 707,062\n",
            "Trainable params: 707,062\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "inputs = np.concatenate((x_train, x_test), axis=0)\n",
        "targets = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in skf.split(inputs, targets):\n",
        "  x = SpatialDropout1D(0.2)(input)\n",
        "  x = TCN(128,dilations = [1, 2, 4, 8, 16],kernel_size = 3, return_sequences=True, name = 'tnc1')(x)\n",
        "  x = TCN(128,dilations = [1, 2, 4, 8, 16],kernel_size = 3, return_sequences=True, name = 'tnc2')(x)\n",
        "  max_pool = GlobalMaxPooling1D()(x)\n",
        "  x = Dense(128, activation=\"relu\")(max_pool)\n",
        "  x = Dropout(0.2)(x)\n",
        "  output = Dense(20, activation=\"softmax\")(x)    \n",
        "  model = Model(inputs=input, outputs=output)\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  y_train = (np.argmax(y_train, axis=1)).reshape(-1, 1)\n",
        "  y_test =  (np.argmax(y_test, axis=1)).reshape(-1, 1)\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "  history = model.fit(x_train, y_train, epochs=50, verbose=True, validation_data=(x_validation, y_validation), batch_size=128,callbacks=callbacks)\n",
        "  scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "  "
      ],
      "metadata": {
        "id": "EHhAb0E5yfue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDA-lbMQ6tWg",
        "outputId": "3a7ca80a-dcde-4749-936e-70b1ab5c5d1a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.03483825549483299 - Accuracy: 99.09675717353821%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.0334651842713356 - Accuracy: 99.03489351272583%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.04454832896590233 - Accuracy: 98.71302843093872%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.030938971787691116 - Accuracy: 99.12139773368835%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.04448337480425835 - Accuracy: 98.53978753089905%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 98.90117287635803 (+- 0.2326504304465748)\n",
            "> Loss: 0.037654823064804076\n",
            "------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Final_Stratified_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "170e85bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1022, 6, 1024, 1)\n",
      "(1022, 1024)\n",
      "(332, 6, 1024, 1)\n",
      "(332, 1024)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import preprocessing\n",
    "from tensorflow.keras import layers ,models\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def read_data(data_path):\n",
    "    data = []\n",
    "    file_names = os.listdir(data_path)\n",
    "    file_names.sort(key=lambda x:int(x[:-4]))\n",
    "    for file_name in file_names:\n",
    "        file_path = os.path.join(data_path, file_name)\n",
    "        signal_data = np.loadtxt(file_path)\n",
    "        data.append(signal_data)\n",
    "    data = np.array(data).transpose(0, 2, 1)\n",
    "    d_shape = data.shape\n",
    "    return data.reshape(d_shape[0], 1, d_shape[1], d_shape[2])\n",
    "\n",
    "\n",
    "def read_label(data_path):\n",
    "    data = []\n",
    "    file_names = os.listdir(data_path)\n",
    "    file_names.sort(key=lambda x:int(x[:-10]))\n",
    "    for file_name in file_names:\n",
    "        file_path = os.path.join(data_path, file_name)\n",
    "        signal_data = np.loadtxt(file_path)\n",
    "        data.append(signal_data)\n",
    "    return np.array(data)\n",
    "\n",
    "\n",
    "\n",
    "train_data_path = r\"D:\\Fourth year\\Graduation project\\data2\\Dataset #8\\Dataset #8\\train\\train_data\"\n",
    "train_label_path = r\"D:\\Fourth year\\Graduation project\\data2\\Dataset #8\\Dataset #8\\train\\train_label\"\n",
    "test_data_path = r\"D:\\Fourth year\\Graduation project\\data2\\Dataset #8\\Dataset #8\\test\\test_data\"\n",
    "test_label_path = r\"D:\\Fourth year\\Graduation project\\data2\\Dataset #8\\Dataset #8\\test\\test_label\"\n",
    "#train_data = read_data(train_data_path)\n",
    "#train_label = read_label(train_label_path)\n",
    "#test_data = read_data(test_data_path)\n",
    "#test_label = read_label(test_label_path)\n",
    "\n",
    "#print(train_data.shape)\n",
    "#print(train_label.shape)\n",
    "#print(test_data.shape)\n",
    "#print(test_label.shape)\n",
    "#1022 number of files in train \n",
    "#332 number of files in train\n",
    "#6 number of columns in each file\n",
    "#1024 number of rows in each file\n",
    "\n",
    "train_data = read_data(train_data_path).transpose(0, 2, 3, 1) # 519\n",
    "train_label = read_label(train_label_path)\n",
    "test_data = read_data(test_data_path).transpose(0, 2, 3, 1) # 519\n",
    "test_label = read_label(test_label_path)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_data.shape)\n",
    "print(test_label.shape)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b050c471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(np.unique(train_label))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdebab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.permutation(len(train_data))\n",
    "train_data = train_data[idx]\n",
    "train_label = train_label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abbd6435",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label[train_label == -1] = 0\n",
    "test_label[test_label == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efe595d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 6, 1024, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 6, 1024, 1)   4           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 6, 1024, 64)  1088        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 6, 1024, 64)  256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 6, 1024, 64)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 6, 1024, 64)  8256        re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 6, 1024, 64)  256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 6, 1024, 64)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 6, 512, 64)   0           re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 6, 512, 64)   256         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 6, 512, 128)  131200      batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 6, 512, 128)  512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 6, 512, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 6, 512, 128)  262272      re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 6, 512, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 6, 512, 128)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 6, 256, 128)  0           re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 6, 256, 128)  512         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 6, 256, 256)  524544      batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 6, 256, 256)  1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 6, 256, 256)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 6, 256, 256)  1048832     re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 6, 256, 256)  1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 6, 256, 256)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 6, 256, 256)  1048832     re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 6, 256, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 6, 256, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 6, 512, 128)  65664       re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 512, 256)  0           conv2d_transpose[0][0]           \n",
      "                                                                 re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 6, 512, 256)  1024        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 6, 512, 128)  524416      batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 6, 512, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 6, 512, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 6, 512, 128)  262272      re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 6, 512, 128)  512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 6, 512, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 6, 1024, 64)  16448       re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 1024, 128) 0           re_lu_1[0][0]                    \n",
      "                                                                 conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 6, 1024, 128) 512         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 6, 1024, 64)  131136      batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 6, 1024, 64)  256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 6, 1024, 64)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 6, 1024, 64)  65600       re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 6, 1024, 64)  256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 6, 1024, 64)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 1, 1024, 256) 98560       re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 1, 1024, 256) 1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 1, 1024, 256) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 1, 1024, 1)   257         re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1, 1024, 1)   4           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape (TFOpLambda)         (None, 1024)         0           batch_normalization_17[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 4,198,857\n",
      "Trainable params: 4,194,117\n",
      "Non-trainable params: 4,740\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def make_model(input_shape):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    conv = keras.layers.BatchNormalization()(input_layer)\n",
    "    conv1_1 = keras.layers.Conv2D(filters=64, kernel_size=[1, 16], padding=\"same\")(conv)\n",
    "    conv1_1 = keras.layers.BatchNormalization()(conv1_1)\n",
    "    conv1_1 = keras.layers.ReLU()(conv1_1)\n",
    "\n",
    "    conv1_2 = keras.layers.Conv2D(filters=64, kernel_size=[1, 2], padding=\"same\")(conv1_1)\n",
    "    conv1_2 = keras.layers.BatchNormalization()(conv1_2)\n",
    "    conv1_2 = keras.layers.ReLU()(conv1_2)\n",
    "    \n",
    "    conv2_1= keras.layers.MaxPooling2D(pool_size=[1, 16], strides=[1,2], padding=\"same\")(conv1_2)\n",
    "    conv2_1 = keras.layers.BatchNormalization()(conv2_1)\n",
    "    \n",
    "    conv2_2 = keras.layers.Conv2D(filters=128, kernel_size=[1, 16], padding=\"same\")(conv2_1)\n",
    "    conv2_2 = keras.layers.BatchNormalization()(conv2_2)\n",
    "    conv2_2 = keras.layers.ReLU()(conv2_2)\n",
    "    \n",
    "    conv2_3 = keras.layers.Conv2D(filters=128, kernel_size=[1, 16], padding=\"same\")(conv2_2)\n",
    "    conv2_3 = keras.layers.BatchNormalization()(conv2_3)\n",
    "    conv2_3 = keras.layers.ReLU()(conv2_3)\n",
    "    \n",
    "    conv3_1 = keras.layers.MaxPooling2D(pool_size=(1, 2), strides=[1,2], padding=\"same\", data_format=None)(conv2_3)\n",
    "    conv3_1 = keras.layers.BatchNormalization()(conv3_1)\n",
    "    \n",
    "    conv3_2 = keras.layers.Conv2D(filters=256, kernel_size=[1, 16], padding=\"same\")(conv3_1)\n",
    "    conv3_2 = keras.layers.BatchNormalization()(conv3_2)\n",
    "    conv3_2 = keras.layers.ReLU()(conv3_2)\n",
    "    \n",
    "    conv3_3 = keras.layers.Conv2D(filters=256, kernel_size=[1, 16], padding=\"same\")(conv3_2)\n",
    "    conv3_3 = keras.layers.BatchNormalization()(conv3_3)\n",
    "    conv3_3 = keras.layers.ReLU()(conv3_3)\n",
    "    \n",
    "    conv3_4 = keras.layers.Conv2D(filters=256, kernel_size=[1, 16], padding=\"same\")(conv3_3)\n",
    "    conv3_4 = keras.layers.BatchNormalization()(conv3_4)\n",
    "    conv3_4 = keras.layers.ReLU()(conv3_4)\n",
    "    \n",
    "    conv2_4_1 = keras.layers.Conv2DTranspose(filters=128, kernel_size=[1,2],strides=[1,2], padding=\"same\")(conv3_4)\n",
    "    conv2_4 = tf.keras.layers.Concatenate(axis =3)([conv2_4_1, conv2_3])\n",
    "    conv2_4 = keras.layers.BatchNormalization()(conv2_4)\n",
    "    \n",
    "    conv2_5 = keras.layers.Conv2D(filters=128, kernel_size=[1, 16], padding=\"same\")(conv2_4)\n",
    "    conv2_5 = keras.layers.BatchNormalization()(conv2_5)\n",
    "    conv2_5 = keras.layers.ReLU()(conv2_5)\n",
    "    \n",
    "    conv2_6 = keras.layers.Conv2D(filters=128, kernel_size=[1, 16], padding=\"same\")(conv2_5)\n",
    "    conv2_6 = keras.layers.BatchNormalization()(conv2_6)\n",
    "    conv2_6 = keras.layers.ReLU()(conv2_6)\n",
    "    \n",
    "    conv1_3_1 = keras.layers.Conv2DTranspose(filters=64, kernel_size=[1, 2],strides=[1,2], padding=\"same\")(conv2_6)\n",
    "    conv1_3 = tf.keras.layers.Concatenate(axis =3)([conv1_2, conv1_3_1])\n",
    "    conv1_3 = keras.layers.BatchNormalization()(conv1_3)\n",
    "    \n",
    "    conv1_4 = keras.layers.Conv2D(filters=64, kernel_size=[1, 16], padding=\"same\")(conv1_3)\n",
    "    conv1_4 = keras.layers.BatchNormalization()(conv1_4)\n",
    "    conv1_4 = keras.layers.ReLU()(conv1_4)\n",
    "    \n",
    "    conv1_4 = keras.layers.Conv2D(filters=64, kernel_size=[1, 16], padding=\"same\")(conv1_4)\n",
    "    conv1_4 = keras.layers.BatchNormalization()(conv1_4)\n",
    "    conv1_4 = keras.layers.ReLU()(conv1_4)\n",
    "    \n",
    "    conv1_5 = keras.layers.Conv2D(filters=256, kernel_size=[6,1], padding=\"valid\")(conv1_4)\n",
    "    conv1_5 = keras.layers.BatchNormalization()(conv1_5)\n",
    "    conv1_5 = keras.layers.ReLU()(conv1_5)\n",
    "    \n",
    "    #gap = keras.layers.GlobalAveragePooling2D()(conv1_5)\n",
    "\n",
    "    output_layer = keras.layers.Conv2D(filters=1, kernel_size=[1, 1], padding=\"same\",activation=\"softmax\")(conv1_5)\n",
    "    output_layer = keras.layers.BatchNormalization()(output_layer)\n",
    "    out= tf.reshape(output_layer,[-1,1024])\n",
    "    layers.Flatten()\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=out)\n",
    "    #out = tf.reshape(output_layer, [-1, 1024])\n",
    "    #return out\n",
    "     \n",
    "model = make_model(input_shape=train_data.shape[1:])\n",
    "keras.utils.plot_model(model, show_shapes=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aafb781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2d43c63373f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m      \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m )\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3040\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1964\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.00001\n",
    "epochs = 150\n",
    "batch_size = 32\n",
    "display_step = 1\n",
    "data_len = len(train_data)\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.00001\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    train_label,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "     callbacks=callbacks,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2174ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
